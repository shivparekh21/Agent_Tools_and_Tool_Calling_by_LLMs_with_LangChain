{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Tools in LangChain"
      ],
      "metadata": {
        "id": "-CVPAiNAy9MH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ],
      "metadata": {
        "id": "L1KvMtf54l0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "yXgPP-n3lDy6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain  # ==0.3.14\n",
        "!pip install langchain-openai # ==0.3.0\n",
        "!pip install langchain-community # ==0.3.14"
      ],
      "metadata": {
        "id": "2evPp14fy258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88c9246-f204-4862-fa60-b98f46bce666"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.8)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.6.8)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain) (2.5.0)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.2.8)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.16.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.6.8)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-1.1.7\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.2.8)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (26.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Data Extraction APIs"
      ],
      "metadata": {
        "id": "TlfidBdQZRGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to create custom tools\n",
        "!pip install wikipedia # ==1.4.0\n",
        "!pip install markitdown\n",
        "# to highlight json\n",
        "!pip install rich"
      ],
      "metadata": {
        "id": "uZKQDgQURhmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af41c7d4-1a8b-4822-dec4-5ffa52325675"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2026.1.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=f9e1b98f968976880d268ff0e1994fca1d8663aaa8b3a6f9a426cf12eb26ad52\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Collecting markitdown\n",
            "  Downloading markitdown-0.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown) (0.7.1)\n",
            "Collecting magika~=0.6.1 (from markitdown)\n",
            "  Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting markdownify (from markitdown)\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown) (2.32.5)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (8.3.1)\n",
            "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown)\n",
            "  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (1.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (2026.1.4)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.14.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.3.0)\n",
            "Downloading markitdown-0.1.4-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl (15.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxruntime, markdownify, magika, markitdown\n",
            "Successfully installed magika-0.6.3 markdownify-1.2.2 markitdown-0.1.4 onnxruntime-1.24.1\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Get a free API key from [here](https://tavily.com/#api)\n",
        "\n",
        "- Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ],
      "metadata": {
        "id": "ory1TRS3gpTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "os.environ['WEATHER_API_KEY'] = userdata.get('WEATHER_API_KEY')"
      ],
      "metadata": {
        "id": "MxSMZ1Z5gMn7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Built-in Tools"
      ],
      "metadata": {
        "id": "65C3PellZGYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the Wikipedia Tool\n",
        "\n",
        "Enables you to tap into the Wikipedia API to search wikipedia pages for information"
      ],
      "metadata": {
        "id": "howf-v0ARWbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=3,\n",
        "                                       doc_content_chars_max=8000)\n",
        "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper, features=\"lxml\")"
      ],
      "metadata": {
        "id": "q2CMhK9Rjk2t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vars() or __dict__ - shows instance attributes (if available)\n",
        "# print(vars(wiki_tool))\n",
        "# help(wiki_tool)"
      ],
      "metadata": {
        "id": "k9C15oX-2qtk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool.description"
      ],
      "metadata": {
        "id": "t1Ce8wbYodYO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6d9b7b91-afdc-4ea0-e4cc-874dfa8e32c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2MSVAh2osSE",
        "outputId": "60b6ae5a-4cdf-4ff5-e50a-e6b920e0db8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': {'description': 'query to look up on wikipedia',\n",
              "  'title': 'Query',\n",
              "  'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wiki_tool.invoke({\"query\": \"ISRO\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luhjlzeSkgUq",
        "outputId": "9a61758b-ba09-45c6-8be6-a418bf06eb03",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: ISRO\n",
            "Summary: The Indian Space Research Organisation (ISRO ) is the national space agency of India, headquartered in Bengaluru, Karnataka. It serves as the principal research and development arm of the Department of Space (DoS), overseen by the Prime Minister of India, with the Chairman of ISRO also serving as the chief executive of the DoS. It is primarily responsible for space-based operations, space exploration, international space cooperation and the development of related technologies. The agency maintains a constellation of imaging, communications and remote sensing satellites. It operates the GAGAN and IRNSS satellite navigation systems. It has sent three missions to the Moon and one mission to Mars.\n",
            "Formerly, ISRO was known as the Indian National Committee for Space Research (INCOSPAR), which was set up in 1962 by then-Prime Minister Jawaharlal Nehru on the recommendation of scientist Vikram Sarabhai. It was renamed as ISRO in 1969 and was subsumed into the Department of Atomic Energy (DAE). The establishment of ISRO institutionalised space research activities in India. In 1972, the Government set up a space commission and the DoS bringing ISRO under its purview. It has since then been managed by the DoS, which also governs various other institutions in the domain of astronomy and space technology.\n",
            "ISRO built India's first satellite Aryabhata which was launched by the Soviet space agency Interkosmos in 1975. In 1980, it launched the satellite RS-1 on board the indigenously built launch vehicle SLV-3, making India the seventh country to undertake orbital launches. It has subsequently developed various small-lift and medium-lift launch vehicles, enabling the agency to launch various satellites and deep space missions. It is one of the six government space agencies in the world that possess full launch capabilities with the ability to deploy cryogenic engines, launch extraterrestrial missions and artificial satellites. It is also the only one of the four governmental space agencies to have demonstrated unmanned soft landing capabilities.\n",
            "ISRO's programmes have played a significant role in socio-economic development. It has supported both civilian and military domains in various aspects such as disaster management, telemedicine, navigation and reconnaissance. ISRO's spin-off technologies have also aided in new innovations in engineering and other allied domains.\n",
            "\n",
            "Page: Gaganyaan\n",
            "Summary: Gaganyaan (Sanskrit: [ɡəɡənəjɑːnə],, from Sanskrit: gagana, \"celestial\" and yāna, \"craft, vehicle\") is an Indian crewed orbital spacecraft intended to be the formative spacecraft of the Indian Human Spaceflight Programme. The spacecraft is being designed to carry three people to low Earth orbit, and a planned upgraded version will be equipped with rendezvous and docking capabilities. \n",
            "In its maiden crewed mission, ISRO's largely autonomous 5.3-metric tonne capsule will orbit the Earth at 400 km altitude for up to seven days with a two- or three-person crew on board. The first crewed mission was originally planned to be launched on ISRO's human-rated LVM3 rocket (HLVM3) in December 2021. As of November 2024, it is expected to be launched no earlier than 2027.\n",
            "The Hindustan Aeronautics Limited (HAL)-manufactured crew module underwent its first uncrewed experimental flight on 18 December 2014. As of May 2019, design of the crew module has been completed. The Defence Research and Development Organisation (DRDO) provides support for critical human-centric systems and technologies such as space-grade food, crew healthcare, radiation measurement and protection, parachutes for the safe recovery of the crew module, and the fire suppression system.\n",
            "The Gaganyaan mission is led by V. R. Lalithambika, the former Director of the Directorate of the Human Spaceflight Programme with ISRO Chairman S. Somanath and S. Unnikrishnan Nair, Director of Vikram Sarabhai Space Centre. Imtiaz Ali Khan superseded V. R. Lalithambika as the Director of the Directorate of Human Spaceflight Programme.\n",
            "\n",
            "Page: Chairperson of ISRO\n",
            "Summary: The Chairperson of the Indian Space Research Organisation is the statutory head of ISRO. The officeholder is a secretary to the Government of India and an executive of the Department of Space (DoS) which directly reports to the Prime Minister of India.\n",
            "The Indian National Committee for Space Research (INCOSPAR) was founded in 1962 under the Department of Atomic Energy (DAE) with Vikram Sarabhai as its chairperson which in 1969 became ISRO. In 1972, government of India had set up a space commission and DoS and brought ISRO under DoS.\n",
            "Since Sarabhai has assumed the position, there have been eleven chairmen of the ISRO, with Satish Dhawan serving the longest term of 12 years as the chairman.\n",
            "Recently on 8 January 2025, The Central Government has appointed Dr. V. Narayanan, currently the director of Liquid Propulsion Systems Centre (LPSC), Thiruvananthapuram, as the new chairperson of ISRO, and also as the secretary of the DoS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wiki_tool.invoke({\"query\": \"Make in India\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jglV7GRXjk5O",
        "outputId": "5351d3e2-dfd2-44af-80e5-7fab5b92b966",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: Make in India\n",
            "Summary: Make in India is an initiative by the Government of India to create and encourage companies to develop, manufacture and assemble products in India and incentivize dedicated investments into manufacturing. The policy approach was to create a conducive environment for investments, develop a modern and efficient infrastructure, and open up new sectors for foreign capital.\n",
            "Make in India has been unsuccessful at achieving its stated targets. Under this programme, the share of manufacturing in GDP was projected to reach 25% by 2022. However, the GDP share of manufacturing has actually fallen from 16.7% in 2013–2014 to 15.9% in 2023–2024.\n",
            "\n",
            "\n",
            "\n",
            "Page: India\n",
            "Summary: India, officially the Republic of India, is a country in South Asia.  It is the seventh-largest country by area; the most populous country since 2023; and, since its independence in 1947, the world's most populous democracy. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is near Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Myanmar, Thailand, and Indonesia.\n",
            "Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago. Their long occupation, predominantly in isolation as hunter-gatherers, has made the region highly diverse. Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE. By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest. Its hymns recorded the early dawnings of Hinduism in India. India's pre-existing Dravidian languages were supplanted in the northern regions. By 400 BCE, caste had emerged within Hinduism, and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity. Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires. This era was noted for creativity in art, architecture, and writing, but the status of women declined, and untouchability became an organised belief. In South India, the Middle kingdoms exported Dravidian language scripts and religious cultures to the kingdoms of Southeast Asia.\n",
            "In the 1st millennium, Islam, Christianity, Judaism, and Zoroastrianism became established on India's southern and western coasts. In the early centuries of the 2nd millennium Muslim armies from Central Asia intermittently overran India's northern plains. The resulting Delhi Sultanate drew northern India into the cosmopolitan networks of medieval Islam. In south India, the Vijayanagara Empire created a long-lasting composite Hindu culture. In the Punjab, Sikhism emerged, rejecting institutionalised religion. The Mughal Empire ushered in two centuries of economic expansion and relative peace, and left a rich architectural legacy. Gradually expanding rule of the British East India Company turned India into a colonial economy but consolidated its sovereignty. British Crown rule began in 1858. The rights promised to Indians were granted slowly, but technological changes were introduced, and modern ideas of education and the public life took root. A nationalist movement emerged in India, the first in the non-European British Empire and an influence on other nationalist movements. Noted for nonviolent resistance after 1920, it became the primary factor in ending British rule. In 1947, the British Indian Empire was partitioned into two independent dominions, a Hindu-majority dominion of India and a Muslim-majority dominion of Pakistan. A large-scale loss of life and an unprecedented migration accompanied the partition.\n",
            "India has been a federal republic since 1950, governed through a democratic parliamentary system. It is a pluralistic, multilingual and multi-ethnic society. India's population grew from 361 million in 1951 to over 1.4 billion in 2023. During this time, its nominal per capita income increased from US$64 annually to US$2,601, and its literacy rate from 16.6% to 74%. A comparatively destitute country in 1951, India has become a fast-growing major economy and a hub for information technology services, with an expanding middle class. India has reduced its poverty rate, though at the cost of increasing economic inequality. It is a nuclear-weapon state that ranks high in military expenditure. It has disputes over Kashmir with its neighbours, Pakistan and China, unresolved since the mid-20th century. Among the socio-economic challenges India faces are gender inequality, child malnutrition, and rising levels of air pollution. India's land is megadiverse with four biodiversity hotspots. India's wildlife, which has traditionally been viewed with tolerance in its culture, is supported in protected habitats.\n",
            "\n",
            "\n",
            "\n",
            "Page: Pornography in India\n",
            "Summary: Pornography in India is illegal in all forms including print media, electronic media, and digital media (OTT). Hosting, displaying, uploading, modifying, publishing, transmitting, storing, updating or sharing pornography is illegal in India. India's Supreme Court has said that \"OTT regulation is a necessity as some OTT's [such as] ALTT and Ullu show nudity, obscenity and even porn, because of the absence of any proper rules and regulation.\"\n",
            "On 22 August 2023, the Government of India assured that it would bring rules and regulation to check vulgar and obscene content on social media and OTT platforms.\n",
            "On 14 March 2024, the Ministry of Information and Broadcasting banned eighteen OTT apps from the Google Play store and suspended all 57 of their social media accounts, as well as closed 19 streaming websites. The banned platforms are MoodX, Prime Play, Hunters, Besharams, Rabbit movies, Voovi, Fugi, Mojflix, Chikooflix, Nuefliks, Xtramood, Neon X VIP, X Prime, Tri Flicks, Uncut Adda, Dreams Films, Hot Shots VIP, and Yessma.\n",
            "On 25 July 2025, the Ministry banned 25 OTT apps from the Google Play store and all 40 of their social media accounts, as well as closed 26 streaming websites. The banned platforms include ALTT, Ullu, Big Shots App, Desiflix, Boomex, NeonX VIP, Navarasa Lite, Gulab App, Kangan App, Bull App, ShowHit, Jalva App, Wow Entertainment, Look Entertainment, Hitprime, Fugi, Feneo, ShowX, Sol Talkies, Adda TV, HotX VIP, Hulchul App, MoodX, Triflicks, Mojflix.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " You can customize the default tool with its own name, description and so on as follows"
      ],
      "metadata": {
        "id": "LnfMeoXJVn-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an OBJECT (a thing)\n",
        "print(type(wiki_api_wrapper))  \n",
        " Output: <class 'WikipediaAPIWrapper'>\n",
        "\n",
        " This is a METHOD (an action the object can perform)\n",
        "print(type(wiki_api_wrapper.run))  \n",
        " Output: <class 'method'>\n",
        "\n",
        " The Tool needs a callable (something it can execute)\n",
        "func=wiki_api_wrapper.run  # ✓ This is callable - it can be executed\n",
        "func=wiki_api_wrapper      # ✗ This is just an object - can't be executed directly"
      ],
      "metadata": {
        "id": "vpEpzprD5-wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # APIWrapper - wraps the Wikipedia API\n",
        "# wiki_api_wrapper = WikipediaAPIWrapper(...)\n",
        "# wiki_api_wrapper.run(\"Python\")  # Direct usage\n",
        "\n",
        "# # Tool - wraps the APIWrapper for use by LangChain agents\n",
        "# wiki_tool = Tool(\n",
        "#     name=\"Wikipedia\",\n",
        "#     func=wiki_api_wrapper.run,  # Links to the wrapper's run method\n",
        "#     description=\"...\"\n",
        "# )\n",
        "# ```\n",
        "\n",
        "# **The hierarchy:**\n",
        "# ```\n",
        "# Wikipedia API (external service)\n",
        "#     ↓ wrapped by\n",
        "# WikipediaAPIWrapper (handles API calls, parsing)\n",
        "#     ↓ wrapped by\n",
        "# Tool (provides standardized interface for agents)\n",
        "#     ↓ used by\n",
        "# LangChain Agent (can use multiple tools)"
      ],
      "metadata": {
        "id": "HuL96iW_7Hba"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import Tool\n",
        "\n",
        "wiki_tool_init = Tool(name=\"Wikipedia\",\n",
        "                      func=wiki_api_wrapper.run,\n",
        "                      description=\"useful when you need a detailed answer about general knowledge\")"
      ],
      "metadata": {
        "id": "OdQqNgNb6slg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool_init.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZRTfVUuGo7ti",
        "outputId": "be7851f5-ecae-4065-bddd-381465fa23ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'useful when you need a detailed answer about general knowledge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool_init.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW0emMEIou-L",
        "outputId": "bfc24c86-cdb6-4fb0-e4d7-fb0a25d6556b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tool_input': {'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wiki_tool_init.invoke({\"tool_input\": \"Generative AI\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgAwdPrBjk-x",
        "outputId": "9a36e67d-1e9f-45a1-f223-5655001a0d57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: Generative artificial intelligence\n",
            "Summary: Generative artificial intelligence, also known as generative AI or GenAI, is a subfield of artificial intelligence that uses generative models to generate text, images, videos, audio, software code or other forms of data.\n",
            "These models learn the underlying patterns and structures of their training data and use them to generate new data\n",
            "in response to input, which often takes the form of natural language prompts.\n",
            "The generated material is often called AIGC (AI Generated Content).\n",
            "The prevalence of generative AI tools has increased significantly since the AI boom in the 2020s. This boom was made possible by improvements in deep neural networks, particularly large language models (LLMs), which are based on the transformer architecture. Generative AI applications include chatbots such as ChatGPT, Claude, Copilot, DeepSeek, Google Gemini and Grok; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo, LTX and Sora.\n",
            "Companies in a variety of sectors have used generative AI, including those in software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, and product design.  \n",
            "Generative AI has been used for cybercrime, and to deceive and manipulate people through fake news and deepfakes. Generative AI models have been trained on copyrighted works without the rightholders' permission. Many generative AI systems use large-scale data centers whose environmental impacts include e-waste, consumption of fresh water for cooling, and high energy consumption that is estimated to be growing steadily.\n",
            "\n",
            "Page: Generative AI pornography\n",
            "Summary: Generative AI pornography or simply AI pornography is a digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized entirely by AI algorithms. These algorithms, including generative adversarial networks (GANs) and text-to-image models, generate lifelike images, videos, or animations from textual descriptions or datasets.\n",
            "\n",
            "\n",
            "\n",
            "Page: AI boom\n",
            "Summary: An AI boom is a period of rapid growth in the field of artificial intelligence (AI). The most recent boom originally started gradually in the 2010s with the Deep Learning Phase, but saw increased acceleration in the 2020s. Examples of this include generative AI technologies, such as large language models and AI image generators developed by companies like OpenAI, as well as scientific advances, such as protein folding prediction led by Google DeepMind. This period is sometimes referred to as an AI spring, a term used to differentiate it from previous AI winters. As of 2025, ChatGPT has emerged as the 4th-most visited website globally, surpassed only by Google, YouTube, and Facebook.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the Tavily Search Tool\n",
        "\n",
        "Tavily Search API is a search engine optimized for LLMs and RAG, aimed at efficient, quick and persistent search results"
      ],
      "metadata": {
        "id": "cnQfnkQeV7Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=6,\n",
        "                                search_depth='advanced',\n",
        "                                include_raw_content=True)"
      ],
      "metadata": {
        "id": "UjWM95p5pB4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02a6925-22bb-42e1-fdf4-fe4193e2b47a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2814068160.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
            "  tavily_tool = TavilySearchResults(max_results=6,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_tool.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmawzibmjlC6",
        "outputId": "ceced532-692e-4967-9829-73f5c27d5df4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': {'description': 'search query to look up',\n",
              "  'title': 'Query',\n",
              "  'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_tool.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eERoFFoPjlGJ",
        "outputId": "9bfb06df-4f74-492b-91e3-e90069fc839e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tavily_tool.run(\"Python programming\")  # Works directly only string"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7FOFBZva8Aic"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = tavily_tool.invoke(\"Tell me about Model Context Protocol\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khqWQVcvrnG9",
        "outputId": "5e19944b-31b2-40fa-b116-cf18cd3e4f34"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Model Context Protocol (MCP) :: Spring AI Reference',\n",
              "  'url': 'https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html',\n",
              "  'content': '# Model Context Protocol (MCP)\\n\\n|  |  |\\n --- |\\n|  | New to MCP? Start with our Getting Started with MCP guide for a quick introduction and hands-on examples. |\\n\\nThe Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way. Think of it as a bridge between your AI models and the real world - allowing them to access databases, APIs, file systems, and other external services through a consistent interface. It supports multiple transport mechanisms to provide flexibility across different environments.\\n\\nThe MCP Java SDK provides a Java implementation of the Model Context Protocol, enabling standardized interaction with AI models and tools through both synchronous and asynchronous communication patterns. [...] | MCP Server |\\n| The MCP Server is a foundational component in the Model Context Protocol (MCP) architecture that provides tools, resources, and capabilities to clients. It implements the server-side of the protocol, responsible for:   Server-side protocol operations implementation  + Tool exposure and discovery   + Resource management with URI-based access   + Prompt template provision and handling   + Capability negotiation with clients   + Structured logging and notifications  Concurrent client connection management  Synchronous and Asynchronous API support  Transport implementations:  + Stdio, Streamable-HTTP, Stateless Streamable-HTTP, SSE |  | [...] Search in all Spring Docs',\n",
              "  'score': 0.99993026,\n",
              "  'raw_content': '# Model Context Protocol (MCP)\\n\\n|  |  |\\n| --- | --- |\\n|  | **New to MCP?** Start with our [Getting Started with MCP](../../guides/getting-started-mcp.html) guide for a quick introduction and hands-on examples. |\\n\\nThe [Model Context Protocol](https://modelcontextprotocol.org/docs/concepts/architecture) (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way. Think of it as a bridge between your AI models and the real world - allowing them to access databases, APIs, file systems, and other external services through a consistent interface. It supports multiple transport mechanisms to provide flexibility across different environments.\\n\\nThe [MCP Java SDK](https://modelcontextprotocol.io/sdk/java/mcp-overview) provides a Java implementation of the Model Context Protocol, enabling standardized interaction with AI models and tools through both synchronous and asynchronous communication patterns.\\n\\nSpring AI embraces MCP with comprehensive support through dedicated Boot Starters and MCP Java Annotations, making it easier than ever to build sophisticated AI-powered applications that can seamlessly connect to external systems. This means Spring developers can participate in both sides of the MCP ecosystem - building AI applications that consume MCP servers and creating MCP servers that expose Spring-based services to the wider AI community. Bootstrap your AI applications with MCP support using [Spring Initializer](https://start.spring.io).\\n\\n## MCP Java SDK Architecture\\n\\n|  |  |\\n| --- | --- |\\n|  | This section provides an overview for the [MCP Java SDK architecture](https://modelcontextprotocol.io/sdk/java/mcp-overview). For the Spring AI MCP integration, refer to the [Spring AI MCP Boot Starters](#_spring_ai_mcp_integration) documentation. |\\n\\nThe Java MCP implementation follows a three-layer architecture that separates concerns for maintainability and flexibility:\\n\\nFigure 1. MCP Stack Architecture\\n\\n### Client/Server Layer (Top)\\n\\nThe top layer handles the main application logic and protocol operations:\\n\\n* **McpClient** - Manages client-side operations and server connections\\n* **McpServer** - Handles server-side protocol operations and client requests\\n* Both components utilize the session layer below for communication management\\n\\n### Session Layer (Middle)\\n\\nThe middle layer manages communication patterns and maintains connection state:\\n\\n* **McpSession** - Core session management interface\\n* **McpClientSession** - Client-specific session implementation\\n* **McpServerSession** - Server-specific session implementation\\n\\n### Transport Layer (Bottom)\\n\\nThe bottom layer handles the actual message transport and serialization:\\n\\n* **McpTransport** - Manages JSON-RPC message serialization and deserialization\\n* Supports multiple transport implementations (STDIO, HTTP/SSE, Streamable-HTTP, etc.)\\n* Provides the foundation for all higher-level communication\\n\\n| [MCP Client](https://modelcontextprotocol.io/sdk/java/mcp-client) |\\n| The MCP Client is a key component in the Model Context Protocol (MCP) architecture, responsible for establishing and managing connections with MCP servers. It implements the client-side of the protocol, handling:  * Protocol version negotiation to ensure compatibility with servers * Capability negotiation to determine available features * Message transport and JSON-RPC communication * Tool discovery and execution * Resource access and management * Prompt system interactions * Optional features:  + Roots management   + Sampling support * Synchronous and asynchronous operations * Transport options:  + Stdio-based transport for process-based communication   + Java HttpClient-based SSE client transport   + WebFlux SSE client transport for reactive HTTP streaming |  |\\n\\n| [MCP Server](https://modelcontextprotocol.io/sdk/java/mcp-server) |\\n| The MCP Server is a foundational component in the Model Context Protocol (MCP) architecture that provides tools, resources, and capabilities to clients. It implements the server-side of the protocol, responsible for:  * Server-side protocol operations implementation  + Tool exposure and discovery   + Resource management with URI-based access   + Prompt template provision and handling   + Capability negotiation with clients   + Structured logging and notifications * Concurrent client connection management * Synchronous and Asynchronous API support * Transport implementations:  + Stdio, Streamable-HTTP, Stateless Streamable-HTTP, SSE |  |\\n\\nFor detailed implementation guidance, using the low-level MCP Client/Server APIs, refer to the [MCP Java SDK documentation](https://modelcontextprotocol.io/sdk/java/mcp-overview). For simplified setup using Spring Boot, use the MCP Boot Starters described below.\\n\\n## Spring AI MCP Integration\\n\\nSpring AI provides MCP integration through the following Spring Boot starters:\\n\\n### [Client Starters](mcp-client-boot-starter-docs.html)\\n\\n* `spring-ai-starter-mcp-client` - Core starter providing `STDIO`, Servlet-based `Streamable-HTTP`, `Stateless Streamable-HTTP` and `SSE` support\\n* `spring-ai-starter-mcp-client-webflux` - WebFlux-based `Streamable-HTTP`, `Stateless Streamable-HTTP` and `SSE` transport implementation\\n\\n### [Server Starters](mcp-server-boot-starter-docs.html)\\n\\n#### STDIO\\n\\n| Server Type | Dependency | Property |\\n| [Standard Input/Output (STDIO)](mcp-stdio-sse-server-boot-starter-docs.html) | `spring-ai-starter-mcp-server` | `spring.ai.mcp.server.stdio=true` |\\n\\n#### WebMVC\\n\\n| Server Type | Dependency | Property |\\n| [SSE WebMVC](mcp-stdio-sse-server-boot-starter-docs.html#_sse_webmvc_serve) | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=SSE` or empty |\\n| [Streamable-HTTP WebMVC](mcp-streamable-http-server-boot-starter-docs.html#_streamable_http_webmvc_server) | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=STREAMABLE` |\\n| [Stateless Streamable-HTTP WebMVC](mcp-stateless-server-boot-starter-docs.html#_stateless_webmvc_server) | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=STATELESS` |\\n\\n#### WebMVC (Reactive)\\n\\n| Server Type | Dependency | Property |\\n| [SSE WebFlux](mcp-stdio-sse-server-boot-starter-docs.html#_sse_webflux_serve) | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=SSE` or empty |\\n| [Streamable-HTTP WebFlux](mcp-streamable-http-server-boot-starter-docs.html#_streamable_http_webflux_server) | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=STREAMABLE` |\\n| [Stateless Streamable-HTTP WebFlux](mcp-stateless-server-boot-starter-docs.html#_stateless_webflux_server) | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=STATELESS` |\\n\\n## [Spring AI MCP Annotations](mcp-annotations-overview.html)\\n\\nIn addition to the programmatic MCP client & server configuration, Spring AI provides annotation-based method handling for MCP servers and clients through the [MCP Annotations](mcp-annotations-overview.html) module. This approach simplifies the creation and registration of MCP operations using a clean, declarative programming model with Java annotations.\\n\\nThe MCP Annotations module enables developers to:\\n\\n* Create MCP tools, resources, and prompts using simple annotations\\n* Handle client-side notifications and requests declaratively\\n* Reduce boilerplate code and improve maintainability\\n* Automatically generate JSON schemas for tool parameters\\n* Access special parameters and context information\\n\\nKey features include:\\n\\n* [Server Annotations](mcp-annotations-server.html): `@McpTool`, `@McpResource`, `@McpPrompt`, `@McpComplete`\\n* [Client Annotations](mcp-annotations-client.html): `@McpLogging`, `@McpSampling`, `@McpElicitation`, `@McpProgress`\\n* [Special Parameters](mcp-annotations-special-params.html): `McpSyncServerExchange`, `McpAsyncServerExchange`, `McpTransportContext`, `McpMeta`\\n* **Automatic Discovery**: Annotation scanning with configurable package inclusion/exclusion\\n* **Spring Boot Integration**: Seamless integration with MCP Boot Starters\\n\\n## Additional Resources\\n\\n* [MCP Annotations Documentation](mcp-annotations-overview.html)\\n* [MCP Client Boot Starters Documentation](mcp-client-boot-starter-docs.html)\\n* [MCP Server Boot Starters Documentation](mcp-server-boot-starter-docs.html)\\n* [MCP Utilities Documentation](mcp-helpers.html)\\n* [Model Context Protocol Specification](https://modelcontextprotocol.github.io/specification/)\\n\\n* [Spring AI](../../index.html)\\n\\n  + [1.1.2](../../index.html)\\n  + [1.0.3](../../1.0/index.html)\\n\\n  + [2.0.0-M2](../../2.0/index.html)\\n\\n  + [2.0.0-SNAPSHOT](../../2.0-SNAPSHOT/index.html)\\n  + [1.1.3-SNAPSHOT](../../1.1-SNAPSHOT/index.html)\\n\\n* Related Spring Documentation\\n  + [Spring Boot](https://docs.spring.io/spring-boot/)\\n  + [Spring Framework](https://docs.spring.io/spring-framework/reference/)\\n  + Spring Cloud\\n    - [Spring Cloud Build](https://docs.spring.io/spring-cloud-build/reference/)\\n    - [Spring Cloud Bus](https://docs.spring.io/spring-cloud-bus/reference/)\\n    - [Spring Cloud Circuit Breaker](https://docs.spring.io/spring-cloud-circuitbreaker/reference/)\\n    - [Spring Cloud Commons](https://docs.spring.io/spring-cloud-commons/reference/)\\n    - [Spring Cloud Config](https://docs.spring.io/spring-cloud-config/reference/)\\n    - [Spring Cloud Consul](https://docs.spring.io/spring-cloud-consul/reference/)\\n    - [Spring Cloud Contract](https://docs.spring.io/spring-cloud-contract/reference/)\\n    - [Spring Cloud Function](https://docs.spring.io/spring-cloud-function/reference/)\\n    - [Spring Cloud Gateway](https://docs.spring.io/spring-cloud-gateway/reference/)\\n    - [Spring Cloud Kubernetes](https://docs.spring.io/spring-cloud-kubernetes/reference/)\\n    - [Spring Cloud Netflix](https://docs.spring.io/spring-cloud-netflix/reference/)\\n    - [Spring Cloud OpenFeign](https://docs.spring.io/spring-cloud-openfeign/reference/)\\n    - [Spring Cloud Stream](https://docs.spring.io/spring-cloud-stream/reference/)\\n    - [Spring Cloud Task](https://docs.spring.io/spring-cloud-task/reference/)\\n    - [Spring Cloud Vault](https://docs.spring.io/spring-cloud-vault/reference/)\\n    - [Spring Cloud Zookeeper](https://docs.spring.io/spring-cloud-zookeeper/reference/)\\n  + Spring Data\\n    - [Spring Data Cassandra](https://docs.spring.io/spring-data/cassandra/reference/)\\n    - [Spring Data Commons](https://docs.spring.io/spring-data/commons/reference/)\\n    - [Spring Data Couchbase](https://docs.spring.io/spring-data/couchbase/reference/)\\n    - [Spring Data Elasticsearch](https://docs.spring.io/spring-data/elasticsearch/reference/)\\n    - [Spring Data JPA](https://docs.spring.io/spring-data/jpa/reference/)\\n    - [Spring Data KeyValue](https://docs.spring.io/spring-data/keyvalue/reference/)\\n    - [Spring Data LDAP](https://docs.spring.io/spring-data/ldap/reference/)\\n    - [Spring Data MongoDB](https://docs.spring.io/spring-data/mongodb/reference/)\\n    - [Spring Data Neo4j](https://docs.spring.io/spring-data/neo4j/reference/)\\n    - [Spring Data Redis](https://docs.spring.io/spring-data/redis/reference/)\\n    - [Spring Data JDBC & R2DBC](https://docs.spring.io/spring-data/relational/reference/)\\n    - [Spring Data REST](https://docs.spring.io/spring-data/rest/reference/)\\n  + [Spring Integration](https://docs.spring.io/spring-integration/reference/)\\n  + [Spring Batch](https://docs.spring.io/spring-batch/reference/)\\n  + [Spring Security](https://docs.spring.io/spring-security/reference/) \\n    - [Spring Authorization Server](https://docs.spring.io/spring-authorization-server/reference/)\\n    - [Spring LDAP](https://docs.spring.io/spring-ldap/reference/)\\n    - [Spring Security Kerberos](https://docs.spring.io/spring-security-kerberos/reference/)\\n    - [Spring Session](https://docs.spring.io/spring-session/reference/)\\n    - [Spring Vault](https://docs.spring.io/spring-vault/reference/)\\n  + [Spring AI](https://docs.spring.io/spring-ai/reference/)\\n  + [Spring AMQP](https://docs.spring.io/spring-amqp/reference/)\\n  + [Spring CLI](https://docs.spring.io/spring-cli/reference/)\\n  + [Spring GraphQL](https://docs.spring.io/spring-graphql/reference/)\\n  + [Spring for Apache Kafka](https://docs.spring.io/spring-kafka/reference/)\\n  + [Spring Modulith](https://docs.spring.io/spring-modulith/reference/)\\n  + [Spring for Apache Pulsar](https://docs.spring.io/spring-pulsar/reference/)\\n  + [Spring Shell](https://docs.spring.io/spring-shell/reference/)\\n[All Docs...](../../spring-projects.html)\\n\\n[Search in all Spring Docs](../../search.html)\\n\\n '},\n",
              " {'title': 'Introducing the Model Context Protocol',\n",
              "  'url': 'https://www.anthropic.com/news/model-context-protocol',\n",
              "  'content': 'MCP addresses this challenge. It provides a universal, open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. The result is a simpler, more reliable way to give AI systems access to the data they need.\\n\\nModel Context Protocol\\n\\nThe Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools. The architecture is straightforward: developers can either expose their data through MCP servers or build AI applications (MCP clients) that connect to these servers.\\n\\nToday, we\\'re introducing three major components of the Model Context Protocol for developers: [...] Early adopters like Block and Apollo have integrated MCP into their systems, while development tools companies including Zed, Replit, Codeium, and Sourcegraph are working with MCP to enhance their platforms—enabling AI agents to better retrieve relevant information to further understand the context around a coding task and produce more nuanced and functional code with fewer attempts. [...] \"At Block, open source is more than a development model—it’s the foundation of our work and a commitment to creating technology that drives meaningful change and serves as a public good for all,” said Dhanji R. Prasanna, Chief Technology Officer at Block. “Open technologies like the Model Context Protocol are the bridges that connect AI to real-world applications, ensuring innovation is accessible, transparent, and rooted in collaboration. We are excited to partner on a protocol and use it to build agentic systems, which remove the burden of the mechanical so people can focus on the creative.”',\n",
              "  'score': 0.9999138,\n",
              "  'raw_content': '[Skip to main content](https://www.anthropic.com/news/model-context-protocol#main-content)[Skip to footer](https://www.anthropic.com/news/model-context-protocol#footer)\\n\\n[](https://www.anthropic.com/)\\n\\n*   [Research](https://www.anthropic.com/research)\\n*   [Economic Futures](https://www.anthropic.com/economic-futures)\\n*   Commitments\\n*   Learn\\n*   [News](https://www.anthropic.com/news)\\n\\n[Try Claude](https://claude.ai/)\\n\\nAnnouncements\\n\\nIntroducing the Model Context Protocol\\n======================================\\n\\nNov 25, 2024\\n\\nToday, we\\'re open-sourcing the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses.\\n\\nAs AI assistants gain mainstream adoption, the industry has invested heavily in model capabilities, achieving rapid advances in reasoning and quality. Yet even the most sophisticated models are constrained by their isolation from data—trapped behind information silos and legacy systems. Every new data source requires its own custom implementation, making truly connected systems difficult to scale.\\n\\nMCP addresses this challenge. It provides a universal, open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. The result is a simpler, more reliable way to give AI systems access to the data they need.\\n\\nModel Context Protocol\\n----------------------\\n\\nThe Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools. The architecture is straightforward: developers can either expose their data through MCP servers or build AI applications (MCP clients) that connect to these servers.\\n\\nToday, we\\'re introducing three major components of the Model Context Protocol for developers:\\n\\n*   The Model Context Protocol [specification and SDKs](https://github.com/modelcontextprotocol)\\n*   Local MCP server support in the [Claude Desktop apps](https://claude.ai/redirect/website.v1.48d80cdd-9dbf-43b1-b7a9-ece6ccbe684b/download)\\n*   An [open-source repository](https://github.com/modelcontextprotocol/servers) of MCP servers\\n\\nClaude 3.5 Sonnet is adept at quickly building MCP server implementations, making it easy for organizations and individuals to rapidly connect their most important datasets with a range of AI-powered tools. To help developers start exploring, we’re sharing pre-built MCP servers for popular enterprise systems like Google Drive, Slack, GitHub, Git, Postgres, and Puppeteer.\\n\\nEarly adopters like Block and Apollo have integrated MCP into their systems, while development tools companies including Zed, Replit, Codeium, and Sourcegraph are working with MCP to enhance their platforms—enabling AI agents to better retrieve relevant information to further understand the context around a coding task and produce more nuanced and functional code with fewer attempts.\\n\\n\"At Block, open source is more than a development model—it’s the foundation of our work and a commitment to creating technology that drives meaningful change and serves as a public good for all,” said Dhanji R. Prasanna, Chief Technology Officer at Block. “Open technologies like the Model Context Protocol are the bridges that connect AI to real-world applications, ensuring innovation is accessible, transparent, and rooted in collaboration. We are excited to partner on a protocol and use it to build agentic systems, which remove the burden of the mechanical so people can focus on the creative.”\\n\\nInstead of maintaining separate connectors for each data source, developers can now build against a standard protocol. As the ecosystem matures, AI systems will maintain context as they move between different tools and datasets, replacing today\\'s fragmented integrations with a more sustainable architecture.\\n\\nGetting started\\n---------------\\n\\nDevelopers can start building and testing MCP connectors today. All [Claude.ai](http://claude.ai/redirect/website.v1.48d80cdd-9dbf-43b1-b7a9-ece6ccbe684b) plans support connecting MCP servers to the Claude Desktop app.\\n\\nClaude for Work customers can begin testing MCP servers locally, connecting Claude to internal systems and datasets. We\\'ll soon provide developer toolkits for deploying remote production MCP servers that can serve your entire Claude for Work organization.\\n\\nTo start building:\\n\\n*   Install pre-built MCP servers through the [Claude Desktop app](https://claude.ai/redirect/website.v1.48d80cdd-9dbf-43b1-b7a9-ece6ccbe684b/download)\\n*   Follow our [quickstart guide](https://modelcontextprotocol.io/quickstart) to build your first MCP server\\n*   Contribute to our [open-source repositories](https://github.com/modelcontextprotocol) of connectors and implementations\\n\\nAn open community\\n-----------------\\n\\nWe’re committed to building MCP as a collaborative, open-source project and ecosystem, and we’re eager to hear your feedback. Whether you’re an AI tool developer, an enterprise looking to leverage existing data, or an early adopter exploring the frontier, we invite you to build the future of context-aware AI together.\\n\\n[](https://twitter.com/intent/tweet?text=https://www.anthropic.com/news/model-context-protocol)[](https://www.linkedin.com/shareArticle?mini=true&url=https://www.anthropic.com/news/model-context-protocol)\\n\\nRelated content\\n---------------\\n\\n### Anthropic partners with Allen Institute and Howard Hughes Medical Institute to accelerate scientific discovery\\n\\n[Read more](https://www.anthropic.com/news/anthropic-partners-with-allen-institute-and-howard-hughes-medical-institute)\\n\\n### ServiceNow chooses Claude to power customer apps and increase internal productivity\\n\\n[Read more](https://www.anthropic.com/news/servicenow-anthropic-claude)\\n\\n### Anthropic partners with the UK Government to bring AI assistance to GOV.UK services\\n\\n[Read more](https://www.anthropic.com/news/gov-UK-partnership)\\n\\n[](https://www.anthropic.com/)\\n\\n### Products\\n\\n*   [Claude](https://claude.com/product/overview)\\n*   [Claude Code](https://claude.com/product/claude-code)\\n*   [Cowork](https://claude.com/product/cowork)\\n*   [Claude in Chrome](https://claude.com/chrome)\\n*   [Claude in Excel](https://claude.com/claude-in-excel)\\n*   [Claude in Slack](https://claude.com/claude-in-slack)\\n*   [Skills](https://www.claude.com/skills)\\n*   [Max plan](https://claude.com/pricing/max)\\n*   [Team plan](https://claude.com/pricing/team)\\n*   [Enterprise plan](https://claude.com/pricing/enterprise)\\n*   [Download app](https://claude.ai/download)\\n*   [Pricing](https://claude.com/pricing)\\n*   [Log in to Claude](https://claude.ai/)\\n\\n### Models\\n\\n*   [Opus](https://www.anthropic.com/claude/opus)\\n*   [Sonnet](https://www.anthropic.com/claude/sonnet)\\n*   [Haiku](https://www.anthropic.com/claude/haiku)\\n\\n### Solutions\\n\\n*   [AI agents](https://claude.com/solutions/agents)\\n*   [Code modernization](https://claude.com/solutions/code-modernization)\\n*   [Coding](https://claude.com/solutions/coding)\\n*   [Customer support](https://claude.com/solutions/customer-support)\\n*   [Education](https://claude.com/solutions/education)\\n*   [Financial services](https://claude.com/solutions/financial-services)\\n*   [Government](https://claude.com/solutions/government)\\n*   [Healthcare](https://claude.com/solutions/healthcare)\\n*   [Life sciences](https://claude.com/solutions/life-sciences)\\n*   [Nonprofits](https://claude.com/solutions/nonprofits)\\n\\n### Claude Developer Platform\\n\\n*   [Overview](https://claude.com/platform/api)\\n*   [Developer docs](https://platform.claude.com/docs)\\n*   [Pricing](https://claude.com/pricing#api)\\n*   [Regional Compliance](https://claude.com/regional-compliance)\\n*   [Amazon Bedrock](https://claude.com/partners/amazon-bedrock)\\n*   [Google Cloud’s Vertex AI](https://claude.com/partners/google-cloud-vertex-ai)\\n*   [Console login](https://platform.claude.com/)\\n\\n### Learn\\n\\n*   [Blog](https://claude.com/blog)\\n*   [Claude partner network](https://claude.com/partners)\\n*   [Connectors](https://claude.com/connectors)\\n*   [Courses](https://www.anthropic.com/learn)\\n*   [Customer stories](https://claude.com/customers)\\n*   [Engineering at Anthropic](https://www.anthropic.com/engineering)\\n*   [Events](https://www.anthropic.com/events)\\n*   [Plugins](https://claude.com/plugins)\\n*   [Powered by Claude](https://claude.com/partners/powered-by-claude)\\n*   [Service partners](https://claude.com/partners/services)\\n*   [Startups program](https://claude.com/programs/startups)\\n*   [Tutorials](https://claude.com/resources/tutorials)\\n*   [Use cases](https://claude.com/resources/use-cases)\\n\\n### Company\\n\\n*   [Anthropic](https://www.anthropic.com/company)\\n*   [Careers](https://www.anthropic.com/careers)\\n*   [Economic Futures](https://www.anthropic.com/economic-index)\\n*   [Research](https://www.anthropic.com/research)\\n*   [News](https://www.anthropic.com/news)\\n*   [Claude’s Constitution](https://www.anthropic.com/constitution)\\n*   [Responsible Scaling Policy](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy)\\n*   [Security and compliance](https://trust.anthropic.com/)\\n*   [Transparency](https://www.anthropic.com/transparency)\\n\\n### Help and security\\n\\n*   [Availability](https://www.anthropic.com/supported-countries)\\n*   [Status](https://status.anthropic.com/)\\n*   [Support center](https://support.claude.com/en/)\\n\\n### Terms and policies\\n\\nPrivacy choices*   [Privacy policy](https://www.anthropic.com/legal/privacy)\\n*   [Consumer health data privacy policy](https://www.anthropic.com/legal/consumer-health-data-privacy-policy)\\n*   [Responsible disclosure policy](https://www.anthropic.com/responsible-disclosure-policy)\\n*   [Terms of service: Commercial](https://www.anthropic.com/legal/commercial-terms)\\n*   [Terms of service: Consumer](https://www.anthropic.com/legal/consumer-terms)\\n*   [Usage policy](https://www.anthropic.com/legal/aup)\\n\\n© 2025 Anthropic PBC\\n*   [](https://www.linkedin.com/company/anthropicresearch)\\n*   [](https://x.com/AnthropicAI)\\n*   [](https://www.youtube.com/@anthropic-ai)\\n\\nIntroducing the Model Context Protocol \\\\ Anthropic\\n==============='},\n",
              " {'title': 'Model Context Protocol (MCP), clearly explained (why it ...',\n",
              "  'url': 'https://www.youtube.com/watch?v=7j_NE6Pjv-E',\n",
              "  'content': \"819 comments\\n### Transcript: [...] Timestamps:\\n00:00 - Intro\\n02:26 - The Evolution of LLMs: From Text Prediction to Tool Use\\n07:39 - MCPs explained\\n10:59 - MCP Ecosystem Overview\\n13:47 - Technical Challenges of MCP\\n15:05 - Conclusion on MCP's Potential\\n15:48 - Startup Ideas for Developers and Non-Technical Users\\n\\nKey Points:\\n\\n• MCP (Model ContextProtocol) is a standard that creates a unified layer between LLMs and external services/tools\\n• LLMs by themselves are limited to text prediction and cannot perform meaningful tasks without tools\\n• MCP solves the problem of connecting multiple tools to LLMs by creating a standardized communication protocol\\n• The MCP ecosystem consists of clients (like Tempo, Windsurf, Cursor), the protocol, servers, and services\\n\\n1) What are MCPs and why should you care? [...] language so tool one's English tool two is Spanish tool three is Japanese right and imagine every tool it's its own language and it's not that there isn't a standard for how apis work but every service provider constructs their apis differently there's different information you have to pass there's just various degree of of of of things that you have to set up that again it just feels like gluing a bunch of different things together will it work yes but at scale it gets very diff difficult mCP you can consider it to be a layer between your llm and the services and the tools and this layer translates all those different languages into a unified language that makes complete sense to the llm right so it's the evolution of llm plus tools but in this Evolution it just makes it makes it very\",\n",
              "  'score': 0.9998746,\n",
              "  'raw_content': '# Model Context Protocol (MCP), clearly explained (why it matters)\\n## Greg Isenberg\\n524000 subscribers\\n29179 likes\\n\\n### Description\\n1215140 views\\nPosted: 14 Mar 2025\\nFor startup ideas, trends and prompts to build them join https://Ideabrowser.com....I’m joined by Ras Mic to explain Model Context Protocol (MCP). Mic breaks down how MCPs essentially standardize  how LLMs connect with external tools and services. While LLMs alone can only predict text, connecting them to tools makes them more capable, but this integration has been cumbersome. MCPs create a unified layer that translates between LLMs and services, making it easier to build more powerful AI assistants.\\n\\nTimestamps:\\n00:00 - Intro\\n02:26 - The Evolution of LLMs: From Text Prediction to Tool Use\\n07:39 - MCPs explained\\n10:59 - MCP Ecosystem Overview\\n13:47 - Technical Challenges of MCP\\n15:05 - Conclusion on MCP\\'s Potential\\n15:48 - Startup Ideas for Developers and Non-Technical Users\\n\\nKey Points:\\n\\n• MCP (Model ContextProtocol) is a standard that creates a unified layer between LLMs and external services/tools\\n• LLMs by themselves are limited to text prediction and cannot perform meaningful tasks without tools\\n• MCP solves the problem of connecting multiple tools to LLMs by creating a standardized communication protocol\\n• The MCP ecosystem consists of clients (like Tempo, Windsurf, Cursor), the protocol, servers, and services\\n\\n1) What are MCPs and why should you care?\\n\\nMCPs are NOT some complex physics theory - they\\'re simply STANDARDS that help LLMs connect to external tools and services.\\n\\nThink of them as universal translators between AI models and the tools they need to be truly useful.\\n\\nThis is HUGE for making AI assistants actually capable!\\n\\n2) The Evolution of LLMs: From Text Prediction to Tool Use\\n\\nStage 1: Basic LLMs can only predict text\\n• Ask ChatGPT to send an email? \"Sorry, I can\\'t do that\"\\n• They\\'re glorified text predictors (if I say \"My big fat Greek...\" it knows \"wedding\" comes next)\\n• Limited to answering questions, not DOING things\\n\\n3) The Current State: LLMs + Tools\\n\\nStage 2: LLMs connected to tools\\n• Companies like Perplexity connect LLMs to search engines\\n• This makes them more useful but creates problems\\n• Each tool = different \"language\" the LLM must learn\\n• Connecting multiple tools = engineering NIGHTMARE\\n\\nThis is why we don\\'t have Jarvis-level assistants yet! \\n\\n4) Enter MCPs: The Game-Changer\\n\\nMCPs create a UNIFIED LAYER between LLMs and external services.\\n\\nInstead of your AI speaking 10 different \"languages\" to use 10 different tools, MCPs translate everything into ONE language.\\n\\nResult? LLMs can easily access databases, APIs, and services without massive engineering headaches.\\n\\n5) The MCP Ecosystem Explained\\n\\nThe MCP system has 4 key components:\\n\\n• MCP Client: User-facing apps like @tempoai, Windsurf, Cursor\\n• Protocol: The standardized communication method\\n• MCP Server: Translates between client and services\\n• Service: The actual tool (database, search engine, etc.)\\n\\nBrilliant move by Anthropic: SERVICES must build MCP servers!\\n\\n6) Why This Matters For Builders\\n\\nFor technical folks:\\n• Opportunity to build tools like MCP app stores\\n• Easier integration between services\\n• Less engineering headaches\\n\\nFor non-technical folks:\\n• Watch closely as standards evolve\\n• When standards finalize, new business opportunities will emerge\\n• Think of MCPs as Lego pieces you\\'ll stack to build powerful AI apps\\n\\nNotable Quotes:\\n\\n\"LLMs by themselves are incapable of doing anything meaningful... The only thing an LLM in its current state is good at is predicting the next text.\" - Ross Mike\\n\\n\"Think of every tool that I have to connect to make my LLM valuable as a different language... MCP, you can consider it to be a layer between your LLM and the services and the tools.\" - Ross Mike\\n\\nLCA helps Fortune 500s and fast-growing startups build their future - from Warner Music to Fortnite to Dropbox. We turn \\'what if\\' into reality with AI, apps, and next-gen products https://latecheckout.agency/\\n\\nBoringAds — ads agency that will build you profitable ad campaigns http://boringads.com/\\n\\nBoringMarketing — SEO agency and tools to get your organic customers http://boringmarketing.com/\\n\\nStartup Empire — a membership for builders who want to build cash-flowing businesses https://www.startupempire.co\\n\\nFIND ME ON SOCIAL\\n\\nX/Twitter: https://twitter.com/gregisenberg\\nInstagram: https://instagram.com/gregisenberg/\\nLinkedIn: https://www.linkedin.com/in/gisenberg/\\n\\nFIND MIC ON SOCIAL\\n\\nX/Twitter: https://x.com/rasmickyy\\nYoutube: https://www.youtube.com/@rasmic\\n\\n819 comments\\n### Transcript:\\neveryone is talking about mcps it\\'s gone completely viral but the reality is most people have no idea what mcps are and what they mean and what are the startup opportunities associated with it so in this episode I brought Professor Ross Mike who is probably the the best explainer of technical Concepts in a really easy way that someone who\\'s non-technical can really understand I brought him on he explains it beautifully in such a short amount of time and if you stick to the end you\\'ll hear a couple of his startup ideas that incorporate mcps so um enjoy the episode and see you [Music] soon all right well we got Professor Ross Mike on the Pod um and the reason why we have him is because I don\\'t know what the hell mcps are and I\\'ve been seeing it on X and I need a succinct clear Professor Ross Mike explanation um yes I\\'ve read a bunch of threads on it and I\\'ve seen a couple videos on it but there\\'s nothing like a Ross mic explanation so I\\'m here for the what do I need to know about mcps and that\\'s that\\'s what that\\'s why you\\'re here thank you for coming on I I I appreciate that thank you very much yeah class is definitely in session I\\'ll just start um sharing my screen okay so understanding mCP um is really um important uh but you\\'ll also realize the benefits and why it\\'s sort of a big deal but not really at the same time you see one of the things in programming land that we have and that programmers love are standards and the reason why standards are important is they allow for us Engineers to build systems that communicate with each other the most popular one that you know you might have heard of or you might not and you don\\'t really need to know the details is rest rest apis and they\\'re basically a standard that every company follows when they construct their apis when they construct their services for me as an engineer to be able to connect with them now understanding that engineering is all about standards and having these formalities we follow to make life easier when we think of in the context of an llm I want you to understand this one important thing llms by themselves are incapable of doing anything meaningful what do I mean by that if you remember the first you know chat gbt 3 or was it 3.5 I\\'m not sure but if you just open any chat bot and you tell it to send you an email um it won\\'t know how to do that it will just tell you hey I can\\'t send you an email the most you can do with an llm is ask it questions uh maybe ask it to tell you about some historical figure whatever it may be right um llms are truly incapable of doing anything uh meaningful and what I mean by meaningful it\\'d be nice if you know it could send me an email um if it could um do some specific task on my behalf but the only thing an llm in its current state is good at is predicting the next text right so for example if I say My Big Fat Greek and llm with all the data source with all its training material will determine that the next word is wedding right so this is the most an llm by itself that it could do right the next Evolution was developers figured out how to take llms and combine them with tools and you can think of a tool like an API for example um most of us are aware where chat gbt and these other chat Bots are able to search the internet for example perplexity right perplexity gives you the option to chat with an llm but that llm has the ability to fetch um information from the internet and present that to you the llm itself is not capable of doing that but what they\\'ve done is they\\'ve constructed a tool they\\'ve given the llm access to an external service right and there\\'s plenty of these Services right I think there\\'s Brave search um chat open AI offers an API now so llms have started to become a bit more powerful when we connected tools to them right I can give you an example let\\'s say um let\\'s say every time I get an email I want there to be an entry in a spreadsheet now most of you know there are services like zapier end8 or you know any of those Automation Services if I build out an autom and connect that to my llm it just became a bit more meaningful now that\\'s awesome and cool but it gets really frustrating when you want to build an assistant that does multiple things imagine search the internet um read your emails summarize this you start to become someone who glues a bunch of different tools to these llms and it can get very frustrating very cumbersome if you\\'re wondering why we don\\'t have have an Iron Man level Jarvis assistant is because combining these tools making it work with the llm is one thing but then stacking these tools on top of each other making it cohesive making it work together is a nightmare itself and this is where we\\'re currently at and does before I continue does this make sense this is where we started llms by themselves write me a poem um you know tell me about World War I um and then the second evolution is oh we now have tools right we now have um these things these external services that we can connect to our llm the problem here is they\\'re difficult it\\'s annoying and as someone who works at an AI startup Tempo and we have a lot of tools like for example we do a search um you have to find an external service you have to connect it to the llm and you have to make sure the llm doesn\\'t hallucinate or do something stupid and believe it or not as cool as llms are by themselves they\\'re very very dumb um but these tools make them just a bit more capable so this is where we\\'re at uh Greg we good so far crystal clear I\\'m loving this beautiful quick break in the Pod to tell you a little bit about startup Empire so startup Empire is my private membership where it\\'s a bunch of people like me like you who want to build out their startup ideas now they\\'re looking for content to help accelerate that they\\'re looking for potential co-founders they\\'re looking for uh tutorials from people like me to come in and tell them how do you do email marketing how do you build an audience how do you go viral on Twitter all these different things that\\'s exactly what startup Empire is and it\\'s for people who want to start a startup but are looking for ideas or it\\'s for people who have a startup but just they\\'re not seeing the traction uh that they need so you can check out the link to Startup empire.co in the description now enters mCP and what does mCP mean I think the simplest way right without getting too technicals I\\'ve read the threads too and as a technical person I appreciate it but for the non- Tey I can assume it\\'s frustrating think of it this way think of every tool that I have to connect to to make my llm valuable um as a different language so tool one\\'s English tool two is Spanish tool three is Japanese right and imagine every tool it\\'s its own language and it\\'s not that there isn\\'t a standard for how apis work but every service provider constructs their apis differently there\\'s different information you have to pass there\\'s just various degree of of of of things that you have to set up that again it just feels like gluing a bunch of different things together will it work yes but at scale it gets very diff difficult mCP you can consider it to be a layer between your llm and the services and the tools and this layer translates all those different languages into a unified language that makes complete sense to the llm right so it\\'s the evolution of llm plus tools but in this Evolution it just makes it makes it very simple for the llm to connect and to access different outside resources right because that\\'s what tools are at the end of the day so with mCP I\\'m able to connect to an outside data source an outside database maybe um a tool like uh convex or superbase right um imagine I I just tell the llm you know what create me a new entry in my database and it it\\'s connected to my database via mCP and it knows exactly what to do and how to do in the second evolution llms and tools there\\'s a lot of manual work that goes on there\\'s a lot of stepbystep planning that you have to do and there\\'s a lot of edge cases where it can fail and this is why again none of us as exciting as the space is none of us have a Jarvis level assistant yet it feels like we\\'re there and we\\'re close but this system makes it so that it\\'s very diff and what\\'s frustrating is this imagine let me think of a simple service a simple like you know tool imagine um every time a slack message comes your llm reads that slack message and it shoots you a text right sounds pretty trivial here\\'s the frustrating part imagine slack updates their API or the text service updates makes a change and let\\'s say that service is connected to other services or you have some sort of like automation step-by-step thing that you\\'ve planned it becomes a nightmare it becomes terrifying and this is why even in the age of llms good Engineers will still get paid because stuff like this like this exists but what mCP does it unifies the llm and the service right it creates this this uh layer where the service and the llm can communicate efficiently now let\\'s get into some practicality you can think of the mCP ecosystem as follows you have an mCP client you have the protocol you have an mCP server and you have a service right an mCP client is something like Tempo wind surf cursor and they are basically the client facing side the llm facing side of this ecosystem the protocol again is that two-way connection between the client and the server and the server is what translate translates that external service its capabilities and what it can do to the client and that\\'s why between the mCP client and the mCP server there\\'s the mCP protocol but here\\'s the fascinating part and this is why I think anthropic they\\'re playing 3D chess when they built this is the way this is architected the mCP server is now in the hands of the service provider so if let\\'s say me and Greg run a Dev Tool company right where maybe we\\'re doing a database right like we\\'re like listen we\\'re going to build the best database company in the world and we want people\\'s llms to have access to this database it is now on us to construct this mCP server so that the client can fully access this so anthropic in a way sort of said listen we want our llms to be more powerful more capable uh but it\\'s your job to figure this out and this is why you\\'ve noticed all the external service providers are now building different mCP servers they\\'re building out repos and all this stuff right so this is a big deal in a sense where llms are going to be more capable but from a technological perspective all they did was create a standard a standard that it seems like all companies and all Engineers are going to upon because you can construct any system any API however you please the problem is if you want to scale you want to grow you want other developers other businesses to connect and work with your service it has to be in a fashion that makes sense for them imagine if all of us just spoke different languages but standards allow us to communicate in a way that makes sense to all of us and mCP is that for llms because llms by themselves are not that capable they\\'re just they\\'re they\\'re they\\'re they\\'re systems that have great predictability and they know how to predict the next word but when you can when you add this mCP protocol as a whole you now have a way for it to be capable of doing important stuff now understanding all this it\\'s not all sunshine and rainbows there are some technical challenges if you notice if anyone has set up an mCP um server on any of their favorite mCP clients it\\'s annoying um there\\'s a lot of downloading you have to move this file you have to copy this that and the third um and it\\'s a lot of local stuff there are some Kinks that have to be figured out uh but once this is figured out or finalized polished or maybe they update the standard or maybe someone comes up with a better one we start to enter a world where llms start to become more capable and that is literally all what mCP is just making llms more capable we\\'re trying we\\'re doing that with tools right now it\\'s kind of working um but mCP seems to be the next Evolution I think Greg I saw your latest video um Manis Manis is a great example of number two they have tons of tools and kudos to them they\\'ve engineer engineered it well in a way where you know they well they work well cohesively I didn\\'t get to try it out so I\\'m just looking at what people have done but I can tell you this it\\'s a lot lot of engineering hours it\\'s a lot of one change happens something broke someone\\'s on call and not sleeping but with mCP um it\\'s structured in a way where um if we all follow this um standard um the llm will have access to everything it needs um and we will all be happy users so in short that is literally all what mCP is it\\'s not um Einstein\\'s fifth law of physics or anything crazy like that it\\'s literally standard for llms and it\\'s exciting it\\'s something to be excited about um and yeah I hope I hope that clarified I just kept ramling so I apologize for that gr no no this is this is exactly what I wanted I want to end on one question for you so this is now clear to me crystal clear to me what mcps are but my question is well before I even ask my question every time there\\'s been a popularized protocol for example https or uh SMTP um examples like that there\\'s been a lot of big businesses that were created on top of it and there\\'s been basically this like why now you know why this just opening of opportunities yeah the average person listening to this podcast is building out their ideas is this does this matter or you at all for that person like yeah I think that\\'s a great question I think if I were so I\\'ll speak to the technical and the non- technical to the technical there\\'s a lot of things that a technical person can do here I I just don\\'t have time Greg but one thing I was thinking of was like an mCP App Store and I\\'ll just give this idea out for free because this this podcast is all about ideas basically there\\'s a lot of these repos out there um of mCP servers and it\\'d be cool if someone can go on a site I even bought the domain um it does nothing but again please anybody like steal this idea um um I bought the domain and it\\'d be cool if someone could um go on U like look at the different mCP servers there they they see the GitHub code and whatever and they can click like install or deploy and they that server is deployed and gives them a specific URL and then they can paste that in an mCP client and work that out so for the technical person if you make millions all I ask is just you know send me ,000 but for the non-technical person what I would really focus on is I would just stay up to date with the platforms that are building out mCP capability and just see where the standards are going right because like you said um when these standards are finalized I don\\'t know if mCP has fully won I think it needs to be challenged um or I don\\'t know if anthropic is going to make an update we don\\'t know it\\'s very early but I would say keep very close attention to what the final standard is going to be because once that standard is finalized and all these service providers start to like you know build out their mCP or whatever thing it is you can now start to integrate much seamlessly and much easier right this is why again every week There\\'s a new chatbot interface with new tools and it wins because this part step number two is not easy right especially making it cohesive and making it work fast right like I can sit in two hours and build something like this but building out that user experience making it Flawless limiting the hallucinations it\\'s very very hard I mean this is a lot of the work we do at Tempo but this makes it so that integrating is a lot easier and you can think of these as like Lego pieces that you can continue to stack to stack so for my smart and wise business owners startup uh ideas podcast enjoyers I would really just keep a close attention right I think even for myself I don\\'t think with this mCP stuff we\\'re at a place where any shots can be fired that make um any smart business decision but this is one of those things where you just you sit and you watch and you\\'re just observing and learning and when the right thing at the right time happens you strike so I don\\'t see any crazy business opportunities right now for a non-technical person even for a technical person like imagine if open AI comes with a standard tomorrow and we all just shift to that right it\\'s very early stages but I think understanding how this works means you\\'ll understand how the next thing works and when that becomes fin finalized you hit the ground running amen all right Ross Mike Professor Ross Mike there\\'s no one like you we\\'ll include in the show notes where you can follow him for more really clear explanations around this whole AI coding world and uh dude I\\'ll see you in Miami in a few weeks yeah man I appreciate you I\\'m booking my flight soon so yeah definitely bro I\\'ll see you soon thank you everybody [Music]'},\n",
              " {'title': 'What is Model Context Protocol (MCP)?',\n",
              "  'url': 'https://www.ibm.com/think/topics/model-context-protocol',\n",
              "  'content': 'As the switchboard, MCP decides which sources of power (tool output or context) to connect and when to do so, regulates the current (stream of information), filters and prioritizes inputs. It does that to ensure that only relevant wires are energized (the relevant context is loaded) and manages the circuit’s timing and routing to not overload the system.\\n\\nJust as a well-designed circuit prevents overload and ensures efficient power usage, MCP serves as a connector to facilitate efficient, relevant and structured use of context for optimal AI model performance. [...] These impediments can be remedied with the Model Context Protocol (MCP). MCP allows AI agents to be context-aware while complying with a standardized protocol for tool integration.\\n\\nAn AI agent is a system or program that is capable of autonomously performing tasks on behalf of a user or another system. It performs them by designing its workflow and by using available tools. Multiagent systems consist of multiple AI agents working collectively to perform tasks on behalf of a user or another system. [...] In the reverse server-to-client stream, the received messages in JSON-RPC format are converted back into MCP protocol messages.9 The three JSON-RPC message types include requests, responses and notifications. Requests require a response from the server, whereas notifications do not.\\n\\nModel Context Protocol architecture\\n\\nIn the transport layer between clients and servers, there are two main transport methods for MCP protocol, both of which transmit messages in JSON-RPC 2.0 format. The first is standard input/output (stdio) which works best for integrating local resources due to the simple input/output information transmission. This format is used for lightweight, synchronous messaging.4 Such resources include local file systems, databases and local APIs.',\n",
              "  'score': 0.9998118,\n",
              "  'raw_content': '# What is Model Context Protocol (MCP)?\\n\\n## Author\\n\\n[Anna Gutowska](https://www.ibm.com/think/author/anna-gutowska) \\n\\nAI Engineer, Developer Advocate\\n\\nThe Model Context Protocol (MCP) serves as a standardization layer for [AI](https://www.ibm.com/think/topics/artificial-intelligence) applications to communicate effectively with external services such as [tools](https://www.ibm.com/think/topics/tool-calling), [databases](https://www.ibm.com/think/topics/database) and predefined templates.\\n\\nHave you ever tried to build a [multiagent system](https://www.ibm.com/think/topics/multiagent-system)\\xa0but struggled to produce an effective dissemination of information between each specialized agent? Is the variety of prebuilt and custom tools provided to your [AI agent](https://www.ibm.com/think/topics/ai-agents) causing either tool execution or output parsing errors? Or perhaps, have these complications discouraged you from attempting to develop your own agents entirely?\\n\\nThese impediments can be remedied with the Model Context Protocol (MCP). MCP allows AI agents to be context-aware while\\xa0complying with a standardized protocol for tool integration.\\n\\nAn [AI agent](https://www.ibm.com/think/topics/ai-agents) is a system or program that is capable of autonomously performing tasks on behalf of a user or another system. It performs them by designing its workflow and by using available tools. [Multiagent systems](https://www.ibm.com/think/topics/multiagent-system) consist of multiple AI agents working collectively to perform tasks on behalf of a user or another system.\\n\\nYou can think of MCP for AI applications to serve the same purpose as a USB-C port serves for hardware.1 This analogy highlights the adaptability USB-C ports provide for connecting hardware comparing it to the standardized way in which various tools and data sources provide context to [AI models](https://www.ibm.com/think/topics/ai-model) through MCP.\\n\\n## Tools provide meaning\\n\\n[Large language models (LLMs)](https://www.ibm.com/think/topics/large-language-models) like [Granite](https://www.ibm.com/granite), Gemini and Llama are limited in their capabilities when\\xa0deployed on their own. Without any AI tools, LLMs are skilled in several areas including:\\n\\n* Subsequent text prediction: Prompting an LLM to complete a sentence such as “Jack and Jill went up the...” results in a correct prediction of “Jack and Jill went up the hill.” This prompt and responses is an example of subsequent text prediction and works best on text the model was trained on.\\n* Basic Q&A: Since an LLM on its own cannot access external databases or web searches, it can answer natural language questions that pertain to information in the data used to train the model. An example can be “Tell me about the treaty of Versailles” because this information about a major world war is most likely included in the training data of general-purpose models. LLMs often perform this text generation in the form of a [chatbot](https://www.ibm.com/think/topics/chatbots).\\n* [Sentiment analysis](https://www.ibm.com/think/topics/sentiment-analysis): LLMs can process text and determine whether it expresses a positive, negative or neutral sentiment.\\n* Language translation: LLMs can translate text across languages and geographies. However, not every LLM is trained on data from more than one language.\\n\\nAside from basic functions, an LLM without access to external tools cannot successfully run any user query that requires access to real-time information. To provide LLMs with the opportunity to produce more meaningful results, tool integration can be introduced. Providing external tools such as web searches, datasets and [APIs](https://www.ibm.com/think/topics/api), allows the LLM to expand its capabilities beyond its training data.\\n\\nTo take this one step further, we can build AI agents by using an LLM and its available tools. Summarizing, agentic systems provide an LLM with a set of tools, allowing the model to determine appropriate tool use, adapt to a changing environment and form synthesized conclusions based on tool output. However, at scale, these AI systems tend to fail. Hence, MCP, introduced by Anthropic in 2024, establishes an open standard for AI-tool interactions.2\\n\\nIndustry newsletter\\n\\n### The latest AI trends, brought to you by experts\\n\\nGet curated insights on the most important—and intriguing—AI news. Subscribe to our weekly Think newsletter. See the [IBM Privacy Statement](https://www.ibm.com/privacy).\\n\\n### Thank you! You are subscribed.\\n\\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe [here](https://www.ibm.com/account/reg/signup?formid=news-urx-51525). Refer to our [IBM Privacy Statement](https://www.ibm.com/us-en/privacy) for more information.\\n\\n## MCP establishes a standard\\n\\nIt is cumbersome to connect external services to an LLM. Imagine an electrical circuit connecting a motor to various power sources. MCP is like the wiring and switchboard of this circuit; it decides what electrical current (information) flows to the motor (AI model). Tool output or model context can be compared to the input current—it is the voltage flowing from a source of power and can include memory, tools and past findings.\\n\\nAs the switchboard, MCP decides which sources of power (tool output or context) to connect and when to do so, regulates the current (stream of information), filters and prioritizes inputs. It does that to ensure that only relevant wires are energized (the relevant context is loaded) and manages the circuit’s timing and routing to not overload the system.\\n\\nJust as a well-designed circuit prevents overload and ensures efficient power usage, MCP serves as a connector to\\xa0facilitate efficient, relevant and structured use of context for optimal AI model performance.\\n\\nMCP establishes a new [open source](https://www.ibm.com/think/topics/open-source) standard for AI engineers to agree upon. However, standards are not a new concept in the software industry.\\xa0For example,\\xa0[REST APIs](https://www.ibm.com/think/topics/rest-apis) are industry-standard, offering consistent data exchange between applications through HTTP requests aligned with REST design principles.\\n\\nSimilarly, MCP unifies the LLM and external services to communicate efficiently by setting a standard. This standard allows for “plug-and-play” tool usage rather than writing code for custom integration of each tool.\\n\\nMCP is not an agent framework, but a standardized integration layer for agents accessing tools. It complements agent orchestration frameworks.\\xa0MCP can complement agent orchestration frameworks like [LangChain](https://www.ibm.com/think/topics/langchain), [LangGraph](https://www.ibm.com/think/topics/langgraph), [BeeAI](https://beeai.dev/), LlamaIndex and [crewAI](https://www.ibm.com/think/topics/crew-ai), but it does not replace them; MCP does not decide when a tool is called and for what purpose.\\n\\nMCP simply provides a standardized connection to streamline tool integration.3 Ultimately, the LLM determines which tools to call based on the context of the user’s request.\\n\\n## MCP architecture\\n\\nThe MCP client/server model can be broken down into three key architectural components:\\n\\n### MCP host\\n\\nAn AI application receives the user requests and seeks access to context through the MCP. This integration layer can include IDEs such as Cursor or Claude Desktop. It contains the orchestration logic and can connect each client to a server.4\\n\\n### MCP client\\n\\nCommunication in the MCP ecosystem between the host and server must go through a client. This client exists within the host and converts user requests into a structured format that the open protocol can process. Multiple clients can exist with a singular MCP host but each client has a 1:1 relationship with an MCP server.\\n\\nExamples of MCP clients are IBM® BeeAI, Microsoft Copilot Studio, Claude.ai, Windsurf Editor and Postman. Clients serve as the session manager by handling interruptions, timeouts, reconnections and session closures. Clients also parse responses,\\xa0conduct error handling and\\xa0verify that responses are relevant to the context and appropriate.4\\n\\n### MCP server\\n\\nThe external service that provides the context to the LLM by converting user requests to server actions. Examples of MCP server integrations include Slack, GitHub, Git, Docker or web search. These servers are typically GitHub repositories available in various programming languages (C#, Java™, TypeScript, Python and others) and provide access to MCP tools.\\n\\nTutorials can typically be found within these GitHub repositories to aid in the technical implementation. MCP servers can also be used to connect [LLM inferencing](https://www.ibm.com/think/topics/ai-inference), through AI platform providers such as IBM and OpenAI, to the MCP SDK. In doing so, a reusable MCP service is created for clients to\\xa0access as a “standardized” chat tool.\\n\\nMCP servers are versatile as they allow connections to both internal and external resources and tools. According to the docs provided by Anthropic, Model Context Protocol servers expose data through:\\n\\n* **Resources**: Information retrieval from internal or external databases. Resources return data but do not execute actionable computations.5\\n* **Tools**: Information exchange with tools that can perform a side effect such as a calculation or fetch data through an API request.6\\n* **Prompts**: Reusable templates and workflows for LLM-server communication.7\\n\\nThe transport layer between clients and servers is responsible for two-way message conversion. In the client-to-server stream, MCP protocol messages are converted into JSON-RPC format, allowing for the transport of several data structures and their processing rules.8\\n\\nIn the reverse server-to-client stream, the received messages in JSON-RPC format are converted back into MCP protocol messages.9 The three JSON-RPC message types include requests, responses and notifications. Requests require a response from the server, whereas notifications do not.\\n\\nModel Context Protocol architecture\\n\\nIn the transport layer between clients and servers, there are two main transport methods for MCP protocol, both of which transmit messages in JSON-RPC 2.0 format. The first is standard input/output (stdio) which works best for integrating local resources due to the simple input/output information transmission. This format is used for lightweight, synchronous messaging.4 Such resources include local file systems, databases and local APIs.\\n\\nThe second is server-sent events (SSE) which works best for integrating remote resources. HTTP POST requests serve as the mechanism for transmitting client-to-server messages and SSE is used for the reverse. This format can be used to handle multiple asynchronous, event-driven server-calls at once.4\\n\\n## Benefits of MCP\\n\\nImagine a real-world AI that scans your inbox to schedule client meetings, sends stock updates, and texts summaries of the last hour’s Slack activity. Every service provider constructs their APIs differently by requiring different information to pass, returning different output schemas. Thus, the slightest change in these tools can result in the collapse of this entire AI workflow infrastructure.\\n\\nThere is also a significant development load on engineers to manually construct these tool connections, [debug](https://www.ibm.com/think/topics/debugging) and maintain authentication like API keys and tool permissions. Tools are often dependent on the output of other tools and there exist many edge cases in which these connections fail.\\n\\nThus, it is critical to provide MCP integration as the middle layer between the LLM and the development tools. In this layer, the MCP can convert tool output in a way that is understandable by the model. Without the need to alternate between CLIs, the tool integration occurs all in one place.\\n\\nThere are many real-world use cases for MCP.\\xa0For instance, MCP enhances\\xa0[multiagent orchestration](https://www.ibm.com/think/topics/ai-agent-orchestration) and communication through a shared workspace with common tools, eliminating the need for direct integrations.3\\n\\nMCP can also be used to supplement [retrieval augmented generation (RAG)](https://www.ibm.com/think/topics/retrieval-augmented-generation). Rather than providing the retriever to search a vector store or knowledge base, MCP can connect to a [vector database](https://www.ibm.com/think/topics/vector-database) through a server action. Searching the database as a tool rather than passing the retriever in every LLM invocation allows for more strategic use of the tool. This approach also allows for further [tool-calling](https://www.ibm.com/think/topics/tool-calling) upon data retrieval.3\\n\\n## The future of MCP\\n\\nMCP represents an evolving approach to LLM tool integration that continues to mature and reshape the space over time.\\xa0As technical challenges arise and MCP servers evolve, the standard adapts and MCPs continue to improve.\\n\\nRegardless, the need for standardized tool integration is critical for AI agents to operate autonomously and adapt dynamically to real-world environments.10\\xa0With MCP, we can streamline the automation of complex [agentic workflows](https://www.ibm.com/think/topics/agentic-workflows) to allow for less human oversight.\\xa0In turn, this shift enabled by MCP allows our time to be spent on more nuanced tasks requiring human intellect and intuition.\\n\\nLink copied\\n\\n[Ebook   Start realizing ROI: A practical guide to agentic AI \\n\\nDiscover ways to get ahead, successfully scaling AI across your business with real results.\\n\\n Read the ebook](https://www.ibm.com/account/reg/signup?formid=urx-54067)\\n\\n[Build, run and manage AI agents with watsonx Orchestrate](https://www.ibm.com/products/watsonx-orchestrate)\\n\\n## Resources\\n\\n[Report   AI governance imperative: evolving regulations and emergence of agentic AI \\n\\nLearn how evolving regulations and the emergence of AI agents are reshaping the need for robust AI governance frameworks.\\n\\n Read the report](https://www.ibm.com/forms/mkt-54070)\\n\\n[Techsplainers Podcast   Agentic AI explained \\n\\nTechsplainers by IBM breaks down the essentials of agentic AI, from key concepts to real‑world use cases. Clear, quick episodes help you learn the fundamentals fast.\\n\\n Listen now](https://www.ibm.com/think/podcasts/techsplainers#tabs-fw-44e285b2cc-item-a3ea4f0927-tab)\\n\\n[Guidebook   Unlock AI ROI: A tactical guide to enterprise productivity \\n\\nLearn proven strategies to boost productivity and power enterprise transformation with AI and innovation at the core.\\n\\n Read the guidebook](https://www.ibm.com/account/reg/signup?formid=urx-54227)\\n\\n[Report   IDC MarketScape names IBM a leader in 2025 gen AI evaluation technology \\n\\nDownload the report to learn why IDC MarketScape named IBM a leader in 2025 gen AI evaluation technology, and how watsonx.governance® advances risk management, reporting and integration.\\n\\n Read the report](https://www.ibm.com/forms/mkt-54030)\\n\\n[Buyer guide   How AI agents and assistants can benefit your organization \\n\\nDive into this comprehensive guide that breaks down key use cases and core capabilities, providing step-by-step recommendations to help you choose the right solutions for your business.\\n\\n Read the guide](https://www.ibm.com/forms/mkt-53811)\\n\\n[Video   Reimagine business productivity with AI agents and assistants \\n\\nLearn how AI agents and AI assistants can work together to achieve new levels of productivity.\\n\\n Watch now](https://www.ibm.com/think/videos/ai-academy/reimagine-business-productivity-with-ai)\\n\\n[Demo   Try watsonx Orchestrate \\n\\nExplore how generative AI assistants can lighten your workload and improve productivity.\\n\\n Start the demo](https://www.ibm.com/products/watsonx-orchestrate/demos)\\n\\n[Report   From AI projects to profits: How agentic AI can sustain financial returns \\n\\nLearn how organizations are shifting from launching AI in disparate pilots to using it to drive transformation at the core.\\n\\n Read the report](https://www.ibm.com/thought-leadership/institute-business-value/report/agentic-ai-profits)\\n\\n[Report   Omdia Report on empowered intelligence: The impact of AI agents \\n\\nDiscover how you can unlock the full potential of gen AI with AI agents.\\n\\n Read the report](https://www.ibm.com/forms/mkt-53501)\\n\\n[Podcast   How AI agents will reinvent productivity \\n\\nLearn ways to use AI to be more creative, efficient and start adapting to a future that involves working closely with AI agents.\\n\\n Listen now](https://www.ibm.com/think/podcasts/ai-in-action/how-ai-agents-will-reinvent-productivity)\\n\\n[News   Ushering in the agentic enterprise: Putting AI to work across your entire technology estate \\n\\nStay updated about the new emerging AI agents, a fundamental tipping point in the AI revolution.\\n\\n Read the news](https://www.ibm.com/new/announcements/productivity-revolution-with-ai-agents-that-work-across-stack)\\n\\n[Podcast   The future of agents, AI energy consumption, Anthropic computer use and Google watermarking AI-generated text \\n\\nStay ahead of the curve with our AI experts on this episode of Mixture of Experts as they dive deep into the future of AI agents and more.\\n\\n Listen now](https://www.ibm.com/think/podcasts/mixture-of-experts/future-of-ai-agents-ai-energy-consumption-anthropic-computer-use-google-watermarking-ai)\\n\\n[Case study   How Comparus is using a \"banking assistant\" \\n\\nComparus used solutions from IBM watsonx.ai® and impressively demonstrated the potential of conversational banking as a new interaction model.\\n\\n Read the case study](https://www.ibm.com/case-studies/comparus-gmbh)\\n\\nRelated solutions   \\n AI agents for business   \\n\\nBuild, deploy and manage powerful AI assistants and agents that automate workflows and processes with generative AI.\\n\\n   [Explore watsonx Orchestrate](https://www.ibm.com/products/watsonx-orchestrate)   \\n IBM AI agent solutions   \\n\\nBuild the future of your business with AI solutions that you can trust.\\n\\n   [Explore AI agent solutions](https://www.ibm.com/solutions/ai-agents)   \\n IBM Consulting\\xa0AI services   \\n\\nIBM Consulting AI services help reimagine how businesses work with AI for transformation.\\n\\n   [Explore artificial intelligence services](https://www.ibm.com/consulting/artificial-intelligence)\\n\\nTake the next step\\n\\n \\n\\nWhether you choose to customize pre-built apps and skills or build and deploy custom agentic services using an AI studio, the IBM watsonx platform has you covered.\\n\\n    [Explore watsonx Orchestrate](https://www.ibm.com/products/watsonx-orchestrate)   [Explore watsonx.ai](https://www.ibm.com/products/watsonx-ai)\\n\\n1\\xa0Introduction—Model Context Protocol\\xa0[https://modelcontextprotocol.io/introduction](https://modelcontextprotocol.io/docs/getting-started/intro), 2025  \\n 2 Hou, X., Zhao, Y., Wang, S., & Wang, H., Model context protocol (MCP): Landscape, security threats and future research directions.\\xa0arXiv preprint arXiv: 2503.23278,\\xa02025  \\n 3 Se, K., #14: What is MCP and why is everyone—suddenly!—talking about it?\\xa0[Huggingface.co](https://huggingface.co/).\\xa0<https://huggingface.co/blog/Kseniase/mcp>, 17 March 2025  \\n 4 Ray, P., A survey on Model Context Protocol: Architecture, state-of-the-art, challenges and future directions.\\xa0TechRxiv,\\xa018 April 2025  \\n 5\\xa0Resources—Model Context Protocol\\xa0[https://modelcontextprotocol.io/docs/concepts/resources](https://modelcontextprotocol.io/specification/2025-06-18/server/resources), 2025  \\n 6\\xa0Tools—Model Context Protocol\\xa0[https://modelcontextprotocol.io/docs/concepts/tools](https://modelcontextprotocol.io/specification/2025-06-18/server/tools), 2025  \\n 7\\xa0Prompts—Model Context Protocol\\xa0[https://modelcontextprotocol.io/docs/concepts/prompts](https://modelcontextprotocol.io/specification/2025-06-18/server/prompts),\\xa02025  \\n 8 JSON-RPC Working Group—JSON-RPC 2.0 specification.\\xa0[Jsonrpc.org](https://www.jsonrpc.org/).\\xa0<https://www.jsonrpc.org/specification>,\\xa026 March 2025  \\n 9\\xa0Transports—Model Context Protocol\\xa0[https://modelcontextprotocol.io/docs/concepts/transports](https://modelcontextprotocol.io/specification/2025-06-18/basic/transports), 2025  \\n 10 Singh, A., Ehtesham, A., Kumar, S., and Khoei, T. T., A survey of the Model Context Protocol (MCP): Standardizing context to enhance large language models (LLMs) Preprints,\\xa0[https://doi.org/10.20944/preprints202504.0245.v1](https://www.preprints.org/manuscript/202504.0245/v1),\\xa02025'},\n",
              " {'title': 'Understanding the Power of Model Context Protocol (MCP)',\n",
              "  'url': 'https://www.moveworks.com/us/en/resources/blog/model-context-protocol-mcp-explained',\n",
              "  'content': \"Read whitepaper\\n\\n## What is Model Context Protocol (MCP)?\\n\\nModel Context Protocol is a standard designed to help large language models connect more easily to external tools and services. Services that implement the Model Context Protocol (servers referred to as “MCPs”) enable LLMs to access and utilize external knowledge, tools, and data, significantly enhancing their versatility and power.\\n\\nDriven by organizations like Anthropic, MCP is shaping how AI tools function by providing a reliable framework for integration and interoperability.\\n\\nEssentially, MCP is intended to act as a universal translation layer between AI applications and the tools that can be used to add context and data to the conversation and take action in the world.\\n\\n## Why Model Context Protocol matters [...] With MCP,  a single integration can communicate with any system that supports the protocol, reducing the workload for developers and accelerating the rollout of new features.\\n\\nThis standardization simplifies the deployment process, enhances compatibility, and reduces development time, allowing companies to more efficiently implement and scale their AI solutions\\n\\n## Understanding API challenges and MCP opportunities\\n\\nDevelopers looking to let AI systems and AI agents securely access data from their companies' systems have traditionally faced a big integration challenge. [...] ## How we’re thinking about MCP at Moveworks\\n\\nModel Context Protocol offers a promising framework for standardizing AI integrations, aiming to streamline and enhance the way AI models interact with external systems. While it currently faces some limitations, addressing these can pave the way for broader enterprise adoption.\\n\\nWe believe the ideal way to build highly-performant AI agents today is through Plugin Workspace and Agent Studio. However, we are also planning on being an open ecosystem and allow developers to bring AI agents for low-performance tasks via MCP servers.\",\n",
              "  'score': 0.9997713,\n",
              "  'raw_content': '* [Home](https://www.moveworks.com/)\\n* [Resources](https://www.moveworks.com/us/en/resources)\\n* [Blogs](https://www.moveworks.com/us/en/resources/blog)\\n* [Simplifying AI Connections: Understanding the Power of Model Context Protocol (MCP)](https://www.moveworks.com/us/en/resources/blog/model-context-protocol-mcp-explained)\\n\\nBlog / May 30, 2025\\n\\n# Simplifying AI Connections: Understanding the Power of Model Context Protocol (MCP)\\n\\nWill Davis,\\n\\nPrincipal Presales Solutions Engineer\\n\\n[Matthew Mistele,](https://www.moveworks.com/us/en/company/author/matt-mistele) Senior Engineering Manager\\n\\nTable of contents\\n\\n---\\n\\nBy now, you’ve probably heard all the hype about Model Context Protocol (MCP). But what exactly is MCP? And can it really streamline AI integrations and reduce the need to build custom, case-by-case solutions?\\n\\nMCP represents a promising approach that standardizes how AI models interact with different systems. That’s because MCP is a standard designed to help large language models (LLMs) connect seamlessly to external tools and services.\\n\\nSo, what makes MCP so special – and what challenges remain?\\n\\n**MCP helps AI models adapt to different contexts and data sources, helping to minimize friction and boosting overall capabilities.**\\n\\nWhen an enterprise can set up a robust, enterprise-ready foundation for MCP,\\xa0 it can help to make smoother integrations possible for developers, whether you need AI to chat with another app, access a database, or easily interact with customer service platforms,\\n\\n**MCP has the ability to cut through the complexity of linking up different systems, letting the developers use AI to do what it does best – without developers getting tangled up in technical complexity.**\\n\\nIn this blog, we\\'ll break down how:\\n\\n* MCP elevates AI tool capabilities\\n* Limitations and challenges\\n* How MCP can lead to more effective and responsive AI experiences\\xa0the right foundation\\n\\nWhether you’re a developer, business owner, or tech enthusiast,\\xa0 we explore the foundations of MCP and how MCP is changing AI integrations.\\n\\n### Discover the power of AI agents. Get our white paper on agentic automation\\n\\n[Read whitepaper](https://www.moveworks.com/us/en/resources/white-papers/unleash-ai-agents-with-agentic-automation-engine)\\n\\n## What is Model Context Protocol (MCP)?\\n\\nModel Context Protocol is a standard designed to help large language models connect more easily to external tools and services. Services that implement the Model Context Protocol (servers referred to as “MCPs”) enable LLMs to access and utilize external knowledge, tools, and data, significantly enhancing their versatility and power.\\n\\nDriven by organizations like\\xa0[Anthropic,](https://www.anthropic.com/news/model-context-protocol)\\xa0MCP is shaping how AI tools function by providing a reliable framework for integration and interoperability.\\n\\n**Essentially, MCP is intended to act as a universal translation layer between AI applications and the tools that can be used to add context and data to the conversation and take action in the world.**\\n\\n## Why Model Context Protocol matters\\n\\nMCP benefits organizations with AI tools by providing a standardized framework that ensures seamless integration and interoperability between various AI models and applications to help reduce complexity.\\n\\n***Standardization***\\n\\nMCP offers a standardized way to integrate APIs, meaning developers can use a common set of protocols to connect different systems. This reduces confusion and development time, as there\\'s no need to learn new ways of doing things for each integration.\\n\\n***Open source integration***\\n\\n[Open source Model Context Protocol (MCP) servers](https://www.fierce-network.com/cloud/what-mcp-and-why-does-it-matter-ai)facilitate the smooth integration of AI agents and models with various tools, data sources, and services. This helps to create a more modular, flexible, and powerful AI ecosystem. They do this by acting as a standard interface, enabling AI systems to communicate and interact with different applications without needing custom integrations.\\n\\n***Reduced complexity***\\n\\nBy eliminating the need to create separate, specific integrations for each tool, MCP simplifies development. Previously, if you wanted to connect a tool like Notion to different AI systems, separate integrations were needed for each; now, you can point to an MCP server and Notion will be able to know what’s available and how to get it.\\n\\nWith MCP,\\xa0 a single integration can communicate with any system that supports the protocol, reducing the workload for developers and accelerating the rollout of new features.\\n\\nThis standardization simplifies the deployment process, enhances compatibility, and reduces development time, allowing companies to more efficiently implement and scale their AI solutions\\n\\n## Understanding API challenges and MCP opportunities\\n\\nDevelopers looking to let AI systems and AI agents securely access data from their companies\\' systems have traditionally faced a big integration challenge.\\n\\nTypically, each organization designs their own method to integrate AI Agents with external applications – often involving creating custom APIs or middleware – with the goal of linking AI Agents with external applications, to empower these agents to perform tasks.\\n\\nHowever, if each vendor works in their own unique way this hurts standardization. Differing approaches leave developers to pick up the slack and \"glue things together\", while increasing potential errors and inefficiencies.\\n\\nWithout a standard like MCP, developers must coordinate with every single AI provider to align on an integration setup that works.\\n\\nFor example, if you had AI Agents A & B, and Apps C & D – you might end up in a world where there are 4 different implementations (one for each vendor). But MCP standardizes how AI agents (MCP Hosts) access MCP assets, and it standardizes how applications (MCP servers) provide MCP assets.\\n\\n**In short, while MCP itself is not a technology shift or paradigm change – it\\'s a crucial contract that the software world is agreeing to follow.**\\n\\nWith MCP,\\xa0 you simply build an MCP server, and then every AI system that supports MCP can integrate, knowing available features and requirements.\\n\\n*Source:\\xa0[Sumeet Agrawal](https://www.linkedin.com/posts/sumeet-agrawal-2b74676_before-vs-after-mcp-why-every-llm-dev-activity-7318853326689705984-gcQL?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAjzY1gBQ0rsaY1dtYq3rEKRGUwvQisfVOk),\\xa0[Linkedin](https://www.linkedin.com/posts/sumeet-agrawal-2b74676_before-vs-after-mcp-why-every-llm-dev-activity-7318853326689705984-gcQL?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAjzY1gBQ0rsaY1dtYq3rEKRGUwvQisfVOk).*\\n\\n## Benefits of MCP for AI applications\\n\\nThe Model Content Protocol is poised to change how AI applications are built and used, impacting both developers and everyday users.\\n\\nDevelopers benefit by offering a straightforward way to link their systems to different AI platforms, speeding up access and increasing adoption by everyday users. For everyday users, MCP offers a chance to easily connect their LLM client of choice to their favorite tools, simplifying, and providing more context to their everyday experience.\\n\\nHowever, certain challenges remain in enabling MCP to live up to its great potential.\\n\\n### MCP promise vs. reality: An enterprise perspective\\n\\nMCP positions itself as a universal standard for connecting AI models to external tools and data sources. This sparks interest for ease of integration, but it can fall short for enterprises in important areas.\\n\\nFor developers, it can be liberating and enable them to rapidly experiment and integrate new services without complexity.\\n\\n**But enterprises face different realities. They require security, stability, operational predictability, and alignment with structured workflows.**\\n\\nFor instance, adoption of MCP may encounter [security challenges](https://techcommunity.microsoft.com/blog/microsoft-security-blog/understanding-and-mitigating-security-risks-in-mcp-implementations/4404667), as any given MCP server might not fully support robust encryption and access controls necessary for data protection. The specification\\'s maturity can also cause issues, with evolving standards leading to integration inconsistencies.\\n\\nAdditionally, MCP might limit operational control, restricting dynamic customization and management needed for compliance. Workflow misalignment can occur if MCP doesn\\'t fit with established processes, causing disruptions. Imagine an example where a user has requirements around saving commit information from Github into another application such as SFDC.\\n\\nThey might think to download a publicly available MCP server for both but this business requirement wouldn’t be captured in either, leading the user to either not follow this business requirement or having to create yet another MCP server directly for their needs.\\n\\nGiven these limitations, MCPs still need additional support and development to be able to deliver on these fronts.\\n\\n## Steps for MCP to enhance enterprise readiness\\n\\nTo evolve from a promising technology to a reliable enterprise standard, MCP users should consider adding capabilities to better address enterprise needs:\\n\\n* Support and document a robust, enterprise-grade security framework that dictates how developers can better secure created MCP servers.\\n* Enhance the stability and clarity of the specification, incorporating predictable updates and comprehensive documentation.\\n* Introduce tools that provide clear operational oversight and control over AI interactions.\\n* Adapt MCP to align more closely with existing structured enterprise workflows, minimizing the need for businesses to adjust their current processes.\\n\\n## How we’re thinking about MCP at Moveworks\\n\\nModel Context Protocol offers a promising framework for standardizing AI integrations, aiming to streamline and enhance the way AI models interact with external systems. While it currently faces some limitations, addressing these can pave the way for broader enterprise adoption.\\n\\nWe believe the ideal way to build highly-performant AI agents today is through Plugin Workspace and [Agent Studio](https://www.moveworks.com/us/en/platform/ai-agent-builder). However, we are also planning on being an open ecosystem and allow developers to bring AI agents for low-performance tasks via MCP servers.\\n\\nThat’s why Moveworks is developing this capability, helping to enable seamless connections to MCPs. By standardizing interactions and simplifying the integration process, we hope to enable MCPs to balance flexibility with the demands of structured enterprise environments.\\n\\nTrue innovation requires consistent updates, strategic insights, and collaborative efforts with stakeholders.\\xa0 As companies adopt MCP protocols and continue to develop and mature, these are becoming a key part of AI ecosystems that are increasingly agile and context-aware.\\n\\n*The content of this blog post is for informational purposes only.*\\n\\n## Subscribe to our Insights blog\\n\\nThank you for subscribing!\\n\\nBy submitting, you agree to our\\xa0[Privacy Policy](https://www.moveworks.com/us/en/legal/privacy-policy).\\n\\n## Related articles\\n\\nBlog\\n\\n### Employee Experience Framework: A Strategic Blueprint for HR\\n\\nLearn how to build an employee experience framework that aligns people, processes, and tech to drive enterprise-wide employee satisfaction and engagement.\\n\\n[Read the blog](/us/en/resources/blog/how-to-create-an-employee-experience-framework)\\n\\nBlog\\n\\n### Modern Framework for Scalable Employee Data Management\\n\\nModernize your employee data management framework with secure, scalable tools that streamline workflows and power smarter decisions across your workforce.\\n\\n[Read the blog](/us/en/resources/blog/employee-data-management-framework)\\n\\nBlog\\n\\n### How to Start Digital Transformation in Enterprise HR\\n\\nLearn how to start HR digital transformation with practical steps, best practices, and AI-powered strategies to streamline and improve employee experience.\\n\\n[Read the blog](/us/en/resources/blog/how-to-get-started-with-digital-transformation-in-hr)\\n\\n## The AI Assistant platform for your entire workforce\\n\\nFind what you need instantly and automate tasks end-to-end in seconds across apps with AI agents that can realize your business objectives.\\n\\n[Get a demo](https://www.moveworks.com/us/en/demo)'},\n",
              " {'title': 'Model Context Protocol',\n",
              "  'url': 'https://modelcontextprotocol.io/',\n",
              "  'content': 'Get started\\n\\n# What is the Model Context Protocol (MCP)?\\n\\nMCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)—enabling them to access key information and perform tasks. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\\n\\n## \\u200b What can MCP enable?',\n",
              "  'score': 0.9997677,\n",
              "  'raw_content': '[Model Context Protocol home page![light logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/light.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=4498cb8a57d574005f3dca62bdd49c95)![dark logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/dark.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=c0687c003f8f2cbdb24772ab4c8a522c)](/)\\n\\n[Documentation](/docs/getting-started/intro)[Specification](/specification/2025-11-25)[Registry](/registry/about)[Community](/community/contributing)\\n\\n##### Get started\\n\\n* [What is MCP?](/docs/getting-started/intro)\\n\\n##### About MCP\\n\\n* [Architecture](/docs/learn/architecture)\\n* [Servers](/docs/learn/server-concepts)\\n* [Clients](/docs/learn/client-concepts)\\n* [Versioning](/specification/versioning)\\n\\n##### Develop with MCP\\n\\n* [Connect to local MCP servers](/docs/develop/connect-local-servers)\\n* [Connect to remote MCP Servers](/docs/develop/connect-remote-servers)\\n* [Build an MCP server](/docs/develop/build-server)\\n* [Build an MCP client](/docs/develop/build-client)\\n* [SDKs](/docs/sdk)\\n\\n##### Developer tools\\n\\n* [MCP Inspector](/docs/tools/inspector)\\n\\n##### Extensions\\n\\n* [Extensions Overview](/docs/extensions/overview)\\n* [MCP Apps](/docs/extensions/apps)\\n\\n* [What can MCP enable?](#what-can-mcp-enable)\\n* [Why does MCP matter?](#why-does-mcp-matter)\\n* [Start Building](#start-building)\\n* [Learn more](#learn-more)\\n\\nGet started\\n\\n# What is the Model Context Protocol (MCP)?\\n\\nMCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)—enabling them to access key information and perform tasks. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\\n\\n## [\\u200b](#what-can-mcp-enable) What can MCP enable?\\n\\n* Agents can access your Google Calendar and Notion, acting as a more personalized AI assistant.\\n* Claude Code can generate an entire web app using a Figma design.\\n* Enterprise chatbots can connect to multiple databases across an organization, empowering users to analyze data using chat.\\n* AI models can create 3D designs on Blender and print them out using a 3D printer.\\n\\n## [\\u200b](#why-does-mcp-matter) Why does MCP matter?\\n\\nDepending on where you sit in the ecosystem, MCP can have a range of benefits.\\n\\n* **Developers**: MCP reduces development time and complexity when building, or integrating with, an AI application or agent.\\n* **AI applications or agents**: MCP provides access to an ecosystem of data sources, tools and apps which will enhance capabilities and improve the end-user experience.\\n* **End-users**: MCP results in more capable AI applications or agents which can access your data and take actions on your behalf when necessary.\\n\\n## [\\u200b](#start-building) Start Building\\n\\n[## Build servers\\n\\nCreate MCP servers to expose your data and tools](/docs/develop/build-server)[## Build clients\\n\\nDevelop applications that connect to MCP servers](/docs/develop/build-client)\\n\\n## [\\u200b](#learn-more) Learn more\\n\\n[## Understand concepts\\n\\nLearn the core concepts and architecture of MCP](/docs/learn/architecture)\\n\\nWas this page helpful?\\n\\n[Architecture](/docs/learn/architecture)'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build your own tools in LangChain\n",
        "\n",
        "Tools are interfaces that an agent, chain, or LLM can use to interact with the world. They combine a few things:\n",
        "\n",
        "- The name of the tool\n",
        "- A description of what the tool is\n",
        "- JSON schema of what the inputs to the tool are\n",
        "- The function to call\n",
        "- Whether the result of a tool should be returned directly to the user\n",
        "\n",
        "It is useful to have all this information because this information can be used to build action-taking systems! The name, description, and JSON schema can be used to prompt the LLM so it knows how to specify what action to take, and then the function to call is equivalent to taking that action."
      ],
      "metadata": {
        "id": "-GNP2J9Dd_nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Simple Math Tool"
      ],
      "metadata": {
        "id": "ZtoArDYfheYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by building a simple tool which does some basic math"
      ],
      "metadata": {
        "id": "JvPAmW62eLyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(a, b):\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "# Let's inspect some of the attributes associated with the tool.\n",
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa0mztbQ8Ae3",
        "outputId": "48025226-615a-4d12-9dac-d0cbe3c94385"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiply\n",
            "Multiply two numbers.\n",
            "{'a': {'title': 'A'}, 'b': {'title': 'B'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(multiply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "tfP2TjeK8FsR",
        "outputId": "84bf5c26-7cc9-454e-b596-b390aba593f9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.tools.structured.StructuredTool"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.tools.structured.StructuredTool</b><br/>def __init__(**kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/tools/structured.py</a>Tool that can operate on any number of inputs.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 40);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsOVBIvX8Agu",
        "outputId": "d6608b0e-648f-4355-d597-54c965442870"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"a\": 2.1, \"b\": 3.2})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC7o_Mv5-Grc",
        "outputId": "3a08e158-e24f-42a6-b6d9-ca1b2c94278c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.720000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 'abc'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vN4tHdDa-Tm2",
        "outputId": "f9d59d12-b017-4539-a6df-e4406b5a2340"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcabc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now build a tool with data type enforcing"
      ],
      "metadata": {
        "id": "XED8giGYeS_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.tools import StructuredTool\n",
        "\n",
        "class CalculatorInput(BaseModel):\n",
        "    a: float = Field(description=\"first number\")\n",
        "    b: float = Field(description=\"second number\")\n",
        "\n",
        "\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# we could also use the @tool decorator from before\n",
        "multiply = StructuredTool.from_function(\n",
        "    func=multiply,\n",
        "    name=\"multiply\",\n",
        "    description=\"use to multiply numbers\",\n",
        "    args_schema=CalculatorInput,\n",
        "    return_direct=True\n",
        "    )\n",
        "\n",
        "# Let's inspect some of the attributes associated with the tool.\n",
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sKF2zqQ8Aih",
        "outputId": "c30ef934-e35e-4a6c-8d40-ef464ec7b3a6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiply\n",
            "use to multiply numbers\n",
            "{'a': {'description': 'first number', 'title': 'A', 'type': 'number'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'number'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5taFxZg8Akc",
        "outputId": "96b27660-9cf5-4491-a4be-d57456ba742b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code will error out as abc is not a floating point number\n",
        "multiply.invoke({\"a\": 2, \"b\": 'abc'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3PTl9ezG8Ans",
        "outputId": "cc64201b-fb90-4697-f437-e047e6354126"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for CalculatorInput\nb\n  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='abc', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/float_parsing",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-303488317.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this code will error out as abc is not a floating point number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'abc'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m     ) -> Any:\n\u001b[1;32m    641\u001b[0m         \u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prep_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_to_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_call_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0mchild_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                 tool_args, tool_kwargs = self._to_args_and_kwargs(\n\u001b[0m\u001b[1;32m    960\u001b[0m                     \u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36m_to_args_and_kwargs\u001b[0;34m(self, tool_input, tool_call_id)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0;31m# StructuredTool with no args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mtool_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0;31m# For backwards compatibility, if run_input is a string,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;31m# pass as a positional argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36m_parse_input\u001b[0;34m(self, tool_input, tool_call_id)\u001b[0m\n\u001b[1;32m    709\u001b[0m                             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                         \u001b[0mtool_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                 \u001b[0mresult_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModelV1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36mmodel_validate\u001b[0;34m(cls, obj, strict, extra, from_attributes, context, by_alias, by_name)\u001b[0m\n\u001b[1;32m    714\u001b[0m             )\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         return cls.__pydantic_validator__.validate_python(\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for CalculatorInput\nb\n  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='abc', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/float_parsing"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a Web Search & Information Extraction Tool"
      ],
      "metadata": {
        "id": "QMsvq9sVhjuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_raw_content=True)\n",
        "\n",
        "result = tavily_tool.invoke(\"Tell me about Microsoft's Q1 2025 earning call report\")\n",
        "result\n",
        "# Getting the url which is used later"
      ],
      "metadata": {
        "id": "cazBMQsghoaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bf61bf-4864-48c8-bde6-739fdf859fb0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Microsoft Corp (MSFT) Q1 2025 Earnings Call Highlights',\n",
              "  'url': 'https://finance.yahoo.com/news/microsoft-corp-msft-q1-2025-072133599.html',\n",
              "  'content': \"Revenue: $65.6 billion, up 16%.\\n Earnings Per Share (EPS): $3.30, an increase of 10%.\\n Microsoft Cloud Revenue: $38.9 billion, up 22%.\\n Commercial Bookings: Increased 30% and 23% in constant currency.\\n Commercial Remaining Performance Obligation: $259 billion, up 22% and 21% in constant currency.\\n Operating Income: Increased 14%; operating margins at 47%.\\n Productivity and Business Processes Revenue: $28.3 billion, up 12% and 13% in constant currency.\\n Intelligent Cloud Revenue: $24.1 billion, up 20% and 21% in constant currency.\\n Azure and Other Cloud Services Revenue: Grew 33% and 34% in constant currency.\\n More Personal Computing Revenue: $13.2 billion, up 17%.\\n Gaming Revenue: Increased 43% and 44% in constant currency.\\n Free Cash Flow: $19.3 billion, down 7% year over year. [...] Free Cash Flow: $19.3 billion, down 7% year over year.\\n Capital Expenditures: $20 billion.\\n Cash Flow from Operations: $34.2 billion, up 12%.\\n LinkedIn Revenue: Increased 10% and 9% in constant currency.\\n Dynamics Revenue: Grew 14%, driven by Dynamics 365, which grew 18% and 19% in constant currency. [...] ### Positive Points\\n\\n Microsoft Cloud revenue surpassed $38.9 billion, marking a 22% increase, driven by strong demand for AI and cloud services.\\n AI business is on track to surpass an annual revenue run rate of $10 billion next quarter, making it the fastest-growing business in Microsoft's history.\\n Azure and other cloud services revenue grew 33% in constant currency, with healthy consumption trends.\\n Microsoft 365 Copilot adoption is accelerating, with nearly 70% of the Fortune 500 using it, and customers continue to adopt it at a faster rate than any other new Microsoft 365 suite.\\n LinkedIn revenue increased 10%, with record engagement and growth across all lines of business.\\n\\n### Negative Points\",\n",
              "  'score': 0.97938764,\n",
              "  'raw_content': 'Ein Fehler ist aufgetreten.\\n\\n[Zur Navigation springen](#ybar-navigation)  [Zum Hauptinhalt springen](#nimbus-app)  [Zur rechten Spalte springen](#right-rail) \\n\\n\\n### \\n\\n* [Today\\'s news](https://www.yahoo.com/news/)\\n* [US](https://www.yahoo.com/news/us/)\\n* [Politics](https://www.yahoo.com/news/politics/)\\n* [2025 Election](https://www.yahoo.com/events/elections/)\\n* [World](https://www.yahoo.com/news/world/)\\n* [Weather](https://www.yahoo.com/news/weather/)\\n* [Climate change](https://www.yahoo.com/issues/climate-change/)\\n* [Health](https://health.yahoo.com/)\\n  + [Wellness](https://health.yahoo.com/wellness/) \\n    - [Mental health](https://health.yahoo.com/wellness/mental-health/)\\n    - [Sexual health](https://health.yahoo.com/wellness/sexual-health/)\\n    - [Dermatology](https://health.yahoo.com/wellness/dermatology/)\\n    - [Oral health](https://health.yahoo.com/wellness/oral-health/)\\n    - [Hair loss](https://health.yahoo.com/wellness/hair-loss/)\\n    - [Foot health](https://health.yahoo.com/wellness/foot-health/)\\n  + [Nutrition](https://health.yahoo.com/nutrition/) \\n    - [Healthy eating](https://health.yahoo.com/nutrition/healthy-eating/)\\n    - [Meal delivery](https://health.yahoo.com/nutrition/meal-delivery/)\\n    - [Weight loss](https://health.yahoo.com/nutrition/weight-loss/)\\n    - [Vitamins and supplements](https://health.yahoo.com/nutrition/vitamins-supplements/)\\n  + [Fitness](https://health.yahoo.com/fitness/) \\n    - [Equipment](https://health.yahoo.com/fitness/equipment/)\\n    - [Exercise](https://health.yahoo.com/fitness/exercise/)\\n  + [Women\\'s health](https://health.yahoo.com/womens-health/)\\n  + [Sleep](https://health.yahoo.com/sleep/)\\n  + [Healthy aging](https://health.yahoo.com/healthy-aging/) \\n    - [Hearing](https://health.yahoo.com/healthy-aging/hearing/)\\n    - [Mobility](https://health.yahoo.com/healthy-aging/mobility/)\\n* [Science](https://www.yahoo.com/news/science/)\\n* [Originals](https://www.yahoo.com/guides/originals/)\\n  + [The 360](https://www.yahoo.com/events/elections/)\\n* [Newsletters](https://news.yahoo.com/newsletters/)\\n* [Games](https://www.yahoo.com/games)\\n\\n### \\n\\n* [Health](https://health.yahoo.com/)\\n  + [Wellness](https://health.yahoo.com/wellness/) \\n    - [Nutrition](https://health.yahoo.com/wellness/nutrition/)\\n    - [Fitness](https://health.yahoo.com/wellness/fitness/)\\n    - [Healthy aging](https://health.yahoo.com/wellness/healthy-aging/)\\n    - [Sleep](https://health.yahoo.com/wellness/sleep/)\\n  + [Your body](https://health.yahoo.com/your-body/) \\n    - [Children\\'s health](https://health.yahoo.com/your-body/childrens-health/)\\n    - [Dermatology](https://health.yahoo.com/your-body/dermatology/)\\n    - [Foot health](https://health.yahoo.com/your-body/foot-health/)\\n    - [Hair loss](https://health.yahoo.com/your-body/hair-loss/)\\n    - [Oral health](https://health.yahoo.com/your-body/oral-health/)\\n    - [Sexual health](https://health.yahoo.com/your-body/sexual-health/)\\n    - [Weight management](https://health.yahoo.com/your-body/weight-management/)\\n    - [Women\\'s health](https://health.yahoo.com/your-body/womens-health/)\\n  + [Conditions](https://health.yahoo.com/conditions/) \\n    - [Cardiovascular health](https://health.yahoo.com/conditions/cardiovascular-health/)\\n    - [Digestive health](https://health.yahoo.com/conditions/digestive-health/)\\n    - [Endocrine system](https://health.yahoo.com/conditions/endocrine-system/)\\n    - [Hearing](https://health.yahoo.com/conditions/hearing/)\\n    - [Mental health](https://health.yahoo.com/conditions/mental-health/)\\n* [Parenting](https://www.yahoo.com/lifestyle/family-relationships/)\\n  + [Family health](https://www.yahoo.com/lifestyle/family-relationships/)\\n  + [So mini ways](https://www.yahoo.com/guides/so-mini-ways/)\\n* [Style and beauty](https://www.yahoo.com/lifestyle/style-beauty/)\\n  + [It Figures](https://www.yahoo.com/guides/it-figures/)\\n  + [Unapologetically](https://www.yahoo.com/guides/unapologetically/)\\n* [Horoscopes](https://www.yahoo.com/lifestyle/horoscope/)\\n* [Shopping](https://shopping.yahoo.com/)\\n  + [Style](https://shopping.yahoo.com/style/) \\n    - [Accessories](https://shopping.yahoo.com/style/accessories/)\\n    - [Clothing](https://shopping.yahoo.com/style/clothing/)\\n    - [Luggage](https://shopping.yahoo.com/style/luggage/)\\n    - [Shoes](https://shopping.yahoo.com/style/shoes/)\\n  + [Beauty](https://shopping.yahoo.com/beauty/) \\n    - [Fragrance](https://shopping.yahoo.com/beauty/fragrance/)\\n    - [Hair](https://shopping.yahoo.com/beauty/hair/)\\n    - [Makeup](https://shopping.yahoo.com/beauty/makeup/)\\n    - [Nails](https://shopping.yahoo.com/beauty/nails/)\\n    - [Skincare](https://shopping.yahoo.com/beauty/skincare/)\\n    - [Sunscreen](https://shopping.yahoo.com/beauty/sunscreen/)\\n  + [Health](https://shopping.yahoo.com/health/) \\n    - [Dental](https://shopping.yahoo.com/health/dental/)\\n    - [Fitness](https://shopping.yahoo.com/health/fitness/)\\n    - [Hair loss](https://shopping.yahoo.com/health/hair-loss/)\\n    - [Hearing](https://shopping.yahoo.com/health/hearing/)\\n    - [Mental health](https://shopping.yahoo.com/health/mental-health/)\\n    - [Mobility](https://shopping.yahoo.com/health/mobility/)\\n    - [Nutrition](https://shopping.yahoo.com/health/nutrition/)\\n    - [Personal care](https://shopping.yahoo.com/health/personal-care/)\\n    - [Sexual health](https://shopping.yahoo.com/health/sexual-health/)\\n    - [Sleep](https://shopping.yahoo.com/health/sleep/)\\n    - [Women\\'s health](https://shopping.yahoo.com/health/womens-health/)\\n  + [Home and garden](https://shopping.yahoo.com/home-garden/) \\n    - [Bedding](https://shopping.yahoo.com/home-garden/bedding/)\\n    - [Cleaning](https://shopping.yahoo.com/home-garden/cleaning/)\\n    - [Gardening](https://shopping.yahoo.com/home-garden/gardening/)\\n    - [Kitchen](https://shopping.yahoo.com/home-garden/kitchen/)\\n    - [Outdoor](https://shopping.yahoo.com/home-garden/outdoor/)\\n  + [Pets](https://shopping.yahoo.com/pets/)\\n  + [Tech](https://shopping.yahoo.com/tech/) \\n    - [Accessories](https://shopping.yahoo.com/tech/accessories/)\\n    - [Audio](https://shopping.yahoo.com/tech/audio/)\\n    - [Auto](https://shopping.yahoo.com/tech/auto/)\\n    - [Computers](https://shopping.yahoo.com/tech/computing/)\\n    - [Phones](https://shopping.yahoo.com/tech/phones/)\\n    - [Smart home](https://shopping.yahoo.com/tech/smart-home/)\\n    - [Streaming](https://shopping.yahoo.com/tech/streaming/)\\n    - [TVs](https://shopping.yahoo.com/tech/tvs/)\\n  + [Gift ideas](https://shopping.yahoo.com/gift-ideas/) \\n    - [Best gifts for men](https://shopping.yahoo.com/gift-ideas/article/best-gift-ideas-for-men-200430444.html)\\n    - [Best gift cards](https://shopping.yahoo.com/gift-ideas/article/best-gift-cards-184432258.html)\\n    - [Best gifts for mom](https://shopping.yahoo.com/gift-ideas/article/best-gifts-for-mom-172933189.html)\\n    - [Best gifts for teens](https://shopping.yahoo.com/gift-ideas/article/best-gifts-for-teens-185109070.html)\\n  + [Stores](https://shopping.yahoo.com/stores/) \\n    - [Amazon](https://shopping.yahoo.com/stores/amazon/)\\n    - [Best Buy](https://shopping.yahoo.com/stores/best-buy/)\\n    - [Home Depot](https://shopping.yahoo.com/stores/home-depot/)\\n    - [Macy\\'s](https://shopping.yahoo.com/stores/macys/)\\n    - [Nordstrom](https://shopping.yahoo.com/stores/nordstrom/)\\n    - [Target](https://shopping.yahoo.com/stores/target/)\\n    - [Walmart](https://shopping.yahoo.com/stores/walmart/)\\n    - [Wayfair](https://shopping.yahoo.com/stores/wayfair/)\\n  + [Shopping Guides](https://shopping.yahoo.com/guides/) \\n    - [Best cordless stick vacuums](https://shopping.yahoo.com/home-garden/cleaning/article/best-cordless-stick-vacuums-194920452.html)\\n    - [Best water bottles](https://shopping.yahoo.com/home-garden/kitchen/article/best-water-bottles-151922237.html)\\n    - [Best vacuums](https://shopping.yahoo.com/home-garden/cleaning/article/best-vacuums-tested-and-reviewed-220428339.html)\\n    - [Best air fryers](https://shopping.yahoo.com/home-garden/kitchen/article/best-air-fryers-191551179.html)\\n    - [Best luggage](https://shopping.yahoo.com/style/luggage/article/best-luggage-185322761.html)\\n    - [Best jeans](https://shopping.yahoo.com/style/clothing/article/best-jeans-193623018.html)\\n    - [Best bras](https://shopping.yahoo.com/style/clothing/article/best-bras-152359298.html)\\n    - [Best nontoxic nail polish](https://shopping.yahoo.com/beauty/nails/article/the-best-non-toxic-nail-polish-201830177.html)\\n    - [Best under eye cream](https://shopping.yahoo.com/beauty/skincare/article/best-under-eye-creams-223255282.html)\\n    - [Best skin tightening creams](https://shopping.yahoo.com/beauty/skincare/article/best-skin-tightening-creams-212112383.html)\\n    - [Best coffee makers](https://shopping.yahoo.com/home-garden/kitchen/article/best-single-serve-coffee-maker-215624408.html)\\n  + [Deals](https://shopping.yahoo.com/deals/)\\n  + [Toys and games](https://shopping.yahoo.com/toys-games/)\\n  + [General](https://shopping.yahoo.com/general/)\\n  + [Valentine\\'s Day gifts](https://shopping.yahoo.com/valentines-day-gifts/) \\n    - [Best Valentine\\'s Day gifts](https://shopping.yahoo.com/gift-ideas/article/the-best-valentines-day-gifts-to-shop-for-all-the-loves-of-your-life-213456733.html)\\n    - [Valentine\\'s Day gifts for her](https://shopping.yahoo.com/gift-ideas/article/best-valentines-day-gifts-for-her-165952434.html)\\n    - [Valentine\\'s Day gifts for him](https://shopping.yahoo.com/gift-ideas/article/best-valentines-day-gifts-for-him-154928813.html)\\n* [Food](https://www.yahoo.com/lifestyle/food-drink/)\\n* [Travel](https://travel.yahoo.com/)\\n* [Autos](https://autos.yahoo.com/)\\n  + [EV & Future Tech](https://autos.yahoo.com/ev-and-future-tech/)\\n  + [Classic & Collector](https://autos.yahoo.com/classic-and-collector/)\\n  + [Deals & Buying Guides](https://autos.yahoo.com/deals-and-buying-guides/)\\n  + [Ownership](https://autos.yahoo.com/ownership/)\\n  + [Safety & Recalls](https://autos.yahoo.com/safety-and-recalls/)\\n  + [Policy & Environment](https://autos.yahoo.com/policy-and-environment/)\\n  + [New Vehicles & Reviews](https://autos.yahoo.com/new-vehicles-and-reviews/)\\n  + [Auto Shows](https://autos.yahoo.com/auto-shows/)\\n  + [General](https://autos.yahoo.com/general/)\\n  + [People & Culture](https://autos.yahoo.com/people-and-culture/)\\n* [Gift ideas](https://shopping.yahoo.com/gift-ideas/)\\n* [Buying guides](https://shopping.yahoo.com/guides/)\\n* [Valentine\\'s Day gifts](https://shopping.yahoo.com/gift-ideas/article/the-best-valentines-day-gifts-to-shop-for-all-the-loves-of-your-life-213456733.html)\\n\\n### \\n\\n* [Celebrity](https://www.yahoo.com/entertainment/celebrity/)\\n* [TV](https://www.yahoo.com/entertainment/tv/)\\n* [Movies](https://www.yahoo.com/entertainment/movies/)\\n* [Music](https://www.yahoo.com/entertainment/music/)\\n* [How to Watch](https://www.yahoo.com/guides/how-to-watch/)\\n* [Interviews](https://www.yahoo.com/guides/interviews/)\\n* [Videos](https://www.yahoo.com/guides/videos/)\\n\\n### \\n\\n* [My Portfolio](https://finance.yahoo.com/portfolios/)\\n* [News](https://finance.yahoo.com/news/)\\n  + [Latest](https://finance.yahoo.com/topic/latest-news/)\\n  + [Originals](https://finance.yahoo.com/topic/yahoo-finance-originals/)\\n  + [Premium news](https://finance.yahoo.com/topic/premium-news)\\n  + [Newsletters](https://finance.yahoo.com/news/sign-up-for-yahoo-finances-morning-brief-174158888.html/)\\n  + [Stock market](https://finance.yahoo.com/topic/stock-market-news/)\\n  + [Crypto](https://finance.yahoo.com/topic/crypto/)\\n  + [Earnings](https://finance.yahoo.com/topic/earnings/)\\n  + [Tariffs](https://finance.yahoo.com/topic/tariffs/)\\n  + [Tax Insights via H&R Block](https://finance.yahoo.com/topic/hrb-2026/)\\n  + [More Topics](https://finance.yahoo.com/news/) \\n    - [Economies](https://finance.yahoo.com/topic/economic-news/)\\n    - [Tech](https://finance.yahoo.com/topic/tech/)\\n    - [Housing](https://finance.yahoo.com/topic/housing-market/)\\n* [Markets](https://finance.yahoo.com/markets/)\\n  + [Stocks](https://finance.yahoo.com/markets/stocks/) \\n    - [Most active](https://finance.yahoo.com/markets/stocks/most-active/)\\n    - [Day gainers](https://finance.yahoo.com/markets/stocks/gainers/)\\n    - [Day losers](https://finance.yahoo.com/markets/stocks/losers/)\\n    - [Trending](https://finance.yahoo.com/markets/stocks/trending/)\\n    - [Highest dividend](https://finance.yahoo.com/markets/stocks/highest-dividend/)\\n    - [Small cap](https://finance.yahoo.com/markets/stocks/small-cap-stocks/)\\n    - [Large cap](https://finance.yahoo.com/markets/stocks/large-cap-stocks/)\\n    - [Most expensive](https://finance.yahoo.com/markets/stocks/most-expensive-stocks/)\\n    - [Highest beta](https://finance.yahoo.com/markets/stocks/highest-beta-stocks/)\\n    - [Pink sheet](https://finance.yahoo.com/markets/stocks/pink-sheet-stocks/)\\n    - [Unusual volume](https://finance.yahoo.com/markets/stocks/unusual-volume-stocks/)\\n  + [Crypto](https://finance.yahoo.com/markets/crypto/all/) \\n    - [Most active](https://finance.yahoo.com/markets/crypto/most-active/)\\n    - [Day gainers](https://finance.yahoo.com/markets/crypto/gainers/)\\n    - [Day losers](https://finance.yahoo.com/markets/crypto/losers/)\\n  + [Prediction markets](https://finance.yahoo.com/markets/prediction/trending/) \\n    - [Finance](https://finance.yahoo.com/markets/prediction/finance/)\\n    - [Crypto](https://finance.yahoo.com/markets/prediction/crypto/)\\n    - [Equities](https://finance.yahoo.com/markets/prediction/equities/)\\n    - [Earnings](https://finance.yahoo.com/markets/prediction/earnings/)\\n    - [Tech](https://finance.yahoo.com/markets/prediction/tech/)\\n    - [Economy](https://finance.yahoo.com/markets/prediction/economy/)\\n  + [Private companies](https://finance.yahoo.com/markets/private-companies/highest-valuation/) \\n    - [52 week gainers](https://finance.yahoo.com/markets/private-companies/52-week-gainers/)\\n    - [Recently funded](https://finance.yahoo.com/markets/private-companies/recently-funded/)\\n    - [Most funded](https://finance.yahoo.com/markets/private-companies/most-funded/)\\n  + [Options](https://finance.yahoo.com/markets/options/most-active/) \\n    - [Day gainers](https://finance.yahoo.com/markets/options/gainers/)\\n    - [Day losers](https://finance.yahoo.com/markets/options/losers/)\\n    - [Highest open interest](https://finance.yahoo.com/markets/options/highest-open-interest/)\\n    - [Highest implied volatility](https://finance.yahoo.com/markets/options/highest-implied-volatility/)\\n  + [Sectors](https://finance.yahoo.com/sectors/) \\n    - [Technology](https://finance.yahoo.com/sectors/technology/)\\n    - [Financial services](https://finance.yahoo.com/sectors/financial-services/)\\n    - [Consumer cyclical](https://finance.yahoo.com/sectors/consumer-cyclical/)\\n    - [Communication services](https://finance.yahoo.com/sectors/communication-services/)\\n    - [Healthcare](https://finance.yahoo.com/sectors/healthcare/)\\n    - [Industrials](https://finance.yahoo.com/sectors/industrials/)\\n    - [Consumer defensive](https://finance.yahoo.com/sectors/consumer-defensive/)\\n    - [Energy](https://finance.yahoo.com/sectors/energy/)\\n    - [Basic materials](https://finance.yahoo.com/sectors/basic-materials/)\\n    - [Real estate](https://finance.yahoo.com/sectors/real-estate/)\\n    - [Utilities](https://finance.yahoo.com/sectors/utilities/)\\n  + [Treasury bonds](https://finance.yahoo.com/markets/bonds/)\\n  + [Futures](https://finance.yahoo.com/markets/commodities/)\\n  + [Currencies](https://finance.yahoo.com/markets/currencies/ )\\n  + [World indices](https://finance.yahoo.com/markets/world-indices/)\\n  + [ETFs](https://finance.yahoo.com/markets/etfs/)\\n* [Research](https://finance.yahoo.com/research-hub/screener/)\\n  + [Stock picks](https://finance.yahoo.com/stock-picks)\\n  + [Screeners](https://finance.yahoo.com/research-hub/screener/) \\n    - [Stocks](https://finance.yahoo.com/research-hub/screener/equity/)\\n    - [Most shorted](https://finance.yahoo.com/research-hub/screener/most_shorted_stocks/)\\n    - [Most active penny stocks](https://finance.yahoo.com/research-hub/screener/most_active_penny_stocks/)\\n    - [Analyst strong buy](https://finance.yahoo.com/research-hub/screener/analyst_strong_buy_stocks/)\\n  + [Calendar](https://finance.yahoo.com/calendar/) \\n    - [Earnings](https://finance.yahoo.com/calendar/earnings/)\\n    - [Stock splits](https://finance.yahoo.com/calendar/splits/)\\n    - [IPOs](https://finance.yahoo.com/calendar/ipo/)\\n    - [Economic events](https://finance.yahoo.com/calendar/economic/)\\n  + [Stock comparison](https://finance.yahoo.com/compare/) \\n    - [NVDA vs INTC](https://finance.yahoo.com/compare?comps=NVDA,INTC)\\n    - [NVDA vs AMD](https://finance.yahoo.com/compare?comps=NVDA,AMD)\\n    - [GOOG vs AMZN](https://finance.yahoo.com/compare?comps=GOOG,AMZN)\\n    - [AAPL vs MSFT](https://finance.yahoo.com/compare?comps=AAPL,MSFT)\\n    - [TSLA vs RIVN](https://finance.yahoo.com/compare?comps=TSLA,RIVN)\\n  + [Currency converter](https://finance.yahoo.com/currency-converter/)\\n  + [Advanced charts](https://finance.yahoo.com/chart/%5EGSPC/)\\n  + [Investment ideas](/about/plans/select-plan/investmentIdeas/?.done=%2Fresearch%2Ftrade-ideas%3Fncid%3Ddcm_306158753_490172245_127172993&ncid=dcm_306158753_490172245_127172993)\\n  + [Research reports](/about/plans/select-plan/researchReports/?.done=%2Fresearch%3Fncid%3Ddcm_306158756_490172245_127172993&ncid=dcm_306158756_490172245_127172993)\\n* [Community](https://finance.yahoo.com/community/)\\n* [Personal Finance](https://finance.yahoo.com/personal-finance/)\\n  + [My Money](https://finance.yahoo.com/my-money/)\\n  + [Credit cards](https://finance.yahoo.com/personal-finance/credit-cards/) \\n    - [Compare Credit Cards](https://finance.yahoo.com/personal-finance/credit-cards/compare/)\\n    - [Best 0% APR cards](https://finance.yahoo.com/personal-finance/credit-cards/article/best-zero-percent-apr-credit-cards-202429925.html)\\n    - [Best balance transfer cards](https://finance.yahoo.com/personal-finance/credit-cards/article/best-balance-transfer-credit-cards-123841213.html)\\n    - [Best rewards cards](https://finance.yahoo.com/personal-finance/credit-cards/article/best-rewards-credit-cards-172941111.html)\\n    - [Best travel cards](https://finance.yahoo.com/personal-finance/credit-cards/article/best-travel-rewards-credit-card-172745542.html)\\n  + [Banking](https://finance.yahoo.com/personal-finance/banking/) \\n    - [Best CD rates](https://finance.yahoo.com/personal-finance/banking/article/best-cd-rates-201308688.html)\\n    - [Best high-yield savings accounts](https://finance.yahoo.com/personal-finance/banking/article/best-high-yield-savings-account-171334498.html)\\n    - [Best money market accounts](https://finance.yahoo.com/personal-finance/banking/article/4-percent-interest-money-market-accounts-160154289.html)\\n    - [Best free checking accounts](https://finance.yahoo.com/personal-finance/banking/article/best-free-checking-accounts-195709452.html)\\n    - [Best online banks](https://finance.yahoo.com/personal-finance/banking/article/best-online-banks-225003422.html)\\n  + [Mortgage](https://finance.yahoo.com/personal-finance/mortgages/) \\n    - [Best mortgage lenders](https://finance.yahoo.com/personal-finance/mortgages/article/best-mortgage-lenders-173044403.html)\\n    - [Lowest mortgage rates](https://finance.yahoo.com/personal-finance/mortgages/article/8-strategies-for-getting-the-lowest-mortgage-rate-possible-in-2026-224601956.html)\\n    - [Mortgage refinance](https://finance.yahoo.com/personal-finance/mortgages/article/refinance-mortgage-162831396.html)\\n    - [First time homebuyer](https://finance.yahoo.com/personal-finance/mortgages/article/first-time-home-buyer-195246478.html)\\n    - [Mortgage payment calculator](https://finance.yahoo.com/personal-finance/calculators/mortgage-payment-calculator/)\\n    - [Home affordability calculator](https://finance.yahoo.com/personal-finance/calculators/how-much-home-can-i-afford/)\\n  + [Insurance](https://finance.yahoo.com/personal-finance/insurance/) \\n    - [Find car insurance](https://finance.yahoo.com/personal-finance/insurance/article/cheap-car-insurance-152307402.html)\\n    - [Types of car insurance](https://finance.yahoo.com/personal-finance/insurance/article/types-of-car-insurance-175724082.html)\\n    - [Find life insurance](https://finance.yahoo.com/personal-finance/insurance/article/what-is-life-insurance-200844307.html)\\n  + [Taxes](https://finance.yahoo.com/personal-finance/taxes/) \\n    - [How to file](https://finance.yahoo.com/personal-finance/taxes/article/irs-direct-file-230748915.html)\\n    - [Tax brackets and rates](https://finance.yahoo.com/personal-finance/taxes/article/tax-brackets-165854746.html)\\n    - [Child tax credit](https://finance.yahoo.com/personal-finance/taxes/article/child-tax-credit-2023-170245284.html)\\n    - [Tax extension](https://finance.yahoo.com/personal-finance/taxes/article/tax-extension-220004592.html)\\n    - [Tax refund status](https://finance.yahoo.com/personal-finance/taxes/article/wheres-my-refund-223612874.html)\\n  + [Student loans](https://finance.yahoo.com/personal-finance/student-loans/) \\n    - [Federal vs. private](https://finance.yahoo.com/personal-finance/student-loans/article/are-federal-or-private-loans-better-175200294.html)\\n    - [How to apply](https://finance.yahoo.com/personal-finance/student-loans/article/how-to-apply-for-federal-student-loans-203505397.html)\\n    - [FAFSA 2026-27](https://finance.yahoo.com/personal-finance/student-loans/article/what-is-fafsa-173422253.html)\\n    - [Student loan assistance](https://finance.yahoo.com/personal-finance/student-loans/article/when-do-student-loans-resume-203115948.html)\\n  + [Personal loans](https://finance.yahoo.com/personal-finance/personal-loans/) \\n    - [Best personal loans](https://finance.yahoo.com/personal-finance/personal-loans/article/best-personal-loans-202034980.html)\\n    - [Improve credit score](https://finance.yahoo.com/personal-finance/banking/article/how-to-improve-credit-score-140045472.html)\\n    - [How to get approved](https://finance.yahoo.com/personal-finance/personal-loans/article/how-to-get-approved-for-personal-loan-173728303.html)\\n* [Videos](https://finance.yahoo.com/videos/)\\n  + [Latest](https://finance.yahoo.com/videos/latest/)\\n  + [Editor\\'s picks](https://finance.yahoo.com/videos/editor-picks/)\\n  + [Trending stocks](https://finance.yahoo.com/videos/trending-stocks/)\\n  + [Investing insights](https://finance.yahoo.com/videos/investing-insights/)\\n  + [Live shows](https://finance.yahoo.com/videos/series/) \\n    - [Morning Brief](https://finance.yahoo.com/videos/series/morning-brief/)\\n    - [Opening Bid](https://finance.yahoo.com/videos/series/opening-bid/)\\n    - [Market Catalysts](https://finance.yahoo.com/videos/series/market-catalysts/)\\n    - [Market Domination](https://finance.yahoo.com/videos/series/market-domination/)\\n    - [Market Domination Overtime](https://finance.yahoo.com/videos/series/market-domination-overtime/)\\n    - [Asking for a Trend](https://finance.yahoo.com/videos/series/asking-for-a-trend/)\\n  + [Video podcasts](https://finance.yahoo.com/videos/series/) \\n    - [Stocks in Translation](https://finance.yahoo.com/videos/series/stocks-in-translation/)\\n    - [Trader Talk](https://finance.yahoo.com/videos/series/trader-talk/)\\n    - [Living Not So Fabulously](https://finance.yahoo.com/videos/series/living-fabulously/)\\n    - [The Big Idea](https://finance.yahoo.com/videos/series/big-idea/)\\n    - [Financial Freestyle](https://finance.yahoo.com/videos/series/financial-freestyle/)\\n  + [FA Corner](https://finance.yahoo.com/topic/fa-corner/)\\n  + [ETF Report](https://finance.yahoo.com/topic/etf-report/)\\n  + [Options Unlocked](https://finance.yahoo.com/topic/options-101/)\\n* [Watch Now](https://finance.yahoo.com/live/)\\n\\n### \\n\\n* [Fantasy](https://sports.yahoo.com/fantasy/)\\n  + [News](https://sports.yahoo.com/fantasy/news/)\\n  + [Fantasy football](https://football.fantasysports.yahoo.com/)\\n  + [Best ball](https://bestball.fantasysports.yahoo.com/)\\n  + [Pro Pick \\'Em](https://football.fantasysports.yahoo.com/pickem)\\n  + [College Pick \\'Em](https://football.fantasysports.yahoo.com/college)\\n  + [Fantasy baseball](https://baseball.fantasysports.yahoo.com/)\\n  + [Fantasy hockey](https://hockey.fantasysports.yahoo.com/)\\n  + [Fantasy basketball](https://basketball.fantasysports.yahoo.com/)\\n  + [Download the app](https://sports.yahoo.com/fantasy/mobile/)\\n* [Daily fantasy](https://sports.yahoo.com/dailyfantasy/)\\n* [NFL](https://sports.yahoo.com/nfl/)\\n  + [News](https://sports.yahoo.com/nfl/news/)\\n  + [Scores and schedules](https://sports.yahoo.com/nfl/scoreboard/)\\n  + [Standings](https://sports.yahoo.com/nfl/standings/)\\n  + [Stats](https://sports.yahoo.com/nfl/stats/)\\n  + [Teams](https://sports.yahoo.com/nfl/teams/)\\n  + [Players](https://sports.yahoo.com/nfl/players/)\\n  + [Drafts](https://sports.yahoo.com/nfl/draft/)\\n  + [Injuries](https://sports.yahoo.com/nfl/injuries/)\\n  + [Odds](https://sports.yahoo.com/nfl/odds/)\\n  + [Super Bowl](https://sports.yahoo.com/nfl/topic/super-bowl/)\\n  + [GameChannel](https://sports.yahoo.com/nfl/gamechannel/)\\n  + [Videos](https://sports.yahoo.com/videos/nfl/)\\n* [NBA](https://sports.yahoo.com/nba/)\\n  + [News](https://sports.yahoo.com/nba/news/)\\n  + [Draft](https://sports.yahoo.com/nba/draft/)\\n  + [Scores and schedules](https://sports.yahoo.com/nba/scoreboard/)\\n  + [Standings](https://sports.yahoo.com/nba/standings/)\\n  + [Stats](https://sports.yahoo.com/nba/stats/)\\n  + [Teams](https://sports.yahoo.com/nba/teams/)\\n  + [Players](https://sports.yahoo.com/nba/players/)\\n  + [Injuries](https://sports.yahoo.com/nba/injuries/)\\n  + [Videos](https://sports.yahoo.com/videos/nba/)\\n  + [Odds](https://sports.yahoo.com/nba/odds/)\\n  + [Playoffs](https://sports.yahoo.com/nba/playoffs/)\\n* [MLB](https://sports.yahoo.com/mlb/)\\n  + [News](https://sports.yahoo.com/mlb/news/)\\n  + [Scores and schedules](https://sports.yahoo.com/mlb/scoreboard/)\\n  + [Standings](https://sports.yahoo.com/mlb/standings/)\\n  + [Stats](https://sports.yahoo.com/mlb/stats/)\\n  + [Teams](https://sports.yahoo.com/mlb/teams/)\\n  + [Players](https://sports.yahoo.com/mlb/players/)\\n  + [Odds](https://sports.yahoo.com/mlb/odds/)\\n  + [Videos](https://sports.yahoo.com/videos/mlb/)\\n  + [World Baseball Classic](https://sports.yahoo.com/mlb/world-baseball-classic/)\\n* [NHL](https://sports.yahoo.com/nhl/)\\n  + [News](https://sports.yahoo.com/nhl/news/)\\n  + [Scores and schedules](https://sports.yahoo.com/nhl/scoreboard/)\\n  + [Standings](https://sports.yahoo.com/nhl/standings/)\\n  + [Stats](https://sports.yahoo.com/nhl/stats/)\\n  + [Teams](https://sports.yahoo.com/nhl/teams/)\\n  + [Players](https://sports.yahoo.com/nhl/players/)\\n  + [Odds](https://sports.yahoo.com/nhl/odds/)\\n  + [Playoffs](https://sports.yahoo.com/nhl/stanley-cup-playoffs/)\\n* [College football](https://sports.yahoo.com/college-football/)\\n  + [News](https://sports.yahoo.com/college-football/news/)\\n  + [Scores and schedules](https://sports.yahoo.com/college-football/scoreboard/)\\n  + [Standings](https://sports.yahoo.com/college-football/standings/)\\n  + [Rankings](https://sports.yahoo.com/college-football/rankings/)\\n  + [Stats](https://sports.yahoo.com/college-football/stats/)\\n  + [Teams](https://sports.yahoo.com/college-football/teams/)\\n* [College basketball](https://sports.yahoo.com/college-basketball/)\\n* [Soccer](https://sports.yahoo.com/soccer/)\\n  + [News](https://sports.yahoo.com/soccer/news/)\\n  + [Scores and schedules](https://sports.yahoo.com/soccer/scoreboard/)\\n  + [Premier League](https://sports.yahoo.com/soccer/premier-league/)\\n  + [MLS](https://sports.yahoo.com/soccer/mls/)\\n  + [NWSL](https://sports.yahoo.com/soccer/nwsl/)\\n  + [Liga MX](https://sports.yahoo.com/soccer/ligamx-clausura/)\\n  + [CONCACAF League](https://sports.yahoo.com/soccer/concacaf-league/)\\n  + [Champions League](https://sports.yahoo.com/soccer/champions-league/)\\n  + [La Liga](https://sports.yahoo.com/soccer/la-liga/)\\n  + [Serie A](https://sports.yahoo.com/soccer/serie-a/)\\n  + [Bundesliga](https://sports.yahoo.com/soccer/bundesliga/)\\n  + [Ligue 1](https://sports.yahoo.com/soccer/ligue-1/)\\n  + [World Cup](https://sports.yahoo.com/soccer/world-cup/)\\n* [NFL Draft](https://sports.yahoo.com/nfl/draft/)\\n* [Yahoo Sports AM](https://sports.yahoo.com/newsletters/yahoo-sports-am/)\\n* [Show all](https://sports.yahoo.com/)\\n  + [WNBA](https://sports.yahoo.com/wnba/)\\n  + [Sportsbook](https://sports.yahoo.com/sportsbook/)\\n  + [NCAAF](https://sports.yahoo.com/college-football/)\\n  + [Tennis](https://sports.yahoo.com/tennis/)\\n  + [Golf](https://sports.yahoo.com/golf/)\\n  + [NASCAR](https://sports.yahoo.com/motorsports/nascar/)\\n  + [NCAAB](https://sports.yahoo.com/college-basketball/)\\n  + [NCAAW](https://sports.yahoo.com/college-womens-basketball/)\\n  + [Boxing](https://sports.yahoo.com/boxing/)\\n  + [USFL](https://sports.yahoo.com/usfl/)\\n  + [Cycling](https://sports.yahoo.com/cycling/)\\n  + [Motorsports](https://sports.yahoo.com/motorsports/)\\n  + [Olympics](https://sports.yahoo.com/olympics/beijing-2022/)\\n  + [Horse racing](https://sports.yahoo.com/horse-racing/)\\n  + [GameChannel](https://sports.yahoo.com/mlb/gamechannel/)\\n  + [Rivals](https://n.rivals.com/)\\n  + [Newsletters](https://sports.yahoo.com/newsletters/)\\n  + [Podcasts](https://sports.yahoo.com/podcasts/)\\n  + [Videos](https://sports.yahoo.com/videos/)\\n  + [RSS](https://sports.yahoo.com/syndication/)\\n  + [Jobs](https://sports.yahoo.com/jobs/)\\n  + [Help](https://help.yahoo.com/kb/sports-news)\\n  + [World Cup](https://sports.yahoo.com/soccer/world-cup/)\\n  + [More news](https://sports.yahoo.com/news/)\\n\\n### New on Yahoo\\n\\n* [Creators](https://creators.yahoo.com/)\\n* [Tech](https://tech.yahoo.com/)\\n  + [AI](https://tech.yahoo.com/ai/) \\n    - [Apple Intelligence](https://tech.yahoo.com/ai/apple-intelligence/)\\n    - [ChatGPT](https://tech.yahoo.com/ai/chatgpt/)\\n    - [Claude](https://tech.yahoo.com/ai/claude/)\\n    - [Gemini](https://tech.yahoo.com/ai/gemini/)\\n    - [Meta](https://tech.yahoo.com/ai/meta-ai/)\\n    - [Microsoft Copilot](https://tech.yahoo.com/ai/copilot/)\\n    - [Perplexity](https://tech.yahoo.com/ai/perplexity-ai/)\\n  + [Audio](https://tech.yahoo.com/audio/) \\n    - [Audio deals](https://tech.yahoo.com/audio/deals/)\\n  + [Computing](https://tech.yahoo.com/computing/)\\n  + [Gaming](https://tech.yahoo.com/gaming/) \\n    - [Gaming deals](https://tech.yahoo.com/gaming/deals/)\\n    - [Nintendo](https://tech.yahoo.com/gaming/nintendo/)\\n    - [PC](https://tech.yahoo.com/gaming/pc/)\\n    - [PlayStation](https://tech.yahoo.com/gaming/playstation/)\\n    - [Xbox](https://tech.yahoo.com/gaming/xbox/)\\n  + [Home entertainment](https://tech.yahoo.com/home-entertainment/) \\n    - [TVs](https://tech.yahoo.com/home-entertainment/tvs/)\\n  + [Phones](https://tech.yahoo.com/phones/)\\n  + [Puzzle hints](https://tech.yahoo.com/puzzles/) \\n    - [Connections](https://tech.yahoo.com/puzzles/connections/)\\n    - [Quordle](https://tech.yahoo.com/puzzles/quordle/)\\n    - [Strands](https://tech.yahoo.com/puzzles/strands/)\\n    - [Wordle](https://tech.yahoo.com/puzzles/wordle/)\\n  + [Science](https://tech.yahoo.com/science/) \\n    - [Space](https://tech.yahoo.com/science/space/)\\n  + [Streaming](https://tech.yahoo.com/streaming/) \\n    - [Streaming reviews](https://tech.yahoo.com/streaming/reviews/)\\n  + [Tech News](https://tech.yahoo.com/news/)\\n  + [VPN](https://tech.yahoo.com/vpn/) \\n    - [VPN deals](https://tech.yahoo.com/vpn/deals/)\\n  + [Deals](https://tech.yahoo.com/deals/)\\n  + [More](#) \\n    - [Apps](https://tech.yahoo.com/apps/)\\n    - [AR and VR](https://tech.yahoo.com/ar-vr/)\\n    - [Business](https://tech.yahoo.com/business/)\\n    - [Cameras](https://tech.yahoo.com/cameras/)\\n    - [Cybersecurity](https://tech.yahoo.com/cybersecurity/)\\n    - [Entertainment](https://tech.yahoo.com/entertainment/)\\n    - [General](https://tech.yahoo.com/general/)\\n    - [Reviews and guides](https://tech.yahoo.com/reviews-and-guides/)\\n    - [Smart home](https://tech.yahoo.com/home/)\\n    - [Social media](https://tech.yahoo.com/social-media/)\\n    - [Transportation](https://tech.yahoo.com/transportation/)\\n    - [Wearables](https://tech.yahoo.com/wearables/)\\n* [Local services](https://local.yahoo.com/)\\n  + [Moving](https://local.yahoo.com/movers/)\\n  + [Roofing](https://local.yahoo.com/roofing/)\\n  + [Painting](https://local.yahoo.com/painting/)\\n  + [Plumbing](https://local.yahoo.com/plumbing/)\\n\\n* [Terms](https://guce.yahoo.com/terms?locale=en-US)\\n* [Privacy](https://guce.yahoo.com/privacy-policy?locale=en-US)\\n* [Your Privacy Choices](https://guce.yahoo.com/state-controls?locale=en-US&state=DE)\\n* [Feedback](https://yahoo.uservoice.com/forums/952723-finance-b3)\\n\\n© 2026 All rights reserved.\\n\\n[About our ads](https://legal.yahoo.com/us/en/yahoo/privacy/adinfo/index.html)  [Advertising](https://www.adtech.yahooinc.com/advertising/solutions)  [Careers](https://www.yahooinc.com/careers/)\\n\\n# Yahoo Finance\\n\\n [Yahoo Finance](https://finance.yahoo.com/)\\n\\n[Mail](https://mail.yahoo.com/)\\n\\n[Sign in](https://login.yahoo.com/?.lang=en-US&src=finance)\\n\\n[## Prediction markets are now on Yahoo Finance\\n\\nGo to hub](/markets/prediction/trending/?ncid=100003406)\\n\\n# Microsoft Corp (MSFT) Q1 2025 Earnings Call Highlights: Strong Cloud Growth Amid AI ...\\n\\nGuruFocus News\\n\\n4 min read\\n\\nIn this article: \\n\\n* [StockStory Top Pick](https://stockstory.org/high-quality/top-6-to-buy-this-week?partner=yahoo&utm_source=yahoo&utm_medium=content_ticker&utm_campaign=contenthighqualitystock)\\n\\n  [MSFT\\n\\n  -0.74%](/quote/MSFT/ \"MSFT\")\\n\\n* **Revenue:** $65.6 billion, up 16%.\\n* **Earnings Per Share (EPS):** $3.30, an increase of 10%.\\n* **Microsoft Cloud Revenue:** $38.9 billion, up 22%.\\n* **Commercial Bookings:** Increased 30% and 23% in constant currency.\\n* **Commercial Remaining Performance Obligation:** $259 billion, up 22% and 21% in constant currency.\\n* **Operating Income:** Increased 14%; operating margins at 47%.\\n* **Productivity and Business Processes Revenue:** $28.3 billion, up 12% and 13% in constant currency.\\n* **Intelligent Cloud Revenue:** $24.1 billion, up 20% and 21% in constant currency.\\n* **Azure and Other Cloud Services Revenue:** Grew 33% and 34% in constant currency.\\n* **More Personal Computing Revenue:** $13.2 billion, up 17%.\\n* **Gaming Revenue:** Increased 43% and 44% in constant currency.\\n* **Free Cash Flow:** $19.3 billion, down 7% year over year.\\n* **Capital Expenditures:** $20 billion.\\n* **Cash Flow from Operations:** $34.2 billion, up 12%.\\n* **LinkedIn Revenue:** Increased 10% and 9% in constant currency.\\n* **Dynamics Revenue:** Grew 14%, driven by Dynamics 365, which grew 18% and 19% in constant currency.\\n\\n* [Warning! GuruFocus has detected 4 Warning Sign with MSFT.](https://www.gurufocus.com/term/gf-score/MSFT)\\n\\nRelease Date: October 30, 2024\\n\\nFor the complete transcript of the earnings call, please refer to the [full earnings call transcript](https://finance.yahoo.com/quote/MSFT).\\n\\n### Positive Points\\n\\n* Microsoft Cloud revenue surpassed $38.9 billion, marking a 22% increase, driven by strong demand for AI and cloud services.\\n* AI business is on track to surpass an annual revenue run rate of $10 billion next quarter, making it the fastest-growing business in Microsoft\\'s history.\\n* Azure and other cloud services revenue grew 33% in constant currency, with healthy consumption trends.\\n* Microsoft 365 Copilot adoption is accelerating, with nearly 70% of the Fortune 500 using it, and customers continue to adopt it at a faster rate than any other new Microsoft 365 suite.\\n* LinkedIn revenue increased 10%, with record engagement and growth across all lines of business.\\n\\n### Negative Points\\n\\n* Microsoft Cloud gross margin percentage decreased by 2 points year over year, driven by scaling AI infrastructure.\\n* Operating expenses increased by 12%, partly due to the Activision acquisition, impacting overall profitability.\\n* Free cash flow decreased by 7% year over year, reflecting higher capital expenditures to support cloud and AI offerings.\\n* Supply constraints, particularly in AI infrastructure, are impacting Azure\\'s ability to meet demand, leading to potential growth deceleration.\\n* The Activision acquisition had a negative $0.05 impact on earnings per share due to purchase accounting adjustments and related costs.\\n\\n### Q & A Highlights\\n\\n**Q**: What are the internal and external constraints Microsoft faces in investing in AI innovations, particularly regarding the funding of future generations of foundational models and building out capacity sustainably? **A**: Satya Nadella, CEO, explained that capital outlay for AI training is rate-limited by monetization of inference. Microsoft allocates capital based on demand signals, similar to cloud infrastructure. External constraints include data center (DC) and power availability, which are being addressed to match supply and demand by the second half of the fiscal year.\\n\\n**Q**: Why is Azure\\'s growth expected to decelerate in Q2 despite strong performance in Q1? **A**: Amy Hood, CFO, noted that the deceleration is primarily due to supply pushouts affecting AI supply, not a decline in underlying consumption growth. The company expects stable consumption growth from Q1 to Q2 and anticipates acceleration in the second half of the year as more supply becomes available.\\n\\n**Q**: How does Microsoft view its relationship with OpenAI, and how does it manage CapEx demands from this partnership? **A**: Satya Nadella emphasized the mutual success of the partnership, with Microsoft providing infrastructure for OpenAI\\'s model innovations. Amy Hood added that Microsoft is committed to meeting OpenAI\\'s demand signals while also serving broader customer needs, which drives their capital investment strategy.\\n\\n**Q**: How does Microsoft plan to monetize AI inference, and what impact will it have on the company\\'s financials? **A**: Satya Nadella highlighted that Microsoft\\'s AI business is already generating significant revenue from inference, with products like GitHub Copilot and M365 Copilot driving demand. The company focuses on real enterprise demand rather than selling raw GPUs for training, ensuring high-quality revenue.\\n\\n**Q**: Can you explain the evolution from Copilot to agents and autonomous agents in Microsoft\\'s AI strategy? **A**: Satya Nadella described a system comprising Copilot, Copilot Studio, agents, and autonomous agents. Copilot serves as the UI layer for AI, while Copilot Studio allows for extending capabilities and building agents. Autonomous agents operate independently but interact with Copilot for exceptions, forming a comprehensive AI system.\\n\\nFor the complete transcript of the earnings call, please refer to the [full earnings call transcript](https://finance.yahoo.com/quote/MSFT).\\n\\nThis article first appeared on [GuruFocus](https://www.gurufocus.com/news/2575531/microsoft-corp-msft-q1-2025-earnings-call-highlights-strong-cloud-growth-amid-ai-infrastructure-challenges?r=caf6fe0e0db70d936033da5461e60141).\\n\\n[AGB](https://guce.yahoo.com/terms?locale=en-US)  und [Datenschutzerklärung](https://guce.yahoo.com/privacy-policy?locale=en-US)\\n\\n[Your Privacy Choices](https://guce.yahoo.com/state-controls?locale=en-US&state=DE)\\n\\n[More Info](/more-info)\\n\\n---\\n\\n\\n\\n## Empfohlene Nachrichtenartikel\\n\\n '},\n",
              " {'title': '🔴WATCH LIVE: Microsoft Q1 2025 Earnings Call | $MSFT',\n",
              "  'url': 'https://www.youtube.com/watch?v=Qbna4xKBBRU',\n",
              "  'content': \"Microsoft Q1 2025 GAAP EPS $3.30 Beats $3.09 Estimate, Sales $65.60B Beat $64.51B Estimate\\n\\r\\nLooking for a transcript of this call? Check out the Benzinga Earnings Call Transcripts API - \\r\\n\\r\\n🌐💻Find more coverage on www.benzinga.com\\r\\n\\r\\n📃🖊 Sign up for Benzinga's Trading Competition Powered by TradeZero for your chance to win up to $30,000! - \\r\\n\\r\\nFollow us on socials:\\r\\n📷 Instagram: www.instagram.com/benzinga\\r\\n👨\\u200d👩\\u200d👦📕Facebook: www.facebook.com/benzinga\\r\\n⏱TikTok: www.tiktok.com/benzinga\\r\\n🐤Twitter: twitter.com/benzinga [...] to last quarter demand continues to be higher than our available capacity non- AI growth Trends were also in line with expectations in total and across regions as customers continued to migrate and modernize on the Azure platform the non AI Point contribution to Azure growth was sequentially lower by approximately 1 point in our on premises server business Revenue decreased 1% lower than expected transactional purchasing ahead of the Windows Server 2025 launch as well as lower purchasing of licenses running in multicloud environments was mostly offset by the benefit from in Period Revenue recognition noted earlier Enterprise and partner Services Revenue decreased 1% and was relatively unchanged in constant currency segment gross margin dollars increased 15% and gross margin percentage [...] more than offset by a decline in devices as the trends from q1 continue search and news advertising xtac Revenue growth should be in the high teens with continued growth in both volume and revenue per search this will be higher than overall search and news advertising Revenue growth which we expect to be in the high single digits and in gaming we expect Revenue to decline in the high single digits due to Hardware we expect Xbox content and services Revenue growth to be relatively flat we're excited about last week's launch of Call of Duty where we saw the most Game Pass subscriber ads we've ever seen on a launch day there are two things about the launch that are different than the Call of Duty launch a year ago where Revenue was mostly recognized in the quarter of purchase first the game\",\n",
              "  'score': 0.95598555,\n",
              "  'raw_content': \"# 🔴WATCH LIVE: Microsoft Q1 2025 Earnings Call | $MSFT\\n## Benzinga\\n293000 subscribers\\n42 likes\\n\\n### Description\\n8109 views\\nPosted: 30 Oct 2024\\nMicrosoft Q1 Earnings Highlights: 'AI-Driven Transformation Is Changing Work,' Company Beats Revenue, EPS Estimates - https://www.benzinga.com/news/earnings/24/10/41636770/microsoft-q1-earnings-highlights-ai-driven-transformation-is-changing-work-company-beats-revenue-ep\\n\\nMicrosoft Q1 2025 GAAP EPS $3.30 Beats $3.09 Estimate, Sales $65.60B Beat $64.51B Estimate\\n\\r\\nLooking for a transcript of this call? Check out the Benzinga Earnings Call Transcripts API - https://www.benzinga.com/apis/cloud-p...\\r\\n\\r\\n🌐💻Find more coverage on www.benzinga.com\\r\\n\\r\\n📃🖊 Sign up for Benzinga's Trading Competition Powered by TradeZero for your chance to win up to $30,000! - https://benzingapartners.go2cloud.org...\\r\\n\\r\\nFollow us on socials:\\r\\n📷 Instagram: www.instagram.com/benzinga\\r\\n👨\\u200d👩\\u200d👦📕Facebook: www.facebook.com/benzinga\\r\\n⏱TikTok: www.tiktok.com/benzinga\\r\\n🐤Twitter: twitter.com/benzinga\\r\\n\\r\\nDisclaimer: This live stream is for informational and educational purposes only. The content featured, including earnings calls, is publicly available and sourced from respective company disclosures. Benzinga is not affiliated with the companies being discussed, nor do we claim ownership of the material presented. Trading in financial markets involves significant risk, and there is no guarantee of profit. The information provided by any financial product or service is for educational purposes and should not be considered as financial advice. Before making any investment decisions, it's important to conduct thorough research and consult with a qualified financial advisor. Past performance is not indicative of future results. Always invest what you can afford to lose and be aware of the potential for loss in any investment strategy.\\r\\n\\r\\n#Microsoft #ArtificialIntelligence $MSFT\\n\\n4 comments\\n### Transcript:\\nbe for for [Music] [Applause] [Music] make me make me make me make me [Music] bab B Bab [Music] [Music] I [Music] [Applause] [Music] a a [Music] h [Music] a [Music] n [Music] [Applause] [Music] [Music] [Applause] [Music] [Applause] [Music] oh n [Music] we [Music] o [Music] yeah sh [Music] greetings and welcome to the Microsoft fiscal year 2025 first quarter earnings conference call at this time all participants are on a listen only mode a question and answer session will follow the formal presentation if anyone should require operator assistance during the conference please press star zero on your telephone keypad as a reminder this conference is being recorded it is now my pleasure to introduce your host Brett Iverson vice president of investor relations please go ahead good afternoon and thank you for joining us today on the call with me are Sati Nadella chairman and chief executive officer Amy Hood chief finan officer Alice Jala Chief accounting officer and Keith dolliver corporate secretary and Deputy General Counsel on the Microsoft invest relations website you can find our earnings press release and financial summary slide deck which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between Gap and non-gaap financial measures we have recast certain prior period amounts to reflect the fy2 changes to the composition of our segments announced in August 2024 additional details including FY 23 and FY 24 recast segment Revenue operating income and product and service level Revenue can be found in the financial statements file on the investor relations website more detailed Outlook slides will also be available on the Microsoft invest relations website when we provide Outlook commentary on today's call on this call we we will discuss certain non-gap items the non-gaap financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with gap they are included as additional clarifying items to Aid investors in further understanding the company's first quarter performance in addition to the impact these items and events have [Music] on all growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted we will also provide growth rates in constant currency when available as a framework for assessing how our underlying businesses performed excluding the effect of foreign currency rate fluctuations where growth rates are the same in constant currency we will refer to the growth rate only we will post our prepared remarks to website immediately following the call until the complete transcript is available today's call is being webcast live live and recorded if you ask a question it will be included in our live Transmission in the transcript and in any future use of the recording you can replay the call and view the transcript on the Microsoft invest relations website during this call we'll be making forward-looking statements which are predictions projections or other statements about future events these statements are based on current expectations and assumptions that are subject to risks and uncertainties actual results could materially differ because of factors discussed in today's earnings press release in the comments made during this conference call and in the risk factor section of our form 10K forms 10q and other reports and filings with the Securities and Exchange Commission we do not undertake any duty to update any forward-looking statement and with that I'll turn the call over to Saia thank you Brett we are off to a solid start to our fiscal year driven by continued strength of Microsoft cloud which surpassed $8.9 billion in Revenue up 22% AI driven transformation is changing work work artifacts and workflow across every role function and business process helping customers Drive New Growth and operating leverage all up our AI business is on track to surpass an annual revenue run rate of $10 billion next quarter which will make it the fastest business in our history to reach this Milestone now I'll highlight examples of our progress starting with infrastructure Azure took share this quarter we are seeing continued growth in Cloud migration Azure Arc now has over 39,000 customers across every industry including American Tower CTT L'Oreal up more than 80% year-over-year we now have data centers in over 60 regions around the world and this quarter we announced new cloud and AI infrastructure investments in Brazil Italy Mex Mexico and Sweden as we expand our capacity in line with our long-term demand signals at the Silicon layer a new cobalt 100 VMS are being used by companies like datab bricks elastic seamen Snowflake and synapsis to power their general purpose workloads at up to 50% better price performance than previous generations on top of this we're building out our next Generation AI infrastructure innovating across the full stack to optimize our Fleet for AI workloads we offer the broadest selection of AI accelerators including our first party accelerator Maya 100 as well as the latest gpus from AMD and Nvidia in fact we're the first Cloud to bring up nvidia's Blackwell system with gb200 power AI servers our partnership with open AI also continues to deliver results we have an economic interest in a company that has grown significantly in value and we have built differentiated IP and are driving Revenue momentum more broadly with Azure AI we are building an endtoend app platform to help customers build their own co-pilots and agents Azure open AI usage more than doubled over the past six months as both digital natives like grammarly and Harvey as well as established Enterprises like Bajaj Finance Hitachi KT and LG move apps from test to production GE Aerospace for example used Azure open AI to build a new digital assistant for all 52,000 of its employees in just 3 months it has been used to conduct over 500,000 internal queries and process more than 200,000 documents and this quarter we added support for open ai's newest model family 01 we're also bringing industry specific models to Azure AI including a collection of best-in-class multimodel models for medical imaging and with GitHub models we now provide access to our full model catalog directly within the GitHub developer workflow Azure AI is also increasingly an onramp to our data and analytics Services as developers build new AI apps on Azure we have seen an acceleration of azure Cosmos DB and Azure SQL DB hyperscale usage as customers like Air India Nova Nordisk telefonica Toyota motor North America and unipa take advantage of capabilities purpose build built for AI applications and with Microsoft fabric we provide a single AI powered platform to help customers like Chanel ey KPMG Swissair and syo unify their data across clouds we now have over 16,000 paid fabric customers over 70% of the Fortune 500 now on to developers get up copilot is changing the way the world builds software Copilot Enterprise customers increase 55% quarter over quarter as companies like AMD and flutter entertainment tailor co-pilot to their own code base and we are introducing the next phase of AI code generation making GitHub co-pilot agentic across the developer workflow giup co-pilot workspace is a developer environment which leverages Agents from start to finish so developers can go from spec to plan to code all in natural language co-pilot autofix is an AI agent that helps developers at companies like Assyrian and Auto Group fix vulnerabilities in their code over three times faster than it would take them on their own we're also continuing to build on github's open platform ethos by making more models available via GitHub co-pilot and we're expanding the reach of GitHub to a new segment of developers introducing GitHub spark which enables anyone to build apps in natural language already we have brought generative AI to power platform to help customers use low code no code tools to cut costs and development time to date nearly 600,000 organizations have used AI powered capabilities in Power Platform up Forex year-over-year citizen developers at ZF for example built apps simply by describing what they need using natural language and this quarter we introduced new ways for customers to apply AI to streamline complex workflows with power automate now on to work we launched the next wave of Microsoft 365 co-pilot Innovation last month bringing together web work and Pages as the new design system for knowledge work pages is the First new digital artifact for the AI age and it's designed to help you ideate with AI and collaborate with other people we've also made Microsoft 365 co-pilot responses 2x faster and improved response quality by nearly 3x this Innovation is driving accelerated usage and the number of people using Microsoft 365 daily more than doubled quarter over quarter we're also seeing increased adoption from customers in every industry as they use Microsoft 365 co-pilot to drive real business value vone for example will roll out Microsoft 365 co-pilot to 68,000 employees after a trial showed that on average they saved three hours per person per week and UBS will deploy 50,000 seats in our largest finser deal to date and we continue to see Enterprise customers coming back to buy more seats all up nearly 70% of the Fortune 500 now use Microsoft 365 co-pilot and customers continue to adopt it as a faster rate than any other new Microsoft 365 Suite co-pilot is the UI for AI and with Microsoft 365 co-pilot copilot studio and agents and now autonomous agents we have built an endtoend system for AI business transformation with co-pilot Studio organizations can build and connect Microsoft 365 co-pilot to autonomous agents which then delegate to co-pilot when there is an exception more than 100,000 organizations from urew Standard Bank and Thompson Reuters to Virgin money and Zurich Insurance have used co-pilot Studio to date up over 2x quarter over quarter more broadly we are seeing AI drive a fundamental change in the business applications Market as customers shift from Legacy apps to AI first business processes Dynamics 365 continues to take share as organizations like Evon Heineken and Lexar chose our apps over other providers and monthly active users of co-pilot across our CRM and Erp portfolio increased over 60% quarter over quarter our Dynamics 365 contact center is also winning customers like curries L Crosset and rxo as it brings generative AI to every customer engagement Channel and just last week we added 10 outof the-box autonomous agents to Dynamics 365 that helps customers automatically qualify sales leads track suppliers and work hand inand with service reps to resolve issues they're also bringing AI to Industry specific workflows one year in tax co-pilot is now documenting over one .3 million physician patient encounters each month at over 500 healthc care organizations like Baptist Medical Group Baya Scott and White gram Baltimore Medical Center Novant Health and Overlake Medical Center it is showing faster Revenue growth than gith up copilot did in this first year and new features extend Dax Beyond notes helping Physicians automatically draft referrals after visit instructions and diagnostic evidence on top of all this AI Innovation Microsoft teams usage remains at alltime highs as people use it to streamline all their Communications nearly 75% of our teams Enterprise customers now buy premium phone or rooms when it comes to Windows our new class of co-pilot plus PCS is winning new customers they offer best-in-class AI capability performance and value AMD Intel and Qualcomm now all support copilot plus PCS this quarter we also introduced new AI experience only available on copilot plus PCS like click Todo which places an interactive overlay over your desktop to suggest next best actions and as we approach the end of support for Windows 10 a year from now we are well positioned to transition our customers to Windows 11 ensuring they benefit from enhanced features and security improvements we've introduced over the past few years now on to security we continue to Prior prioritize security above all else with our secure future initiative we have dedicated the equivalent of 34,000 full-time Engineers to address the highest priority security tasks we have made significant progress to better protect tenants identities networks and Engineering Systems and we have created new processes to ensure security is prioritized at every level of the company and we continue to take what we learn and turn it into Innovations across our products security co-pilot for example is being used by companies in every industry including Clifford chance intessa sen Paulo and shell to perform SE Ops tasks faster and more accurately and we are now helping customers protect their AI deployments too customers have used Defender to discover and secure more than 750,000 gen app instances and use perview to audit over a billion co-pilot interactions to meet their compliance obligations and all up we continue to take share across all major categories we serve and are consistently recognized by top analysts as a leader in 20 categories more than any other vendor now let me turn to our consumer businesses starting with LinkedIn member growth continues to accelerate with markets in India and Brazil both growing at double digits we're also seeing record engagement as we introduce new ways for our more than 1 billion members to connect sell Services get hired and share knowledge our investments in Rich formats like video strengthen our leadership in B2B advertising and amplify the value we deliver to our customers weekly immersive video views increase 6X quarter over quarter and Total video viewership on LinkedIn is up 36% eurover year our AI power tools also continue to transform how people sell learn and higher in sales new AI features help every team member perform at the level of top sellers and drive more profitable growth in learning just yesterday we announced updates to our coaching experience including personalized Career Development plans linkedin's first agent hiring assistant will help hirers find qualified candidates Faster by tackling the most timec consuming tasks already hirers who use AI assistant messages see a 44% higher acceptance rate compared to those who don't and hiring business continues to take share now want to search advertising in news with co-pilot we seeing the first step towards creating a new AI companion for everyone with new co-pilot experience we introduced earlier this month includes a refresh design and tone along with improved speed and fluency across the web and mobile and it includes Advanced capabilities like voice and vision that make it more delightful and useful and feel more natural you can both browse and converse with co-pilot simultaneously because co-pilot sees what you see more broadly AI is also transforming search browsers and digital advertising and we continue to take share across being an edge being xstack Revenue growth outpace the suchar market now on to gaming one year since we closed our acquisition of Activision Blizzard King we have focused on building a business position for long-term growth driven by higher margin content and services you already see this transformation in our results as we diversify the ways that Gamers access our content we set new records for monthly active users in the quarter as more players than ever play our games across devices and on the Xbox platform Game Pass also set a new q1 record for total revenue and average revenue per subscriber and as we look ahead our IP across our Studios has never been stronger last week's launch of Black Ops 6 was the biggest Call of Duty release ever setting a record for day one players as well as Game Pass subscriber ads on launch day and unit sales on PlayStation and steam were also up over 60% Euro year this speaks to our strategy of meeting Gamers where they are by enabling them to play more games across the screens they spend their time on in closing we're rapidly innovating to expand our opportunity across our commercial and consumer businesses in 3 weeks time we will hold our ignite conference and I look forward to sharing more then about how we are helping every business function use AI to drive growth in this new era with that let me turn it over to Amy thank you Saia and good afternoon everyone this quarter Revenue was 65.6 billion up 16% and earnings per share was $3.30 an increase of 10% with strong execution by our Sal teams and partners we delivered a solid start to our fisal year with double-digit top and bottom line growth we also saw continued share gains across many of our businesses in our Commercial Business increased demand and growth in long-term commitments to our Microsoft cloud platform drove our results commercial bookings were ahead of expectations and increased 30% and 23% in constant currency results were driven by strong execution across our core annuity sales motions and growth in the number of 10 million plus contracts for both Azure and Microsoft 365 additionally we also saw an increase in the number of a $100 million plus contracts for Azure commercial remaining performance obligation increased 22% and 21% in constant currency to $259 billion roughly 40% will be recognized in Revenue in the next 12 months up 17% year-over-year the remaining portion recognized beyond the next 12 months increased 20 7% and this quarter our annuity mix increased to 98% in addition to commercial results that were in line with expectations we also saw some benefit from in Period Revenue recognition across Microsoft 365 commercial Azure and our on premises server business at a company level Activision contributed a net impact of approximately three points to revenue growth was a two-point drag on operating income growth and had a negative 5cent impact to earning per share a reminder that this net impact includes adjusting for the movement of Activision content from our prior relationship as a third party partner to first party and includes $91 million from purchase accounting adjustments integration and transaction related costs FX did not have a significant impact on our results and was roughly in line with expectations on total company Revenue segment level Revenue cogs and operating expense growth Microsoft cloud Revenue was 38 .9 billion and grew 22% roughly in line with expectations Microsoft cloud grow margin percentage decreased 2.0 over-year to 71% this was slightly better than expected due to Improvement in Azure although the gross margin percentage decrease year-over-year continues to be driven by scaling our AI infrastructure company gross margin dollars increased 133% and 14% in constant currency and gross margin percentage with 69% down 2.0 over-year driven by the lower Microsoft cloud gross margin noted earlier as well as the impact from purchase accounting adjustments integration and transaction related cost from the Activision acquisition operating expenses increased 12% lower than expected due to our focus on cost efficiencies and ongoing prioritization work operating expense growth included nine points from the Activision acquisition at a total company level head count at the end of September was 8% higher than a year ago excluding the growth from the Activision acis position head count was 2% higher operating income increased 14% And operating margins were 47% down one point year-over-year excluding the net impact from the Activision acquisition operating margins were up one point as we continue to drive efficiencies across our businesses as we invest in AI infrastructure and capabilities now to our segment results revenue from productivity and business processes was 28.3 billion and grew 12% and 13% % in constant currency ahead of expectations driven by better than expected results across all businesses M365 commercial Cloud Revenue increased 15% and 16% in constant currency with business trends that were as expected the better than expected result was due to a small benefit from the n period Revenue recognition noted earlier our growth was primarily driven by E5 as well as M365 co-pilots paid M365 commercial seats grew 8% year-over-year with installed base expansion across all customer segments seat growth was driven by our small and medium business and Frontline worker offerings M365 commercial Cloud Revenue represents nearly 90% of total M365 commercial products and cloud services M365 commercial products Revenue increased 2% and 3% in constant currency ahead of expectations primarily due to the benefit from in Period Revenue recognition noted earlier M365 consumer products and cloud services Revenue increased 5% and 6% % in constant currency M365 consumer Cloud Revenue increased 6% and 7% in constant currency with continued momentum in M365 consumer subscriptions which grew 10% to 84.4 million M365 consumer Cloud Revenue represents 85% of total M365 consumer products and cloud services LinkedIn Revenue increased 10% and 9% in constant currency slightly ahead of expectations with growth across all lines of business Dynamics Revenue grew 14% driven by Dynamics 365 which grew 18% and 19% in constant currency with continued growth across all workloads and continued share gains as a reminder Dynamics 365 represents about 90% of total Dynamics Revenue segment gross margin dollars increase 11% and 12% in constant currency and gross margin percentage decrease slightly year-over-year driven by scaling our AI infrastructure operating expenses increased 2% and operating income increased 16% next the intelligent Cloud segment Revenue was $24.1 billion increasing 20% and 21% in constant currency in line with expectations Azure and other cloud services Revenue grew 33% and 34% in constant currency with healthy consumption trends that were in line with expectations the better than expected result was due to the small benefit from in period Revenue recognition noted earlier Azure growth included roughly 12 points from AI Services similar to last quarter demand continues to be higher than our available capacity non- AI growth Trends were also in line with expectations in total and across regions as customers continued to migrate and modernize on the Azure platform the non AI Point contribution to Azure growth was sequentially lower by approximately 1 point in our on premises server business Revenue decreased 1% lower than expected transactional purchasing ahead of the Windows Server 2025 launch as well as lower purchasing of licenses running in multicloud environments was mostly offset by the benefit from in Period Revenue recognition noted earlier Enterprise and partner Services Revenue decreased 1% and was relatively unchanged in constant currency segment gross margin dollars increased 15% and gross margin percentage decreased three points year-over-year driven by scaling our AI infrastructure operating expenses increased 8% and operating income grew 18% now to more personal Computing Revenue was 13.2 billion increasing 177% with 15 points of net impact from the Activision acquisition results were above expectations driven by Gaming and search Windows OEM and devices Revenue increased 2% year-over-year as better than expected results in Windows OEM due to mix shift to higher mon izing markets was partially offset by the lower than expected results in devices due to execution challenges in the commercial segment search in news advertising Revenue xtac increased 18% and 19% in constant currency ahead of expectations primarily due to continued execution Improvement we saw rate expansion in addition to healthy volume growth in both Edge and Bing and in Gaming revenue increased 43% and 44% in constant currency with 43 points of net impact from the Activision acquisition results were ahead of expectation driven by stronger than expected performance in both first and third party content as well as consoles Xbox content and services Revenue increased 61% with 53 points of net impact from the Activision acquisition segment gross margin dollars increased 16% and 177% in constant currency with 12 points of net impact from the Activision acquisition gross margin percentage was relatively unchanged year over-year our strong execution on margin Improvement in gaming and search was offset by sales mix shift to those businesses operating expenses increased 49% with 51 points from the Activision acquisition operating income decreased 4% now back to Total company results Capital expenditures including Finance leases were $20 billion in line with expectations and cash paid for ppne was $14.9 billion roughly half of our cloud and AI related spend continues to be for long libed assets that will support monetization over the next 15 years and Beyond the remaining cloud and AI spend is primarily for servers both CPUs and gpus to serve customers based on demand signals cash flow from operations was $ 34.2 billion up 12% driven by strong Cloud Billings and collections partially offset by higher supplier employee and tax payments free cash flow was 19.3 billion down 7% year-over-year reflecting higher Capital expenditures to support our cloud and AI offerings this quarter other income expense was negative $283 million significantly more favorable than anticipated due to foreign currency remeasurement and net gains on investments our losses on investments accounted for under the equity method were as expected our effective tax rate was approximately 19% and finally we returned 9 billion dollars to shareholders through dividends and share repurchases now moving to our Q2 Outlook which unless specifically noted otherwise is on a US dollar basis first FX with the weaker US dollar and assuming current rates remain stable we expect FX to increase total revenue and segment level Revenue growth by less than one point we expect FX to have no meaningful impact to cogs or operating expense growth our Outlook has many of the trends we on q1 continue through Q2 customer demand for our differentiated Solutions should drive another quarter of strong growth in commercial bookings we expect strong growth on a growing XPR base driven by increased long-term commitments to our platform and strong execution across core annuity sales motions as a reminder larger long-term measure contracts which are more unpredictable in their timing can drive increased quarterly volatility and our bookings growth rate Microsoft cloud gross margin percentage should be roughly 70% down your overy year driven by the impact of scaling our AI infrastructure we expect Capital expenditures to increase on a sequential basis given our cloud and AI demand signals as I said last quarter we will stay aligned and if needed adjust to the demand signals we see as a reminder there can be quarterly spin variability from cloud infrastructure build outs and the timing of delivery of Finance leases next segment guidance starting with productivity and business processes we are the market leader when it comes to knowledge-based co-pilots and agents in the Enterprise space and we are focused on continuing to gain share across our productivity Solutions therefore we expect Revenue in productivity and business processes to grow between 10 and 11% in constant currency are 28.7 to 29 billion US M36 5 commercial Cloud Revenue growth should be approximately 14% in constant currency with moderating seat growth across customer segments and arpu growth through E5 and M365 co-pilots for H2 we expect Revenue growth to remain relatively stable compared to Q2 we continue to see growth in M365 co-pilot seats and we expect the related Revenue to continue to grow gradually over time for M365 commercial products we expect Revenue to decline in the low sing single digits as a reminder M365 commercial products include on premises components of M365 Suites so our quarterly Revenue growth can have variability primarily from in Period Revenue recognition depending on the mix of contracts M365 consumer Cloud Revenue growth should be in the mid single digits driven by M365 subscriptions for LinkedIn we expect Revenue growth of approximately 10% driven by continued growth across all businesses and in Dynamics 365 we expect Revenue growth to be in the mid to high teens driven by continued growth across all workloads next intelligent Cloud helping our customers transform and grow with Innovative cloud and AI Solutions is driving continued growth in asure therefore we expect Revenue in intelligent Cloud to grow between 18 and 20% in constant currency or 25.5 to 2.85 billion US Revenue will continue to be driven by Azure which as a reminder can have quarterly variability primarily from imperi revenue recognition depending on the mix of contracts in Azure we expect Q2 Revenue growth to be 31 to 32% in constant currency driven by strong demand for our portfolio of services we expect consumption growth to be stable compared to q1 and we expect to add more sequential dollars to Azure than any other quarter in history we expect the contribution from AI services to be similar to last quarter given the continued capacity constraints as well as some capacity that shifted out of Q2 and in H2 we still expect Azure growth to accelerate from H1 as our Capital Investments create an increase in available AI capacity to serve more of the growing demand and in our on premises server business we expect Revenue to decline in the loow to Mid single digits on a prior year comparable that benefited from purchasing ahead of Windows server 2012 end of support and in Enterprise and partner Services we expect Revenue growth to be in the low single digits now to more personal Computing we continue to make decisions to prioritize strategic higher margin opportunities within each of our consumer businesses our Outlook reflects the Improvement in grow and operating margins from this prioritization work across gaming search and devices we expect revenue and more personal Computing to be 13. 85 to 14.25 billion US Windows OEM and devices Revenue should decline in the low to mid single digits we expect Windows OEM Revenue growth in line with the PC market to be more than offset by a decline in devices as the trends from q1 continue search and news advertising xtac Revenue growth should be in the high teens with continued growth in both volume and revenue per search this will be higher than overall search and news advertising Revenue growth which we expect to be in the high single digits and in gaming we expect Revenue to decline in the high single digits due to Hardware we expect Xbox content and services Revenue growth to be relatively flat we're excited about last week's launch of Call of Duty where we saw the most Game Pass subscriber ads we've ever seen on a launch day there are two things about the launch that are different than the Call of Duty launch a year ago where Revenue was mostly recognized in the quarter of purchase first the game is a ailable on Game Pass so for players who play through game pass the subscription revenue is recognized over time second the game requires an online connection to play so even for players who purchase the Standalone game Revenue recognition will also occur ratably over time now back to company guidance we expect cogs to grow between 11 and 133% in constant currency or to be between 21.9 to 22.1 billion US an operating expense to grow approximately 7% in constant currency or to be between 16.4 and 16.5 billion US this should result in another quarter of operating margin expansion other income and expense is expected to be roughly negative 1.5 billion primarily driven by our share of the expected loss from open AI which is accounted for under the equity method as a reminder we do not recognize Mark to market gains or losses on Equity method method Investments as you heard from Saia our strategic partnership and investment in open aai has been pivotal in building and scaling our AI business and positioning us as the leader in the AI platform wave and lastly we expect our Q2 effective tax rate to be approximately 19% in closing we remain focused on strategically investing in the long-term opportunities that we believe Drive shareholder value monetization from these Investments continues to grow and we're excited that only two and a half years in our AI business is on track to surpass 10 billion of annual revenue run rate in Q2 this will be the fastest business in our history to reach this Milestone we are committed to Growing this leadership position across our entire Microsoft cloud while maintaining our disciplined focus on cost management and prioritization across every team with that let's go to Q&A Brett thanks Amy we'll now move over to Q&A out of respect for others of the call we request the participants please only ask one question operator can you please repeat your instructions thank you ladies and gentlemen if you would like to ask a question please press star one on your telephone keypad and a confirmation tone will indicate your lines in the question Quee you may press star two if you would like to remove your question from the queue for participants using speaker equipment it may be necessary to pick up your handset before pressing the start and our first question comes from the line of Keith Weiss with Morgan Stanley please proceed excellent uh thank you guys for taking the question and congratulations on a really solid quarter uh so Sakia the expansion of capabilities the speed of innovation the magnitude of the opportunities ahead for generative AI it makes this the most exciting period for software I've seen in my 25 years of covering the space and based upon this call it seems like you shared that excitement but am my that's conversation that excitement also feeds two related questions and they both have to do with constraints and the first is like what are the internal constraint or guard rail that Microsoft has when it comes to investing Behind These Innovations particularly in relation to the funding of future generations of foundational models where people were talking about price tags going to tens of billions or even hundred billion dollars plus and then on the other side of the spectrum um what are the external constraints that Microsoft sees in building out this capacity to meet to man and capture the opportunity particularly constraints in your ability to power all these new data centers being built out and power it in an environmentally sustainable fashion I I'd love to get the Microsoft perspective on both those uh questions no thank you uh Keith for those questions I think on the first point um ultimately our you know when you think about let's say a capital outlay for training because that's essentially what you're asking it is going to be rate Limited by your monetization of inference in a given generation right so just like in the past we would allocate Capital to build out cloud based on the demand signal we were seeing and then we would then project the demand and that's what we would build for so you can think of training essentially as that right which is you're building the Next Generation model so that then you have a more capable model that then drives more inference Demand right so ultimately even with all the scaling laws and what have you I think you ultimately will normalize to having a pace in fact I think the best way to think about even is given the Moors law effectively is working uh on the sort of uh silicon and system side so it's just not compute right its efficiencies in computed data as well as algorithms you will want to sort of keep on that curve which is you really want to refresh your Fleet U with the Moors law every year and then effectively depreciate uh over the period of the life cycle of it and then the insurance demand ultimately will govern how much we invest in training because that's I think at the end of the day uh you're all subject to ultimately demand the second piece of the external constraints we have run into obviously lots of external constraints because this demand all showed up pretty fast right I mean if you think about uh even CH the most hit products of this generation all are in our Cloud right whether it's chat GP whether it's co-pilot whether it's get up co-pilot or even Dax co-pilot I mean pick the top four or five products of this generation they're all sort of in and around our ecosystem and so therefore uh we ran into a set of constraints which are everything because DCS don't get built overnight so there is DCs uh there is power um and uh and so that's sort of been the short-term constraint even in Q2 for example some of the demand issues we have or our ability to fulfill demand is because of in external third party stuff that we least moving out so that's the constraints we have but in the long run um we do need effectively power um and we need DCS and some of these things are more long lead and but I feel pretty good that going into the second half of even uh this fiscal year that some of that Supply demand will match up excellent thank you guys thanks Keith operator next question please the next question comes from the line of Brent bill with jeffre please proceed thanks uh Amy good to hear uh the re acceleration in the back half for Azure I I guess many are asking uh you know 34% growth in q1 uh falling to low 30s I I know the comp is is a couple points harder but is there anything else you're contemplating in that guide for Q2 to see that uh to see that deceleration other than a tougher comp thank you uh thanks Brent maybe this is a great question because I can sort of reiterate some of the points I made and and tie them together a little bit uh in q1 uh the 34 in CC as we talked about um you know that upside versus the 33 that we had guided to was primarily due to some Revenue recognition benefits and so um I think about that on a sort of a pure consumption basis uh and AI as being you know 30 three and you think about a point or two uh of diesel that we've guided to and the majority of that is due to unfortunately some Supply pushouts that I mentioned and then sopia reiterated in terms of AI Supply coming online that we counted on the underlying consumption growth is stable q1 to Q2 uh and so to your question on some ins and out it is certainly uh some ins and outs um I do as you heard uh have confidence as we get um a good influx of Supply across the second half of the Year particularly uh on the AI side that will be better able to do some Supply demand matching and and hence while we're talking about acceleration in the back half I'll also take the opportunity to say when you see um usage in AI workloads we always intend to think about that is just a GPU exercise um the importance of having gpus and CPUs be able to run these workloads is also important so that's a piece um of the acceleration at age2 as well thanks thanks Brent operator next question please the next question comes from the line of Mark morler with Bernstein please proceed thank you very much for taking my question and congratulations on the quarter um the question every investor obviously asks is the question on the capex growth and the capex spend obviously half of that facilities an equivalent that have longer life but the other half is the rest of the components do can you give any color on how you think of that growth does it return to the traditional approach where basically capex is going to grow in line or slightly slower than Cloud Revenue um if so any sense of the timing do are we do we have enough facilities online by by sometime next year Etc any color would be appreciated uh thanks Mark you know I think in some ways it's helpful to go back um to the cloud transitions that we worked on um much over a decade ago I think in the early stages and what you did see and and you'll see us doing the same time is you have to build um to meet demand uh unlike the cloud transition we're doing it on a global basis uh in parallel as opposed to sequential uh given the nature of the demand and then um as long as we continue to see that demand grow you're right um the growth in capx will slow and the revenue growth will increase and those two things to your point um get closer and closer together over time the pace of that entirely depends really on the pace of adoption and to stop this point you know some of that spend goes toward building um the next training infrastructure so you won't see all of it in CX some of it uh goes to Opex um when you're spending it on on training but in general that's a that's a healthy way to think about the balance as it over time those do and should uh like the last cycle get closer together thank you very much that's very helpful thanks Mark operator next question please the next question comes from the line of Carl kirad with UBS please proceed okay great uh thank you I'm I'm actually not going to ask a question about the numbers but satian Amy I'd love to ask a question about uh open AI since um the the print three months ago we investors have been hit with a torrent of media stories about open Ai and Microsoft and I'd love to give Microsoft an opportunity to frame the relationship it seems to me it's critically important but uh we have been I think everyone on the line picking up signals that perhaps Microsoft wants to diversify somewhat at the model layer and and offer customers choice so SAA I'd love to get your framing of the relationship and then in terms of the numbers um maybe this is a little bit more for you Amy but how does Microsoft manage the the demands on capex from uh helping uh openi with its scaling Ambitions and how do you manage the the impact on other income that uh you just gave us some uh color on thank you so much sure um thanks SC so I'd say first the um partnership for both sides that's open Ai and Microsoft has been super beneficial um you know after all uh we were the you know we effectively sponsored what is one of the most highest valued uh uh private companies uh today when we uh invested in them and really took a bet on them and their Innovation uh four five years ago and uh uh that has led to great success for Microsoft it's great led to great success for open AI um uh and we continue uh to build on it right so we serve them with world-class infrastructure on which they do their uh innovation in terms of models on top of which we innovate both the model layer with some of the post trining stuff we do uh as well as some of the small models we build uh and then of course all of the product Innovation right one of the things that uh my own sort of conviction of open AI uh and what they were doing came about when I started seeing something like get up co-pilot as a product yet built or Dax co-pilot get built or M365 co-pilot get built so we have a a fantastic portfolio of innovation uh that we build on top of that um and um you know we at the same also I would say we are investors uh we feel very very good about sort of our uh investment stake in open Ai and uh uh and so our all our focus and we're always in constant dialogue with them in a partnership like this when both sides have achieved Mutual success at the face at which we achieved it that means we need to kind of push each other to do more uh to you know capture the moment and that's what uh we plan to do and we intend to keep building on it and maybe to your other two uh questions Carl you know listen um I'm thrilled uh with their success and need for Supply um from Azure and infrastructure and really what it's meant in terms of being able to also serve other customers for us um it's important that we continue uh to invest Capital to meet not only their demand signal uh and needs for compute but also from our broader customers uh that's partially why you've seen uh us committing the amounts of capital we've seen uh over the past few quarters Is our commitment to both grow together uh and for us to continue to grow the Azure platform for customers Beyond them uh and so I don't really think of it as how do you balance it it's just we have customers who have needs and real use cases and delivering value today and and if we can't meet that we need to work to meet it uh and that means working harder and faster to make sure we do that uh which is what the Keem is committed to do second piece of your question I think was on the impact to other income and um not to get too accounting heavy uh on the earning phone call but I would say uh just a reminder uh this is under the equity method uh which means um you know we just take our percentage of losses uh every quarter um and those losses of course are capped by the amount of investment we make in total uh which we did uh talk about in The Q's quarter uh as being $1 13 billion and so over time that's just the constraint um and it's a bit of a mechanical uh entry and so uh I don't really think about managing that that's the investment and acceleration that open AI is making in themselves and and we take a percentage of got it okay very helpful thank you both thanks Carl operator next question please the next question comes from the line of cash rangan with Goldman Sachs please proceed hi yeah thank you very much s when you talked about the investment cycle these models are getting bigger more expensive but you also pointed out to how in the inference phase uh we're likely to get paid how does that cycle look like an inference for Microsoft where are the the the products in the applications that will show up on the Microsoft pnl as a result of the inference phase of AI kicking it thank you very much thanks Cash I mean the good news for us um is that we're not waiting for that inance to show up right if you sort of think about uh the point we even made that this is going to be the fastest growth um uh to10 billion of any business in our history it's all INF uh right one of the things that it may not be um uh as evident is that we're not actually selling raw gpus for other people to train in fact that's sort of a business we turn away because we have so much Demand on inference that we are not taking what I would in fact that's an there's a huge adverse selection problem today where people it's just a bunch of tech companies still you know using VC money to buy a bunch of gpus we kind of really are not even participating in most of that because we are literally going to the deral demand which is in the Enterprise space or our own products like get up co-pilot or M365 co-pilot so I feel the quality of our revenue is also pretty Superior in that context uh and that's what gives us even the conviction to even Amy's answers previously about our Capital spend uh is if this was just all about sort of a bunch of people training large models and that was all we got uh then that would be you know ultimately still waiting to your point for someone to actually have demand which is real and in our case the good news here is we have a diversified portfolio we're seeing real demand uh across all of that portfolio and cash maybe just add a little bit to what Saia is saying I think a part of his two answers is that what you're saying is this number we're talking about the10 billion dollar across inference and our apps um is already what that momentum and that investment and that progress and that revenue is what builds the next cycle of training right and so it's that Circle as opposed to oh we're doing training now and then inference um much of the training Investments that are and that fuel this Revenue growth came before uh and we already funded that work and so that's that's an important part that's to your point that you invest now and you can get the growth later even if you slow down the capex right that that's what you're trying to tell us that's that's the cycle that is important to understand got thank you so much thanks Cash operator next question please the next question comes from the line of Mark Murphy with JP Morgan please proceed thank you very much I'm wondering if you can uh shed any more light just on the nature of the supply limitations that uh you're mentioning that are impacting Azure in Q2 um where that impact might be incrementally just a touch more than we expected is is it more the GPU uh Supply is there some element of power uh cooling or the ability to to wire up the networks and uh Amy um should we infer that uh the supply is constraining azure growth by roughly a couple few points in Q2 or am I am I overestimating that um maybe to answer uh both those questions uh Mark very directly I wouldn't think about it component logic in my Q2 answer the Supply push out as sopia said was third parties that are delivering later than we had expected um that gets pushed mainly into the second half of the year and in general Q3 um so that's third par is where we tended to buy um Supply inclusive uh of kits so it's complete endtoend third party delivery um in terms of the impact you know as I was saying you know when you think about having flat consumption um q1 to Q2 there really are only two things um that impact that difference and one was the help we got in q1 um from the revenue and revenue and accounting help and then uh Q2 has been the supply pushup thank you thanks Mark operator next question please the next question comes from the line of r l show with Barclays please proceed perfect thank you um the um if you if you talk about the market at the moment because you were first with co-pilot you had identified a lot with co-pilots and now we're talking agents um can you kind of s how do you think about that to me it looks like an evolution that we're discovering how to kind of productize AI better Etc so how do you think about that Journey you know between co-pilots agents and maybe what's coming next thank you sure um the way the system we built is um co-pilot co-pilot Studio agents and autonomous agents you should think of that as the spectrum of things right so ultimately the way uh we think about um how this all comes together is you need humans to be able to interface with AI so the UI layer for AI is copile you can then use copile Studio to extend co-pilot for example you want to connect it to your CRM system to your office system to your um you know HR System you do that through co-pilot Studio by building agents effectively you also build autonomous agents so you can use even that's the announcement we made a couple of weeks ago is you can even use copilot Studio to build autonomous agents now these autonomous agents are working independently but from time to time they need to raise is an exception right so autonomous agents are not fully autonomous because at some point they need to either notify someone or have someone input something and when they need to do that they need a UI layer and that's where again it's co-pilot so co-pilot co-pilot agents built in copilot Studio autonomous agents built in copilot Studio that's the full system uh we think that comes together and we feel very very good about the positioning and then of course we are taking the underlying system services that across that entire stack that I just talked about and I'm making it available in Azure right so you have the raw infastructure if you want it you have uh the model layer independent of it you have the AI app server and Azure AI right so everything is also a building block service in Azure for you to be able to build in fact if you want to build everything that we have built uh in the co-pilot stack you can build it yourself using the AI platform so that's sort of in simple terms our strategy and that's kind of how it all comes together okay perfect very clear thanks R operator we have time for one last question and the last question will come from the line of rishy galura with RBC please proceed oh wonderful thanks uh hi seia Amy appreciate the question um I I want to go and think a little bit about uh uh co-pilot Pro um how we should be thinking about uh kind of numbers here with the recategorization seems like that was maybe softer in the past than expected but maybe with uh the the numbers this quarter starting to pick up can you maybe walk us through what you're seeing on that and maybe more importantly how we should be thinking about your overall AI strategy on consumer versus Enterprise especially now with the Mustafa on the full thanks so much yeah on the first part uh Rishi uh to your question I think we feel very very good about the momentum we have in the commercial co-pilot right as I said in my remarks and Amy talked about this is the fastest growth of a new suite in M365 if I compare it to what we saw even back very back in E3 or E5 or the transition from o to M this is really much faster right it's the the numbers of penetration of the fortune uh you know 500 and then the fact that they're coming back for more seats and what have you so it's very strong uh in that context um the other thing I'd love to mention is that uh I we want this to be something that is system systemic right because people need to be able to put the security controls then they need to deploy then there's Skilling and then there's change management so this is not like you just it's not a tool like when I talk about co-pilot co-pilot uh Studio agents it's really as much about a new way to work um and um sometimes I describe it as what happened throughout the 90s with PC penetration after all you know if you take a business process like forecasting what was it like pre- email and Excel and post email and Excel that's the type of change uh that you see uh with copil but overall uh we feel great about the great of progress in the penetration and then on the consumer side look for us the exciting part here is to be able to use the same investment we are making in the commercial where we have structural strength uh and then be on the offense uh one of the things that I think um I hope you all catch in our earnings is uh xtac our Revenue when it comes to what we describe as search news and ads um is growing faster than market so that's uh you know it's fantastic to see that and uh you know so that's kind of a consumer business which you know in Microsoft's large scope you know it's sort of even a 10 plus billion dollar business sort of sometimes goes missing but in our case it is actually a fantastic growth business that's growing faster than Market uh we feel good about uh how we will use AI in LinkedIn in fact LinkedIn is a consumer business as you know you saw even today this week they announced some new capabilities for both consumers and in their case even uh recruiting uh so we think that AI the same investment gets monetized even through uh linkedin's Innovation um and and gaming of course is another place where you'll see some of these things uh apply and windows right so the place where I think I'm excited about is copilot plus PCS right for us it's not about having a disconnected Edge it's about having hybrid AI where uh The Rebirth of sort of the PC as the edge of AI is going to be one of the most exciting things for developers so we feel well position quite frankly uh with the same investment so this is that that's the thing that you know we're not a conglomerate here we are sort of one company that means we invest ones and then we have all these categories that you know benefit from that that's the theory of the here for us and so we feel good about all all of that coming together and maybe just to add one piece because I think rich now that I'm listening and thinking through that question um it feels like you're wondering like why am I not seeing uh the co-pilot if you got made all this progress in the results and the answer is you already are um in that infer 65 commercial number you we've seen that seat growth but those seats that we're adding uh the majority of them are driven by uh Frontline worker and small businesses those have a lower arpo point and so it masks some of the arpo that we're already seeing not just from E5 which continues to contribute but also this quarter um additional impact from co-pilot so as we go forward being able that is where you're going to see the impact will be in ARP uh in M365 commercial and as sopia said I think you'll see the impact of co-pilot engagement frankly across the same xtac number wonderful thank you thanks reishi that wraps up the Q&A portion of today's AR's call thank you for joining us today and we look forward to speaking with all of you again soon thank you this concludes today's conference you may disconnect your lines at this time enjoy the rest of your day\"},\n",
              " {'title': 'Earnings call transcript: Microsoft Q1 2025 earnings beat ...',\n",
              "  'url': 'https://ca.investing.com/news/transcripts/earnings-call-transcript-microsoft-q1-2025-earnings-beat-expectations-stock-surges-93CH-3985817',\n",
              "  'content': \"Satya Nadella, Chairman and Chief Executive Officer, Microsoft: Thank you, Jonathan. It was a record quarter driven by continued strength of Microsoft Cloud, which surpassed $42,000,000,000 in revenue, up 22% in constant currency. Cloud and AI are the essential inputs for every business to expand output, reduce costs and accelerate growth. Now I'll highlight examples starting with infrastructure. We continue to expand our data center capacity. [...] Although the range of potential outcomes is wider than normal. Devices revenue should decline in the high teens. Search and news advertising ex TAC revenue growth should be in the high teens even on a strong prior year comparable. We expect to see continued growth in both volume and revenue per search with share gains across Edge and Bing. Overall search and news advertising revenue growth should be in the mid teens. [...] We expect CapEx to grow. It will grow at a lower rate than FY 2025 and will include a greater mix of short lived assets, which are more directly correlated to revenue than long lived assets. These investments along with focused execution that delivers near term value to our customers will ensure we continue to lead through the cloud and AI opportunity ahead. With that, let's go to Q and A, Jonathan.\\n\\nJonathan Nielsen, Vice President of Investor Relations, Microsoft: Thanks, Amy. We'll now move over to Q and A.\\n\\nAmy Hood, Chief Financial Officer, Microsoft: Out of respect to others on the call,\\n\\nJonathan Nielsen, Vice President of Investor Relations, Microsoft: we request that participants please only ask Operator, can you please repeat your instructions?\",\n",
              "  'score': 0.94339466,\n",
              "  'raw_content': '# Earnings call transcript: Microsoft Q1 2025 earnings beat expectations, stock surges\\n\\n[Transcripts](https://ca.investing.com/news/transcripts)\\n\\nPublished 2025-04-30, 06:40 p/m\\n\\nEarnings call transcript: Microsoft Q1 2025 earnings beat expectations, stock surges\\n\\n[View all comments (0)0](#comments-3985817)\\n\\n© Reuters.\\n\\n[MSFT\\n\\n-2.37%](https://ca.investing.com/equities/microsoft-corp)\\n\\nMicrosoft Corporation, with its impressive $2.93 trillion market capitalization, reported its fiscal Q1 2025 earnings, surpassing analysts\\' expectations with an earnings per share (EPS) of $3.46 against a forecast of $3.23. The company\\'s revenue reached $70.1 billion, exceeding the anticipated $68.53 billion. Trading at a P/E ratio of 31.34x, Microsoft shares rose 7.92% in aftermarket trading, closing at $426.57.\\n\\n[InvestingPro](https://www.investing.com/pro/MSFT) analysis reveals 12 key investment tips for Microsoft, including its 19-year streak of dividend increases and strong financial health metrics. Subscribers can access the complete analysis in the comprehensive Pro Research Report, available exclusively on InvestingPro.\\n\\n## **Key Takeaways**\\n\\n* Microsoft reported a significant earnings beat, with EPS of $3.46 compared to a forecast of $3.23.\\n* The company\\'s revenue of $70.1 billion surpassed expectations, driven by strong cloud and AI service demand.\\n* Microsoft shares surged 7.92% in aftermarket trading, reflecting positive investor sentiment.\\n* Microsoft Cloud revenue grew by 20-22% in constant currency, highlighting robust growth.\\n* The company introduced major innovations, including the Majorana One quantum computing initiative.\\n\\n## **Company Performance**\\n\\nMicrosoft demonstrated strong performance in the first quarter of 2025, with a notable increase in revenue and earnings per share. The company\\'s focus on cloud and AI services contributed significantly to its growth, aligning with broader industry trends. Microsoft\\'s strategic investments in data centers and AI capabilities have positioned it as a leader in the tech sector.\\n\\n## **Financial Highlights**\\n\\n* Revenue: $70.1 billion, up 13.15% in constant currency\\n* Earnings per share: $3.46, up 18.19% in constant currency\\n* Gross margin: Increased by 11.13% in constant currency\\n* Operating income: Rose by 16.19% in constant currency\\n* Microsoft Cloud revenue: $42.4 billion, with a growth rate of 20-22%\\n\\n## **Earnings vs. Forecast**\\n\\nMicrosoft\\'s actual EPS of $3.46 exceeded the forecast of $3.23, representing a surprise of approximately 7.12%. Revenue also surpassed expectations, with actual figures of $70.1 billion compared to a forecast of $68.53 billion. This earnings beat marks a continuation of Microsoft\\'s trend of outperforming analyst expectations, driven by strong cloud and AI demand.\\n\\n## **Market Reaction**\\n\\nFollowing the earnings announcement, Microsoft\\'s stock experienced a significant increase of 7.92% in aftermarket trading, closing at $426.57. This surge reflects investor confidence in the company\\'s growth prospects, particularly in cloud and AI services. The stock remains within its 52-week range, with a high of $468.35 and a low of $344.79. Analyst consensus is strongly bullish, with price targets ranging from $415 to $650.\\n\\nBased on [InvestingPro](https://www.investing.com/pro/MSFT)\\'s Fair Value analysis, Microsoft currently appears to be trading near its Fair Value. For deeper insights into valuation metrics and comprehensive analysis, investors can access the full Pro Research Report.\\n\\n## **Outlook & Guidance**\\n\\nLooking ahead, Microsoft anticipates continued growth in cloud and AI services, despite potential AI capacity constraints beyond June. The company expects its Q4 Microsoft Cloud gross margin to be around 67% and plans to moderate its capital expenditure growth rate. These strategic initiatives aim to sustain Microsoft\\'s competitive edge in the tech industry.\\n\\n## **Executive Commentary**\\n\\nSatya Nadella, CEO of Microsoft, emphasized the transformative role of cloud and AI, stating, \"Cloud and AI are the essential inputs for every business to expand output, reduce costs and accelerate growth.\" Nadella also highlighted the company\\'s focus on innovation, saying, \"We are rapidly innovating opportunity across both consumer and commercial businesses.\"\\n\\n## **Risks and Challenges**\\n\\n* Potential AI capacity constraints may impact service delivery and growth.\\n* Economic uncertainties, including potential recession risks, could affect customer spending.\\n* Increased competition in cloud services from other tech giants may pressure market share.\\n* Regulatory challenges in different regions could impact operations and expansion plans.\\n* Supply chain disruptions may affect hardware and infrastructure development.\\n\\n## **Q&A**\\n\\nDuring the earnings call, analysts inquired about Microsoft\\'s data center strategy and capacity planning, as well as the growth of AI workloads and infrastructure scaling. The company addressed concerns about its resilience to potential economic downturns and highlighted the performance of non-AI Azure services. These insights underscored Microsoft\\'s strategic focus on sustaining growth and innovation.\\n\\n## **Full transcript - Microsoft Corporation (MSFT) Q3 2025:**\\n\\n**Conference Operator**: Greetings, and welcome to the Microsoft Fiscal Year twenty twenty five Third Quarter Earnings Conference Call. At this time, all participants are in a listen only mode. A question and answer session will follow the formal presentation. As a reminder, this conference is being recorded. It is now my pleasure to introduce Jonathan Nielsen, Vice President of Investor Relations.\\n\\nPlease go ahead.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Good afternoon, and thank you for joining us today. On the call with me are Satya Nadella, Chairman and Chief Executive Officer Amy Hood, Chief Financial Officer Alex Jolla, Chief Accounting Officer and Keith Dolliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today\\'s call and provides the reconciliation of differences between GAAP and non GAAP financial measures. More detailed outlook slides will be available on the Microsoft Investor Relations website when we provide outlook commentary on today\\'s call. On this call, we will discuss certain non GAAP items.\\n\\nThe non GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP. They are included as additional clarifying items to aid investors in further understanding the company\\'s third quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year, unless otherwise noted. We will also provide growth rates in constant currency when available as a framework for assessing how our underlying business performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rates only.\\n\\nWe will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today\\'s call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we will be making forward looking statements, which are predictions, projections or other statements about future events.\\n\\nThese statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today\\'s earnings press release, in the comments made during this conference call and in the Risk Factors section of our Form 10 ks, Forms 10 Q and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward looking statement. And with that, I\\'ll turn the call over to Satya.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Thank you, Jonathan. It was a record quarter driven by continued strength of Microsoft Cloud, which surpassed $42,000,000,000 in revenue, up 22% in constant currency. Cloud and AI are the essential inputs for every business to expand output, reduce costs and accelerate growth. Now I\\'ll highlight examples starting with infrastructure. We continue to expand our data center capacity.\\n\\nThis quarter alone, we opened DCs in 10 countries across four continents. Model capabilities are doubling in performance every six months, thanks to multiple compounding scaling laws. We continue to optimize and drive efficiencies across every layer from DC design to hardware and silicon to system software to model optimization all towards lowering costs and increasing performance. You see this in our supply chain where we have reduced dock to lead times for new GPUs by nearly 20% across our blended fleet where we have increased AI performance by nearly 30% ISO power and our cost per token, which is more than halved. When it comes to cloud migrations, we saw accelerating demand with customers in every industry from Abercrombie and French to Coca Cola and ServiceNow, expanding their footprints on Azure.\\n\\nAnd we remain the cloud of choice for customers\\' mission critical VMware, SAP and Oracle workloads with more regional availability than any other hyperscaler. We\\'re also excited about the next frontier in cloud systems with Quantum. In addition to putting our Quantum stack on machines from our partners, we\\'re also making real progress on a path to a utility scale quantum computer with the introduction of Majorana One. When it comes to data and analytics, we have deeply integrated our AI platform with our data stack. PostgreSQL usage accelerated for the third consecutive quarter and it is now used by nearly 60% of the Fortune 500, including companies like BMW and BNY Mellon.\\n\\nCosmos DB revenue growth also accelerated again this quarter and remains the go to database for globally distributed NoSQL workloads at any scale. It is used by customers in every industry like CarMax, DocuSign, NTT Data and OpenAI. This quarter, we also saw analytics consumption accelerate. Microsoft Fabric has more than 21,000 paid customers, up 80% year over year. Fabric brings together data workloads like data warehousing, data science, real time intelligence along with Power BI into one end to end solution.\\n\\nReal time intelligence is now the fastest growing workload in fabric with 40% of customers already using it in just five months since becoming generally available. All up more than 50% of fabric customers like AmorePacific, Louisiana State Government and Petrobras use three or more workloads. And the amount of data in our multi cloud data lake, OneLake has grown more than 6x over the past year. Now on to AI Platform and Tools. Foundry is the agent in AI app factory.\\n\\nIt\\'s now used by developers at over 70,000 enterprises and digital natives from Atomic Work to Epic, Fujitsu and Gainsight to H and R Block and LG Electronics to design, customize and manage their AI apps and agents. We processed over 100,000,000,000,000 tokens this quarter, up 5x year over year, including a record 50,000,000,000,000 tokens last month alone. And four months in, over 10,000 organizations have used our new agent service to build, deploy and scale their agents. This quarter, we also made a new suite of fine tuning tools available to customers with industry leading reliability. And we brought the latest models from OpenAI along with new models from Cohere, DeepSeek, Meta, Mistral, Stability to Foundry.\\n\\nAnd we\\'ve expanded our PHY family of SLMs with new multimodal and mini models. All up PHY has been downloaded 38,000,000 times. And our research teams are taking it one step further with BitNet B1.58, a billion parameter large language model that can run on just CPUs coming to the foundry. Now on to developer tools. We are evolving GitHub Copilot from pair to peer programmer.\\n\\nWith agent mode in Versus Code, Copilot can now iterate on code, recognize errors and fix them automatically. This adds to other Copilot agents like AutoFix, which helps developers remediate vulnerabilities as\\n\\n**Conference Operator**: well\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: as Code Review Agent, which has already reviewed over 8,000,000 pull requests. And we are previewing a first of its kind SWE Agent capable of synchronously executing developer tasks. All up, we now have over 15,000,000 GitHub Copilot users up over 4x year over year. And both digital natives like Twilio and enterprises like Cisco, HPE, Skyscanner and Target continue to choose GitHub Copilot to equip their developers with AI throughout the entire dev life cycle. With Visual Studio and Versus Code, we have the world\\'s most popular editor with over 50,000,000 monthly active users.\\n\\nAnd with Power Platform, we have the leading low code platform for AI makers too. We now have 56,000,000 monthly active Power Platform users, up 27% year over year, who increasingly use our AI features to build apps and automate processes. Now on to future of work. Microsoft three sixty five Copilot is built to facilitate human agent collaboration. Hundreds of thousands of customers across geographies and industries now use Copilot, up 3x year over year.\\n\\nOur overall deal size continues to grow and this quarter we saw a record number of customers returning to buy more seats. And we are going further. Just last week, we announced a major update bringing together agents, notebooks, search and create into a new scaffolding for work. Our new researcher and analyst deep reasoning agents analyze vast amounts of web and enterprise data to deliver highly skilled expertise on demand directly within Copilot. Beyond horizontal knowledge work, we are introducing agents for every role and business process.\\n\\nOur sales agent turns contacts into qualified leads and with Sales Chat reps can quickly get up to speed on new accounts and our customer service agent is deflecting customer inquiries and helping service reps resolve issues faster. With Copilot Studio, customers can extend Copilot and build their own agents with no code, low code. More than 230,000 organizations including 90% of the Fortune 500 have already used Copilot Studio. With deep reasoning and agent flows in Copilot Studio, customers can build agents that perform more complex tasks and also handle deterministic scenarios like document processing and financial approvals. And they can now build computer use agents that take action on the UI across desktop and web apps.\\n\\nAnd with just a click they can turn any SharePoint site into an agent too. This quarter alone customers created over 1,000,000 custom agents across SharePoint and Copilot Studio, up 130 quarter over quarter. When it comes to business applications, Dynamics three sixty five again took share as companies like Avaya, Brunswick, Softcat switched to Dynamics from legacy providers. Verizon for example chose Dynamics three sixty five sales to improve the efficiency of its sellers. In Healthcare, Dragon Co Pilot is off to a fast start.\\n\\nLast quarter alone we helped document nearly 9,500,000 physician patient encounters at providers like City of Hope, Ottawa Hospital, Tufts Medicine and Wellstar up over 50% quarter over quarter. In manufacturing, we introduced factory operations and safety agents at Hanover Massay and leading partners like Autodesk, PTC and Siemens have all built their own industrial AI solutions on our stack. And in retail, we have introduced agents to help customers like Bath and Body Works build more personalized shopping experience and improve store operations. When it comes to Windows Copilot plus PCs are faster and have better battery life than any other device in their category. We also continue to win new customers with best in class AI capabilities.\\n\\nWe offer a growing number of AI apps from partners like Adobe, Canva and Zoom. Just last week, we rolled out exclusive AI experiences like Recall, Click to Do and Windows Search to all Copilot plus PCs. And we continue to see increased commercial traction as we approach end of support for Windows 10. Windows 11 commercial deployments increased nearly 75% year over year. Now on to security.\\n\\nSecurity is our top priority and we have made significant progress against the engineering objectives we outlined a year and a half ago as part of our Secure Future initiative. We are now applying these learnings to deliver new innovation across our platform. Last month along with our partners, we introduced security copilot agents to help defenders autonomously handle high volume security and IT tasks informed by 84,000,000,000,000 daily threat signals. We also added new capabilities to Defender, Entra and Purview to help organizations secure and govern their AI deployments. All up, we now have 1,400,000 secondurity customers, over 900,000 including Global, ManpowerGroup, TriNet, Regions Bank have four or more workloads, up 21% year over year.\\n\\nAnd in Identity, Entra now has more than 900,000,000 monthly active users. Now on to our consumer businesses, starting with LinkedIn. Over 1,000,000,000 professionals use LinkedIn to connect, learn, hire and sell and our membership continues to grow at double digits year over year. Time spent watching videos on the platform was up 36% and comments were up 32% year over year. We\\'re also seeing more members use AI to gain new skills and find jobs.\\n\\nThe number of learners who have used AI powered coaching increased over 2x quarter over quarter. And we remain the market leader in hiring as customers like Equinix and Verizon use LinkedIn hiring assistance to find qualified candidates faster. When it comes to LinkedIn Premium, we saw over 75% quarter over quarter subscriber growth to our Premium Pages offering for SMBs. And LinkedIn marketing solution continues to be the best way to reach B2B decision makers with two consecutive quarters of accelerated revenue growth. More broadly, when it comes to advertising, we are transforming how people search, browse, discover content and use AI as a personal assistant.\\n\\nWith Copilot Search in Bing, we are reimagining search results with overview pages curated by AI and embedded conversational capabilities. With Copilot Vision and Edge, Copilot sees what you see and gives you real time responses while you browse. With Copilot Discover, we are personalizing experience based on user interactions and preferences. And with our updated Copilot app, we are focused on building daily engagement and successful sessions across a range of modalities, whether it is conversing, searching, shopping or travel planning. All up, we again took share across Bing and Edge and our total advertising revenue across our businesses has surpassed $20,000,000,000 over the past twelve months.\\n\\nNow on to Gaming. We continue to transform the business and focus on margin expansion as we bring our games to over 500,000,000 monthly active users across devices. We ended the quarter as the top publisher by pre orders and pre installs on both Xbox and PlayStation Store. PC Game Pass revenue increased over 45% year over year with Xbox Play Anywhere players now can access more than 1,000 games they can play across console and PC. And just last week, we brought cloud gaming to LG TVs.\\n\\nCloud gaming set a new record surpassing 150,000,000 hours played for the first time this quarter. We are also integrating AI across the Xbox. New Copilot for Gaming is a personalized gaming companion that provides in game assistant and expert coaching and our first of its kind Muse model can generate gameplay in real time. Finally, it\\'s fantastic to see the success of the Minecraft movie, which is the top grossing film of the year. In addition to monetizing our IP in new ways, we have seen a 75% plus increase in weekly active users of the game year over year since the release.\\n\\nIn closing, we are rapidly innovating opportunity across both consumer and commercial businesses. In just a few weeks at our BUILD conference, we\\'ll share how we are creating the most powerful AI platform for developers and I encourage you to tune in. With that, let me turn it over to Amy.\\n\\n**Amy Hood, Chief Financial Officer, Microsoft**: Thank you, Satya, and good afternoon, everyone. This quarter revenue was $70,100,000,000 up 1315% in constant currency. Gross margin dollars increased 1113% in constant currency, while operating income increased 1619% in constant currency. And earnings per share was $3.46 an increase of 1819% in constant currency. Results exceeded expectations driven by focused execution from our sales and partner teams.\\n\\nWe continue to see strong demand for our cloud and AI offerings as they help customers drive productivity, increase efficiencies and grow their businesses. And again this quarter revenue from our AI business was above expectations. Commercial bookings increased 1817% in constant currency significantly ahead of expectations again this quarter driven by an Azure commitment from OpenAI. We also saw consistent execution across our core annuity sales motions and continued long term commitments to our platform. Commercial remaining performance obligation increased to $315,000,000,000 up 3433% in constant currency.\\n\\nRoughly 40% will be recognized in revenue in the next twelve months up 17% year over year. The remaining portion recognized beyond the next twelve months increased 47%. And this quarter our annuity mix was 98%. FX was roughly in line with expectations on total company revenue, segment level revenue and operating expense growth. FX decreased COGS growth by only one point, one point unfavorable to expectations.\\n\\nMicrosoft Cloud revenue was $42,400,000,000 ahead of expectations and grew 2022% in constant currency. Microsoft Cloud gross margin percentage was 69% in line with expectations and decreased three points year over year driven by the impact of scaling our AI infrastructure. Company gross margin percentage was also 69% down one point year over year driven by scaling our AI infrastructure. Operating expenses increased 23% in constant currency lower than expected due to our focus on cost efficiencies as well as investments that shifted to Q4. Operating margins increased one point year over year to 46% better than expected as we continue to focus on building high performing teams and increasing our agility by reducing layers with fewer managers.\\n\\nAt a total company level, headcount at the March was 2% higher than a year ago and was down slightly compared to last quarter. Now to our segment results. Revenue from Productivity and Business Processes was $29,900,000,000 and grew 1013% in constant currency ahead of expectations driven by LinkedIn, Microsoft three sixty five Commercial Products and Microsoft three sixty five Consumer. M365 Commercial Cloud revenue increased 1215% in constant currency in line with expectations. ARPU growth was again driven by E5 and M365 Copilot.\\n\\nWith M365 Copilot, we continue to see growth across customer segments and geos. Paid M365 commercial seats grew 7% year over year to over $430,000,000 While we continue to see installed base expansion across all customer segments growth was primarily driven by our small and medium business and frontline worker offerings. M365 commercial products revenue increased 58% in constant currency ahead of expectations due to higher than expected office transactional purchasing. M365 consumer cloud revenue increased 1012% in constant currency ahead of expectations driven by higher than expected subscription growth following the January price increase. M365 consumer subscriptions grew 9% to $87,700,000 LinkedIn revenue increased seven percent and eight percent in constant currency.\\n\\nResults were ahead of expectations due to better than expected performance across all businesses. The Talent Solutions business continues to be impacted by weakness in the hiring market. Dynamics three sixty five revenue increased 1618% in constant currency in line with expectations with continued growth across all workloads. Segment gross margin dollars increased 1013% in constant currency and gross margin percentage was relatively unchanged year over year even with the impact of scaling our AI infrastructure. Operating expenses increased 12% in constant currency and operating income increased 1518% in constant currency.\\n\\nNext, the Intelligent Cloud segment. Revenue was $26,800,000,000 and grew 2122% in constant currency ahead of expectations driven by Azure. In Azure and other cloud services revenue grew 3335% in constant currency including 16 points from AI services. Focused execution drove non AI services results where we saw accelerated growth in our enterprise customer segment as well as some improvement in our scale motions. And in Azure AI services we brought capacity online faster than expected.\\n\\nIn our on premises server business revenue decreased 64% in constant currency slightly below expectations driven by renewals with lower in period revenue recognition from the mix of contracts. The year over year decline is reflective of the continued customer shift to cloud offerings. Enterprise and Partner Services revenue increased 56% in constant currency slightly ahead of expectations due to better than expected performance in Enterprise Support Services. Segment gross margin dollars increased 1314% in constant currency and gross margin percentage decreased four points year over year driven by scaling our AI infrastructure. Operating expenses increased 67% in constant currency and operating income grew 1718% in constant currency.\\n\\nNow to more personal computing. Revenue was $13,400,000,000 and grew six percent and seven percent in constant currency ahead of expectations due to better than expected results across all businesses. Windows OEM and devices revenue increased 3% year over year ahead of expectations as tariff uncertainty through the quarter resulted in inventory levels that remained elevated. Search and news advertising revenue ex TAC increased 2123% in constant currency. Results were significantly ahead of expectations driven by usage from a third party partnership, better than expected rate expansion and volume growth across Edge and Bing.\\n\\nAnd in gaming, revenue increased 56% in constant currency. Xbox content and services revenue increased 89% in constant currency ahead of expectations driven by stronger than expected performance in third party and first party content. Segment gross margin dollars increased 911% in constant currency. Gross margin percentage increased two points year over year driven by strong execution on margin improvement in Search and Gaming. Operating expenses increased 1%.\\n\\nOperating income increased 2123% in constant currency driven by continued prioritization of higher margin opportunities. Now back to total company results. Capital expenditures including finance leases were $21,400,000,000 slightly lower than expected due to normal variability from the timing of delivery of data center leases. Cash paid for PP and E was $16,700,000,000 roughly half of our cloud and AI related spend was on long lived assets that will support monetization over the next fifteen years and beyond. The remaining cloud and AI spend was primarily for servers both CPUs and GPUs to serve customers based on demand signals including our customer contracted backlog of $315,000,000,000 Cash flow from operations was $37,000,000,000 up 16% driven by strong cloud billings and collections partially offset by higher tax payments.\\n\\nAnd this quarter free cash flow was $20,300,000,000 Other income and expense was negative $623,000,000 more favorable than anticipated primarily due to net gains on derivatives and investments. Our losses on investments accounted for under the equity method were slightly higher than expected. Our effective tax rate was approximately 18%. And finally, we returned $9,700,000,000 to shareholders through dividends and share repurchases, an increase of 15% year over year. Now moving to our Q4 outlook, which unless specifically noted otherwise is on a U.\\n\\nS. Dollar basis. First, through April demand signals across our commercial businesses as well as in LinkedIn, gaming and search have remained consistent. Our outlook assumes those trends continue in Q4. If the environment changes, our results may be impacted.\\n\\nIn our Windows OEM business, our outlook assumes the elevated inventory levels from Q3 will come down in Q4. We have widened our guidance range in our More Personal Computing segment to account for some of this variability. Next, FX. With the weakening of the U. S.\\n\\nDollar in April, we now expect FX to increase total revenue growth by one point. Within the segments, we expect FX to increase revenue growth by one point in Productivity and Business Processes and less than one point in Intelligent Cloud and More Personal Computing. We expect FX to increase COGS operating expense growth by less than one point. In Commercial Bookings, we expect solid growth on a significant prior year comparable and a growing ex pre base. Bookings growth will be driven by strong execution across our core annuity sales motions and continued long term commitments to our platform.\\n\\nAs a reminder, larger longer term Azure contracts which are more unpredictable in their timing can drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 67% down year over year primarily driven by the impact of scaling our AI infrastructure. And now capital expenditures. We expect Q4 capital expenditures to increase on a sequential basis. H2 CapEx in total remains unchanged from our January guidance.\\n\\nAs a reminder, there can be quarterly spend variability from cloud infrastructure build outs and the timing of delivery of finance leases. Next to segment guidance. In Productivity and Business Processes, we expect revenue of US32.05 billion dollars to US32.35 billion dollars or growth of 11% to 12% in constant currency. M365 Commercial Cloud revenue growth should be approximately 14% in constant currency relatively stable compared to the prior quarter. We expect continued ARPU growth through E5 and M365 Copilot and some seat growth moderation given the size of the installed base.\\n\\nM365 Commercial Products revenue growth should be in the mid single digits. As a reminder, M365 Commercial Products includes both the Windows commercial on premises components of M365 suites and Office transactional purchasing both of which can be variable due to end period revenue recognition dynamics. M365 Consumer Cloud revenue growth should be in the mid teens driven by the January price increase. For LinkedIn, we expect revenue growth in the high single digits. And in Dynamics three sixty five, we expect revenue growth to be in the mid to high teens with continued growth across all workloads.\\n\\nFor Intelligent Cloud, we expect revenue of $28,750,000,000 to $29,050,000,000 or growth of 20 to 22% in constant currency. Revenue will continue to be driven by Azure which as a reminder can have quarterly variability primarily from in period revenue recognition depending on the mix of contracts. In Azure, we expect Q4 revenue growth to be between 3435% in constant currency driven by strong demand for our portfolio of services. In our non AI services, we expect focused execution to continue driving healthy growth. And in our AI services, while we continue to bring data center capacity online as planned, demand is growing a bit faster.\\n\\nTherefore, we now expect to have some AI capacity constraints beyond June. In our on premises server business, we again expect revenue to decline in the mid single digits with the ongoing customer shift to cloud offerings. And the Enterprise and Partner Services, we expect revenue growth to be in the mid to high single digits driven by Enterprise Support Services. In More Personal Computing, we expect revenue to be $12,350,000,000 to $12,850,000,000 Windows OEM and devices revenue should decline in the mid to high single digits. We expect Windows OEM revenue to decline in the low to mid single digits assuming OEM inventory levels come down through the quarter as noted earlier.\\n\\nAlthough the range of potential outcomes is wider than normal. Devices revenue should decline in the high teens. Search and news advertising ex TAC revenue growth should be in the high teens even on a strong prior year comparable. We expect to see continued growth in both volume and revenue per search with share gains across Edge and Bing. Overall search and news advertising revenue growth should be in the mid teens.\\n\\nAnd in gaming, we expect revenue growth to be in the mid single digits. We expect Xbox content and services revenue growth to be in the high single digits driven by first party content. Now back to company guidance. We expect COGS of 23,600,000,000.0 to $23,800,000,000 or growth of 19% to 20% in constant currency and operating expense of $18,000,000,000 to $18,100,000,000 or growth of approximately 5% in constant currency. Therefore, even with ongoing AI investments as we scale, we continue to expect full year FY 2025 operating margins expected to be roughly negative $1,200,000,000 primarily driven by investments accounted for under the equity method.\\n\\nAs a reminder, we do not recognize mark to market gains or losses on equity method investments. And lastly, we expect our Q4 effective tax rate to be approximately 19%. Now I\\'d like to share some closing thoughts as we look to the next fiscal year. We remain committed to investing against the strong demand signals we see for our services. So as a reminder, our earlier comments on FY 2026 capital expenditures remain unchanged.\\n\\nWe expect CapEx to grow. It will grow at a lower rate than FY 2025 and will include a greater mix of short lived assets, which are more directly correlated to revenue than long lived assets. These investments along with focused execution that delivers near term value to our customers will ensure we continue to lead through the cloud and AI opportunity ahead. With that, let\\'s go to Q and A, Jonathan.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Amy. We\\'ll now move over to Q and A.\\n\\n**Amy Hood, Chief Financial Officer, Microsoft**: Out of respect to others on the call,\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: we request that participants please only ask Operator, can you please repeat your instructions?\\n\\n**Conference Operator**: And our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed.\\n\\n**Keith Weiss, Analyst, Morgan Stanley**: Excellent. Thank you guys for taking the question and congratulations on a fantastic quarter. In what all of us are looking at as a difficult environment, a lot of uncertainty out there, so really impressive to put up the results that you guys did. One of the things that we heard a lot about this quarter in the media and press reports was changing data center commitments, maybe Microsoft walking away from some of those data center commitments. But it sounds like the AI demand is very strong.\\n\\nYou\\'re talking about not being able to hit all that demand with supply. So could you talk to us about what\\'s going on with your data center strategy? Are there any shifts taking place? And maybe in particular, Satya, you could talk about some of the comments that you had made about the potential risk for oversupply in GPUs out in the future. What exactly was that risk you were talking about?\\n\\nAnd are you incorporating that risk into your data center strategy?\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Yes. First of all, thanks, Keith, for the question. The reality is we\\'ve always been making adjustments to build, lease, what pace we build all through the last whatever, ten, fifteen years. It\\'s just that you all pay a lot more attention to what we do quarter over quarter nowadays. Having said that, the key thing for us is to have our build and lease be positioned for what is the workload growth of the future.\\n\\nRight? So that\\'s what you have to go and seek to. So there\\'s a demand part to it. There is the shape of the workload part to it and there is a location part So you don\\'t want to be upside down on having one big data center in one region when you have a global demand footprint.\\n\\nYou don\\'t want to be upside down when the shape of demand changes because after all with essentially pre training plus test time compute, that\\'s a big change in terms of how you think about even what is training, right, forget inferencing. So fundamentally given all of that and then every time that there\\'s great Moore\\'s Law, but remember this is a compounding sort of S curve, right, which is Moore\\'s Law, there\\'s system software, there\\'s model architecture changes, there\\'s the app server efficiency. Given all of that, we just want to make sure we\\'re building accounting for the latest and greatest sort of information we have on all of that. And that\\'s what you see reflected. And I feel very, very good about the pace.\\n\\nIn fact, Amy just mentioned, we will be short power. And so therefore but it\\'s not power it\\'s not a blanket statement. I need power in specific places so that we can either lease or build at the pace at which we want. And so that\\'s the sort of plan that we\\'re executing to. Maybe Amy, you can add\\n\\n**Amy Hood, Chief Financial Officer, Microsoft**: to that.\\n\\n**Unspecified Speaker**: Yes. Maybe just to add a little bit to Satya\\'s comments. Just a reminder, these are very long lead time decisions from land to build to build outs can be lead times of five to seven years, two to three years. So we\\'re constantly in a balancing position as we watch demand curves and many of the things Satya watched. And the second part is just to maybe remind you when Satya talks about being short power, he\\'s really talking about data center space.\\n\\nAnd so we\\'ve continued through the second half to put things in place. In fact, we talked a little bit about pulling even some of that space to be ready earlier and being able to deliver that earlier to customers this quarter, which is really good work by the teams as we continue to get more and more efficient at that process. And I look forward to being able to continue to do that in the future. I did talk about in my comments, we had hoped to be in balance by the end of Q4. We did see some increased demand, as you saw through the quarter.\\n\\nSo, we are going to be a little short, still stay a little tight as we exit the year, but are encouraged by that.\\n\\n**Keith Weiss, Analyst, Morgan Stanley**: Excellent. Thank you, guys.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Keith. Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Brent Thill with Jefferies. Please proceed.\\n\\n**Brent Thill, Analyst, Jefferies**: Thanks. Satya, on your comment about accelerating demand for cloud migrations, I\\'m curious if you could dig in and extrapolate a little more what you\\'re seeing there? Thank you.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Thanks, Brent. So yes, so I sort of think about three big things that are happening in the cloud all in parallel and there\\'s also a relationship between them. One is, I\\'ll just say the classic migration of whether it\\'s SQL, Windows Server. And so that sort of again got good steady state progress because the reality is, I think everyone\\'s now perhaps there\\'s another sort of kick in the data center migrations just because of the efficiency, the cloud provides. So that\\'s sort of one part.\\n\\nThe second piece is good data growth. You saw some like Postgres on Azure. I mean, forgetting even SQL Server, Postgres on Azure is growing, Cosmos is growing. The analytics stuff I talked about with Fabric. It\\'s even the others, whether it is Databricks or even Snowflake on Azure are growing.\\n\\nSo we feel very good about Fabric, growth and our data growth. Then the cloud native growth. So this is again before we even get to AI, some of the core compute consumption of cloud native players is also pretty very healthy. It was healthy throughout the quarter. We projected to go moving forward as well.\\n\\nThen the thing to notice is the ratio and I think we mentioned this multiple times before. If you look underneath even chat GPT, in fact that team does a fantastic job of thinking about not only their growth in terms of AI accelerators they need, they use Cosmos DB, they use Postgres, they use core compute and storage. And so there\\'s even a ratio between any AI workload in terms of AI accelerator to others. So those are the four pockets, I\\'d say, or four different trend lines which all have a relationship with each other. And if I step back, and Amy and I talk a lot about this, this time around there\\'s nothing certain for sure in the future except for one thing, which is our largest business is our infrastructure business.\\n\\nAnd the good news here is the next big platform shift builds on that. So it\\'s not a complete rebuild. Having gone through some of these platform shifts where you have to come out on the other side with a full rebuild. If there is good news here and is that we have a good business in Azure that continues to grow and the new platform depends on that. So we want to stay disciplined and execute super well on that.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thank you. Thanks, Brent. Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.\\n\\n**Mark Moerdler, Analyst, Bernstein Research**: Thank you very much for taking my question and I will reiterate what my peers have said. Congratulations on the great quarter. Satya and Amy, Microsoft is a very different business than it was during the last recession. Incredible job you\\'ve done. If we get into a recession, I hope we don\\'t, how do you think about the stability, the sustainability, revenue volatility of Microsoft today if we were to get into recession?\\n\\nWould the business react early to recession or late? Would a recession have a more shallow impact on revenue? Any thoughts would\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: be appreciated. Maybe I\\'ll start and then Amy should add, Mark. The way at least I think we will approach it is quite frankly be very focused on how we help our customers. If there is any turbulence in the macro. Because one of the things that we feel we can\\'t do just because of the efficiencies of the cloud And the footprint we have and the differentiated sort of layers of the stack from the SaaS application side to the infrastructure side.\\n\\nI think if you sort of buy into the argument that software is the most malleable resource we have to fight any type of inflationary pressure or any type of growth pressure where you need to do more with less, I think we can be super helpful in that. And so if anything, we would probably have more of that mindset is how do we make sure we are helping our customers. And then of course, we\\'ll look to share gains.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Mark. Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Karl Keirstead with UBS. Please proceed.\\n\\n**Brent Thill, Analyst, Jefferies**: Okay. Thanks. A number of metrics to applaud, but I think the one that stands out to me is the 16 growth rate lift to Azure from AI. Sachin, Amy, I\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: just wanted to ask if you\\n\\n**Brent Thill, Analyst, Jefferies**: could unpack that a little bit. Of course, you mentioned that you got a bit of a kicker from capacity coming online. But I\\'m a little bit more interested in where the demand came in above expectations, like what workload type. It\\'s hard for us to see that on the outside. Was it a surge in ChatGPT inference that landed in Azure?\\n\\nWas it an uptick in enterprise AI adoption? And Amy, do you think that 16 points could be higher in June? Thank you.\\n\\n**Unspecified Speaker**: Thanks, Carl, for the question. Just to provide some clarity, because I think your question implies something that we didn\\'t mean to imply on the call. First, the real outperformance in Azure this quarter was in our non AI business. So then to talk about the AI business, really what was better was precisely what we said. We talked about this.\\n\\nWe knew Q3 that we had really matched supply and demand pretty carefully and so didn\\'t expect to do much better than we had guided to on the AI side. We\\'ve been quite consistent on that. So the only real upside we saw on the AI side of the business was that we were able to deliver supply early to a number of customers. And being able to do that throughout the quarter creates quite a good benefit to us. But the majority of our outperformance versus where we had expected to be was on the non AI piece of the business.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Karl. Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Kash Rangan with Goldman Sachs. Please proceed.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Hi, thank you very much. One question for Amy. You\\'ve said in the past that you can attain better and better capital efficiency with the cloud business and probably cloud and AI business. Where do you stand today, Amy? Maybe, Satya, you can opine as well, that you\\'ve said before that you can slow down your CapEx growth rate while still accelerate Azure, which includes AI.\\n\\nCan we get a mark to market on that? Thank you so much.\\n\\n**Unspecified Speaker**: Maybe I\\'ll I\\'ll start, Kash, and let Satya add on. Because I really think when you go back and read some of Satya\\'s comments on how the s curves build on themselves, that\\'s actually the levers that go into the answer of the question that you\\'re asking. And so the way, of course, you\\'ve seen that historically is, right, when we went through the prior cloud transitions, you see CapEx accelerate, you build out data center footprints, you slowly fill CPU capacity. And over time, you see software efficiencies and hardware efficiencies build on themselves. And you saw that process for us for, goodness, now quite a long time.\\n\\nAnd what Tatya is talking about is how quickly that\\'s happening on the AI side of the business and you add to that model diversity. So think about the same levers plus model efficiency, those compound. Now the one thing that\\'s a little different this time is just the pace. And so when you\\'re seeing that happen, pace in terms of efficiency side, but also pace in terms of the build out, So it can mask some of the progress, but we are working hard across all of the teams, hardware, software, even the build teams to get things in place as quickly as possible, dock to live times. All of that is improving and all of that actually is benefiting us.\\n\\nAnd I\\'ll go ahead and say, our margins on the AI side of the business are better than they were at this point by far than when we went through the same transition and the server to cloud transition.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Yes. I mean, I think at a macro level, think the way to think about this is you can ask the question, what\\'s the difference between a hosting business and a hyperscale business? It\\'s software. That\\'s I think the gist of it. We asked for sure it\\'s a capital intensive business, but capital efficiency comes from that system wide software optimization.\\n\\nAnd that\\'s what makes the hyperscale business attractive and that\\'s what we want to just keep executing super well on. Super. Thanks so much.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Mark Murphy with JPMorgan. Please proceed.\\n\\n**Mark Murphy, Analyst, JPMorgan**: Thank you so much. Satya, you had commented recently that the DeepSeek moment is a real thing. And you had said that software efficiencies mean that the fleet will be aged for a longer time. Can you comment on how those advances are affecting the pace and volume of AI experimentation and activity in the marketplace? And Amy, could we start to consider the possibility that software enhancements might extend the useful life assumption that you\\'re using for GPUs?\\n\\nOr is it a little premature to be thinking that way?\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Yeah. First of all, I think some of the work that actually OpenAI first pioneered and did with all of the reasoning models and of course DeepSeek has sort of added to it and done good work as well and others as well. The idea that you can have test time compute plus pre training and then some of the great optimization at inference time that has all happened has proven out. I mean if you look at it, I would say for every Moore\\'s law change and movement, there\\'s probably a 10x improvement because of software, right? That\\'s sort of what\\'s happening with these models.\\n\\nSome of it comes from model architecture, some of that comes from data efficiency, compute efficiency and what have you. So that\\'s what we are riding and we feel that all up when you have a commodity that is getting that better then the question is how do you build out a fleet that\\'s super balanced so that then the workloads can be built and can in fact take advantage of that efficiency at the underlying infrastructure. I mean it\\'s kind of like virtualization. What is the difference between servers and sort of again client server with virtualization? It was efficiency.\\n\\nWhat is the difference between virtualization and cloud? It was efficiency. What is the difference between this generation of cloud and AI? It\\'s efficiency. So the more you can kind of continue to think about software driving that efficiency is what drives demand ultimately.\\n\\n**Unspecified Speaker**: And to your specific question, in terms of thinking about the depreciable life of an asset, we like to have a long history before we make any of those. We\\'re focused on getting every bit of useful life we can, of course, out of assets. But to Tatya\\'s point, that tends to be a software question more than a hardware one.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Thank you. Thanks, Mark.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Kirk Materne with Evercore ISI. Please proceed.\\n\\n**Kirk Materne, Analyst, Evercore ISI**: Yes, thanks very much and congrats on a great quarter. Amy, you mentioned that the upside in Azure came from the non AI services this time around. I was wondering if you could just talk a little bit more about that. And I guess as you look forward, maybe what\\'s different this go round versus what we saw a few years ago when obviously things like optimization weighed on the growth a little bit? It sounds like the product portfolio is much broader right now.\\n\\nBut just wondering if you could add some color on that front. Thank you.\\n\\n**Unspecified Speaker**: Sure. And thanks for the question, Kirk. When we go to non AI, I talked a little bit about this. In general, we saw better than expected performance across our segments, but we saw acceleration in our largest customers. We call that the enterprise segment in general.\\n\\nAnd then in what we talked about of our scale motions where we had some challenges in Q2, things were a little better. And we still have some work to do in our scale motions, and we\\'re encouraged by our progress. We\\'re excited to stay focused on that as, of course, we work through the final quarter of our fiscal year. By geo, the performance was pretty consistent. Satya actually highlighted some of the workloads that came in a little better than we thought.\\n\\nObviously, just some good consistent work on migrations, good execution by the sales and partner teams, the data workloads he went through. And so in general, Kirk, I wouldn\\'t say it\\'s anything beyond that. I do think it was improved execution, And I was happy to see it, but there\\'s still some work to do on our scale motions in particular. Thank you.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Thanks, Kirk.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Operator, we have time for one last question.\\n\\n**Conference Operator**: The last question will come from the line of Alex Zukin with Wolfe Research. Please proceed.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**0: Hey, guys. Thanks for squeezing me in. And again, just amazing congratulations on those Azure numbers, which I think are quite honestly just inspiring. So so maybe to Amy, to to the point that you\\'re making that the surprise factor was on the non Azure, non AI side of the house. And and it sounds like that there\\'s confidence in that continuing, beyond.\\n\\nHow much of that are you starting to see the pull pull in of the non AI driven by the AI portion of Azure? And on the AI portion specifically, as test time compute really just blows out kind of prior conceptions of scaling law challenges, how much does that change potentially the curve of the AI Azure growth as you go forward here over the next few quarters?\\n\\n**Unspecified Speaker**: Hi, Doc. Let me, first of all, say I think we\\'ve talked about this quite a bit. It\\'s always good to have a chance to to iterate this. It\\'s getting harder and harder to separate what an AI workload is from a non AI workload. And we\\'ve talked about it this way, I think, in most instances, to make sure people understood that when we were accelerating all of our CapEx spend over the past two point five three years now, that people had confidence that we were turning that into revenue and product in a way that was transparent and that everyone could understand really the goals that we had set for ourselves and for our partners and customers in terms of building product that turned to Revit.\\n\\nBut\\n\\n**Amy Hood, Chief Financial Officer, Microsoft**: if you take a\\n\\n**Unspecified Speaker**: step back from that, it\\'s that these workloads are being built, GPU, CPU, storage, network, all the same things. And so I think, really, what we\\'re talking about is really how Satya talked about in one of the earlier questions. You know, we\\'re seeing digital natives. Digital natives build workloads. They do AI work.\\n\\nThey do non AI work. Do they tend to do that work in the same cloud? Lots of times. Sometimes, it\\'s all in the same place. Not all the time, but that relationship gets stronger and stronger as people pivot to more of AI heavy workloads.\\n\\nAnd so I think you\\'re starting to see some of that relationship. I think we\\'ll continue to see that as AI workloads continue to get built and experimented with and proof of concepts get expanded. And so I think I mostly focus on the fact that together we saw good performance in Q3 on Azure. Azure inclusive of both components in terms of our execution, in terms of the field and partner teams and backlog and conversion and interesting workloads and adding customer value and solving real problems and adding real value. And I think that\\'s probably how I would approach that number more than trying to separate it in the way that even we have talked about it, but for very different reasons.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Alex. That wraps up the Q and A portion of today\\'s earnings call. Thank you for joining us today, and we look forward to speaking with you all soon.\\n\\n**Unspecified Speaker**: Thank you. Thank you.\\n\\n**Conference Operator**: This concludes today\\'s conference. You may disconnect your lines at this time. Enjoy the rest of your day.\\n\\n*This article was generated with the support of AI and reviewed by an editor. For more information see our T&C.*\\n\\n## Should you be buying MSFT right now?\\n\\n**ProPicks AI evaluates MSFT alongside thousands of other companies every month using 100+ financial metrics**.   \\n  \\n Using powerful AI to generate exciting stock ideas, it looks beyond popularity to assess fundamentals, momentum, and valuation. The AI has no bias—it simply identifies which stocks offer the best risk-reward based on current data with notable past winners that include Super Micro Computer (+185%) and AppLovin (+157%).   \\n  \\n Want to know if MSFT is currently featured in any ProPicks AI strategies, or if there are better opportunities in the same space?\\n\\n[See Stocks](/pro/propicks)\\n\\nEarnings call transcript: Microsoft Q1 2025 earnings beat expectations, stock surges\\n\\n[View all comments (0)0](#comments-3985817)\\n\\n## Latest comments\\n\\nLoading next article…\\n\\n[Trade With A Regulated Broker](https://ca.investing.com/brokers/)\\n\\n1D\\n\\n1W\\n\\n1M\\n\\n6M\\n\\n1Y\\n\\n5Y\\n\\nMax\\n\\n[S&P/TSX](https://ca.investing.com/indices/s-p-tsx-composite \"S&P/TSX Composite\")\\n\\n32,425.65\\n\\n+241.77\\n\\n+0.75%\\n\\n[S&P/TSX 60](https://ca.investing.com/indices/s-p-tsx-60 \"S&P/TSX 60\")\\n\\n1,877.30\\n\\n+7.35\\n\\n+0.39%\\n\\n[US 30](https://ca.investing.com/indices/us-30-futures?cid=1175152 \"US 30 Cash - (CFD)\")\\n\\n49,461.60\\n\\n+53.9\\n\\n+0.11%\\n\\n[US 500](https://ca.investing.com/indices/us-spx-500-futures?cid=1175153 \"US 500 Cash - (CFD)\")\\n\\n6,947.90\\n\\n-28.6\\n\\n-0.41%\\n\\n[S&P 500 VIX](https://ca.investing.com/indices/volatility-s-p-500 \"CBOE Volatility Index - (CFD)\")\\n\\n17.04\\n\\n+0.70\\n\\n+4.28%\\n\\n[DAX](https://ca.investing.com/indices/germany-30 \"DAX - (CFD)\")\\n\\n24,787.68\\n\\n+2.76\\n\\n+0.01%\\n\\n[Dollar Index](https://ca.investing.com/currencies/us-dollar-index \"US Dollar Index Futures - (CFD)\")\\n\\n97.29\\n\\n-0.202\\n\\n-0.21%\\n\\n[Crude Oil WTI Futures](https://ca.investing.com/commodities/crude-oil \"Crude Oil WTI Futures - (CFD)\")\\n\\n62.88\\n\\n+0.74\\n\\n+1.19%\\n\\n[Brent Oil Futures](https://ca.investing.com/commodities/brent-oil \"Brent Oil Futures - (CFD)\")\\n\\n66.94\\n\\n+0.64\\n\\n+0.97%\\n\\n[Natural Gas Futures](https://ca.investing.com/commodities/natural-gas \"Natural Gas Futures - (CFD)\")\\n\\n3.362\\n\\n+0.125\\n\\n+3.86%\\n\\n[Gold Futures](https://ca.investing.com/commodities/gold \"Gold Futures - (CFD)\")\\n\\n4,945.79\\n\\n+293.19\\n\\n+6.30%\\n\\n[Silver Futures](https://ca.investing.com/commodities/silver \"Silver Futures - (CFD)\")\\n\\n88.185\\n\\n+11.176\\n\\n+14.51%\\n\\n[US Soybeans Futures](https://ca.investing.com/commodities/us-soybeans \"US Soybeans Futures - (CFD)\")\\n\\n1,069.13\\n\\n+9.13\\n\\n+0.86%\\n\\n[US Cotton #2 Futures](https://ca.investing.com/commodities/us-cotton-no.2 \"US Cotton #2 Futures - (CFD)\")\\n\\n62.66\\n\\n-0.01\\n\\n-0.02%\\n\\n[BBDb](https://ca.investing.com/equities/bombardier-inc \"Bombardier Inc\")\\n\\n242.50\\n\\n+5.780\\n\\n+2.44%\\n\\n[ENB](https://ca.investing.com/equities/enbridge-inc. \"Enbridge Inc\")\\n\\n49.03\\n\\n+0.75\\n\\n+1.55%\\n\\n[AC](https://ca.investing.com/equities/air-canada \"Air Canada\")\\n\\n20.28\\n\\n+0.70\\n\\n+3.58%\\n\\n[AVGO](https://ca.investing.com/equities/broadcom-drc \"Broadcom Inc DRC\")\\n\\n12.20\\n\\n-0.57\\n\\n-4.46%\\n\\n[AAPL](https://ca.investing.com/equities/apple-computer-inc \"Apple Inc\")\\n\\n268.88\\n\\n-1.13\\n\\n-0.42%\\n\\n[BABA](https://ca.investing.com/equities/alibaba \"Alibaba Group Holdings Ltd ADR\")\\n\\n164.92\\n\\n-3.47\\n\\n-2.06%\\n\\n[TSLA](https://ca.investing.com/equities/tesla-motors \"Tesla Inc\")\\n\\n426.53\\n\\n+4.72\\n\\n+1.12%\\n\\n[Canada 5Y](https://ca.investing.com/rates-bonds/canada-5-year-bond-yield \"Canada 5-Year\")\\n\\n2.957\\n\\n+0.019\\n\\n+0.65%\\n\\n[Canada 10Y](https://ca.investing.com/rates-bonds/canada-10-year-bond-yield \"Canada 10-Year\")\\n\\n3.449\\n\\n+0.012\\n\\n+0.35%\\n\\n[Canada 30Y](https://ca.investing.com/rates-bonds/canada-30-year-bond-yield \"Canada 30-Year\")\\n\\n3.894\\n\\n+0.016\\n\\n+0.41%\\n\\n[U.S. 2Y](https://ca.investing.com/rates-bonds/u.s.-2-year-bond-yield \"United States 2-Year\")\\n\\n3.578\\n\\n+0.008\\n\\n+0.22%\\n\\n[U.S. 10Y](https://ca.investing.com/rates-bonds/u.s.-10-year-bond-yield \"United States 10-Year\")\\n\\n4.288\\n\\n+0.010\\n\\n+0.23%\\n\\n[U.S. 30Y](https://ca.investing.com/rates-bonds/u.s.-30-year-bond-yield \"United States 30-Year\")\\n\\n4.915\\n\\n+0.006\\n\\n+0.12%\\n\\n[Germany 10Y](https://ca.investing.com/rates-bonds/germany-10-year-bond-yield \"Germany 10-Year\")\\n\\n2.8924\\n\\n+0.0254\\n\\n+0.89%\\n\\nMost Popular Articles\\n\\nNews\\n\\nAnalysis\\n\\n[Gold could crash 99.9% in worst-case scenario, this strategist says](https://ca.investing.com/news/commodities-news/gold-could-crash-999-in-worstcase-scenario-this-strategist-says-4434440)\\n\\nBy Investing.co...\\n\\nFeb 03, 2026\\n\\n[TSX futures rise amid stabilizing gold prices, earnings deluge](https://ca.investing.com/news/stock-market-news/tsx-futures-rise-amid-stabilizing-gold-prices-earnings-deluge-4434490)\\n\\nBy Investing.co...\\n\\nFeb 03, 2026\\n\\n[Palantir, Capri and Marathon gain premarket; Merck and Pfizer fall](https://ca.investing.com/news/stock-market-news/palantir-capri-and-marathon-gain-premarket-merck-and-pfizer-fall-4434461)\\n\\nBy Investing.co...\\n\\nFeb 03, 2026\\n\\n[Baird upgrades Palantir: Revenue and FCF ‘too impressive’](https://ca.investing.com/news/stock-market-news/baird-upgrades-palantir-revenue-and-fcf-too-impressive-4434489)\\n\\nBy Investing.co...\\n\\nFeb 03, 2026\\n\\n[Nvidia stock muted as OpenAI seeks AI chip rivals](https://ca.investing.com/news/stock-market-news/nvidia-stock-falls-as-openai-seeks-ai-chip-rivals-4433094)\\n\\nBy Investing.co...\\n\\nFeb 03, 2026\\n\\n[7 Deeply Oversold Stocks Entering February With Rebound Potential](https://ca.investing.com/analysis/7-deeply-oversold-stocks-entering-february-with-rebound-potential-200621794)\\n\\nBy David Wagner\\n\\nFeb 03, 2026\\n\\n[Gold’s Fate Now Hinges on the Dollar and US Data After Friday’s Shock](https://ca.investing.com/analysis/golds-fate-now-hinges-on-the-dollar-and-us-data-after-fridays-shock-200621761)\\n\\nBy Fawad Razaqz...\\n\\nFeb 02, 2026\\n\\n[Silver: CME Margin Hikes Explain the Price Rout](https://ca.investing.com/analysis/silver-cme-margin-hikes-explain-the-price-rout-200621733)\\n\\nBy Ed Yardeni\\n\\nFeb 02, 2026\\n\\n[Copper in a World That Runs on Electricity](https://ca.investing.com/analysis/copper-in-a-world-that-runs-on-electricity-200621593)\\n\\nBy Charles-Henr...\\n\\nJan 31, 2026\\n\\n[AMD Earnings Preview: Computing Demand Likely to Lift Q4 Sales](https://ca.investing.com/analysis/amd-earnings-preview-computing-demand-likely-to-lift-q4-sales-200621789)\\n\\nBy Ali Merchant\\n\\nFeb 03, 2026\\n\\n[More News](https://ca.investing.com/news/most-popular-news)\\n\\n[Market Movers](https://ca.investing.com/markets/canada)\\n\\n| Name | Last | Chg. % | Vol. |  |\\n| --- | --- | --- | --- | --- |\\n| [Bank of Montreal](https://ca.investing.com/equities/bank-of-montreal-financial-group) | 192.17 | +1.49% | 2.30M |  |\\n| [Barrick Mining](https://ca.investing.com/equities/barrick-gold-corp.?cid=1055210) | 65.50 | +3.36% | 1.98M |  |\\n| [Thomson Reuters](https://ca.investing.com/equities/thomson-reuters-corp) | 125.33 | -15.89% | 793.80K |  |\\n| [Shopify Inc](https://ca.investing.com/equities/shopify-inc?cid=25152) | 167.00 | -7.54% | 782.55K |  |\\n| [Celestica Inc.](https://ca.investing.com/equities/celestica) | 398.78 | +2.30% | 232.15K |  |\\n| [Constellation Software](https://ca.investing.com/equities/constellation-software-inc) | 2,281.02 | -7.06% | 44.43K |  |\\n| [Fairfax Financial](https://ca.investing.com/equities/fairfax-financial-holdings-ltd) | 2,265.66 | -0.21% | 41.64K |  |\\n\\n| Name | Last | Chg. % | Vol. |  |\\n| --- | --- | --- | --- | --- |\\n| [Global Cannabis Apps](https://ca.investing.com/equities/fundamental-applications-corp?cid=1075477) | 0.020 | +100.00% | 8.00K |  |\\n| [Martello Tech](https://ca.investing.com/equities/newcastle-energy-corp.) | 0.0100 | +100.00% | 15.59K |  |\\n| [Playgon Games](https://ca.investing.com/equities/global-daily-fantasy-sports-inc) | 0.0100 | +100.00% | 4.50K |  |\\n| [Alturas Minerals](https://ca.investing.com/equities/alturas-minerals-corp.) | 0.010 | +100.00% | 20.60K |  |\\n| [Pulse Oil](https://ca.investing.com/equities/pulse-oil) | 0.0150 | +50.00% | 8.73K |  |\\n|  | 0.0150 | +50.00% | 1.00K |  |\\n| [Questcorp Mining](https://ca.investing.com/equities/questcorp-mining?cid=1209619) | 0.35 | +43.75% | 21.00K |  |\\n\\n| Name | Last | Chg. % | Vol. |  |\\n| --- | --- | --- | --- | --- |\\n|  | 0.0200 | -42.86% | 105.80K |  |\\n| [Intertidal Capital](https://ca.investing.com/equities/intertidal-capital) | 0.11 | -42.11% | 30.00K |  |\\n| [Abasca Resources](https://ca.investing.com/equities/amv-capital-corp) | 0.0750 | -37.50% | 4.60K |  |\\n| [Providence Gold Mines](https://ca.investing.com/equities/red-hut-metals-inc) | 0.0500 | -28.57% | 156.00K |  |\\n| [Current Water](https://ca.investing.com/equities/enpar-technologies-inc.) | 0.020 | 0.00% | 31.44K |  |\\n| [Canso Select Opportunities Fund](https://ca.investing.com/equities/canso-select-opportunities-fund-v) | 6.00 | -25.00% | 100.00 |  |\\n| [TAG Oil](https://ca.investing.com/equities/tag-oil-ltd) | 0.10 | -24.00% | 897.90K |  |\\n\\n## [Trending Stocks](https://ca.investing.com/equities/trending-stocks)\\n\\n| Name | Last | Chg. % | Vol. |  |\\n| --- | --- | --- | --- | --- |\\n| [Celestica Inc.](https://ca.investing.com/equities/celestica) | 398.17 | +2.14% | 232.45K |  |\\n| [BCE Inc](https://ca.investing.com/equities/bce) | 35.58 | +0.79% | 868.38K |  |\\n| [Canadian Imperial Bank](https://ca.investing.com/equities/cibc) | 129.49 | -0.11% | 370.64K |  |\\n| [Air Canada](https://ca.investing.com/equities/air-canada) | 20.30 | +3.68% | 2.14M |  |\\n| [Hut 8](https://ca.investing.com/equities/hut-8-mining) | 79.160 | +3.13% | 551.48K |  |\\n\\nShow more\\n\\nProPicks AI\\n\\nAI-powered **stock picks** with a proven track record to **beat the S&P 500**.\\n\\n[Beat the TSX](/pro/propicks/beat-tsx)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-tsx?entry=ws_propicks)\\n\\n[Canadian Bargains](/pro/propicks/canadian-bargains)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/canadian-bargains?entry=ws_propicks)\\n\\n[Beat the S&P 500](/pro/propicks/beat-sp-500)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-sp-500?entry=ws_propicks)\\n\\n[Dominate the Dow](/pro/propicks/dominate-the-dow)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/dominate-the-dow?entry=ws_propicks)\\n\\n[Tech Titans](/pro/propicks/tech-titans)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/tech-titans?entry=ws_propicks)\\n\\n[Mid-Cap Movers](/pro/propicks/midcap-movers)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/midcap-movers?entry=ws_propicks)\\n\\n[Top Value Stocks](/pro/propicks/top-value-stocks)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/top-value-stocks?entry=ws_propicks)\\n\\n[Best of Buffett](/pro/propicks/best-of-buffett)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/best-of-buffett?entry=ws_propicks)\\n\\n[Mexican Stock Exchange Leaders](/pro/propicks/beat-bmv-ipc)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-bmv-ipc?entry=ws_propicks)\\n\\n[Best Brazilian Stocks](/pro/propicks/beat-bovespa)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-bovespa?entry=ws_propicks)\\n\\n[Italian Market Elite](/pro/propicks/beat-ftse-italia)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-ftse-italia?entry=ws_propicks)\\n\\n[Alpha Germany Select](/pro/propicks/beat-dax)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-dax?entry=ws_propicks)\\n\\n[TASI Superstars](/pro/propicks/beat-tasi)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-tasi?entry=ws_propicks)\\n\\n[Korean Market Leaders](/pro/propicks/beat-kospi)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-kospi?entry=ws_propicks)\\n\\n[Mexican Bargains](/pro/propicks/mexican-bargains)\\n\\nStocks in this strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/mexican-bargains?entry=ws_propicks)\\n\\n---\\n\\nCalendars\\n\\n[Economic Calendar](/economic-calendar/)[Earnings Calendar](/earnings-calendar/)[Holiday Calendar](/holiday-calendar/)\\n\\nUS Economy\\n\\n[Fed Rate Monitor Tool](/central-banks/fed-rate-monitor)[US Treasury Yield Curve](/rates-bonds/usa-government-bonds)\\n\\nMore Tools\\n\\n[Stock Screener](/stock-screener/)[Currency Converter](/currency-converter/)\\n\\nInstall Our AppScan QR code to install app\\n\\nRisk Disclosure: Trading in financial instruments and/or cryptocurrencies involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors. Prices of cryptocurrencies are extremely volatile and may be affected by external factors such as financial, regulatory or political events. Trading on margin increases the financial risks.  \\nBefore deciding to trade in financial instrument or cryptocurrencies you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.  \\n**Fusion Media**\\xa0would like to remind you that the data contained in this website is not necessarily real-time nor accurate. The data and prices on the website are not\\xa0necessarily\\xa0provided by any market or exchange, but may be provided by\\xa0market makers, and so prices may not be accurate and may differ from the actual price at any given market, meaning prices are indicative and not appropriate for trading purposes.\\xa0**Fusion Media**\\xa0and\\xa0any provider of the data contained in this website\\xa0will not accept liability for any loss or damage as a result of your trading, or your reliance on the information contained within this website.  \\nIt is prohibited to use, store, reproduce, display, modify, transmit or distribute the data contained in this website without the explicit prior written permission of Fusion Media and/or the data provider. All intellectual property rights are reserved by the providers and/or the exchange providing the data contained in this website.  \\n**Fusion Media** may be compensated by the advertisers that appear on the website, based on your interaction with the advertisements or advertisers.\\n\\n© 2007-2026 - Fusion Media Limited. All Rights Reserved.'},\n",
              " {'title': 'Microsoft FY25 First Quarter Earnings Conference Call',\n",
              "  'url': 'https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1',\n",
              "  'content': 'Segment gross margin dollars increased 11% and 12% in constant currency and gross margin percentage decreased slightly year-over-year driven by scaling our AI infrastructure. Operating expenses increased 2% and operating income increased 16%.\\n\\nNext, the Intelligent Cloud segment. Revenue was $24.1 billion, increasing 20% and 21% in constant currency, in line with expectations. [...] In our on-premises server business, revenue decreased 1%. Lower-than-expected transactional purchasing ahead of the Windows Server 2025 launch, as well as lower purchasing of licenses running in multi-cloud environments, was mostly offset by the benefit from in-period revenue recognition noted earlier.\\n\\nEnterprise and partner services revenue decreased 1% and was relatively unchanged in constant currency.\\n\\nSegment gross margin dollars increased 15% and gross margin percentage decreased 3 points year-over-year driven by scaling our AI infrastructure. Operating expenses increased 8% and operating income grew 18%. [...] We set new records for monthly active users in the quarter, as more players than ever play our games across devices and on the Xbox platform.\\n\\nGame Pass also set a new Q1 record for total revenue and average revenue per subscriber.\\n\\nAnd, as we look ahead, our IP across our studios has never been stronger.\\n\\nLast week’s launch of Black Ops 6 was the biggest Call of Duty release ever, setting a record for day one players, as well as Game Pass subscriber adds on launch day. And unit sales on PlayStation and Steam were also up over 60% year-over-year.\\n\\nThis speaks to our strategy of meeting gamers where they are by enabling them to play more games across the screens they spend their time on.',\n",
              "  'score': 0.93338853,\n",
              "  'raw_content': \"Microsoft Fiscal Year 2025 First Quarter Earnings Conference Call\\n===============\\n This is the Trace Id: 755b5c6399fd0115d9cc2bbc81bd34ca \\n\\n![Image 1](https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1)\\n\\n[](https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1)\\n\\n[Skip to main content](javascript:void(0))\\n\\n[![Image 2](https://uhf.microsoft.com/images/microsoft/RE1Mu3b.png)Microsoft](https://www.microsoft.com/)\\n\\nInvestor Relations\\n\\n[Investor Relations](https://www.microsoft.com/en-us/investor/default)\\n\\n Investor Relations \\n\\n*   [Home](https://www.microsoft.com/en-us/investor/default)\\n*   \\nEarnings & Financials\\n    *   Earnings Releases Earnings Releases\\n        *   [Press Release & Webcast](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q4/press-release-webcast)\\n        *   [Financial Statements](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q4/income-statements)\\n        *   [Performance](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q4/performance)\\n        *   [Metrics](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q4/metrics)\\n        *   [Segment Results](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q4/productivity-and-business-processes-performance)\\n\\n    *   Financial Statements Financial Statements\\n        *   [Income Statements](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q4/income-statements)\\n        *   [Comprehensive Income](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q4/comprehensive-income)\\n        *   [Balance Sheets](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q4/balance-sheets)\\n        *   [Cash Flows](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q4/cash-flows)\\n        *   [Segment Revenue & Operating Income](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q4/segment-revenues)\\n\\n*   \\nBoard & ESG\\n    *   [Overview](https://www.microsoft.com/en-us/Investor/corporate-governance/overview)\\n    *   Corporate Governance Corporate Governance\\n        *   [Overview](https://www.microsoft.com/en-us/Investor/corporate-governance/framework)\\n        *   [Board of Directors](https://news.microsoft.com/leadership/board-members/)\\n        *   [Board Committees](https://www.microsoft.com/en-us/Investor/corporate-governance/board-of-directors)\\n        *   [Policies and Guidelines](https://www.microsoft.com/en-us/Investor/corporate-governance/policies)\\n\\n    *   [Environment](https://www.microsoft.com/en-us/corporate-responsibility/sustainability)\\n    *   Social Social\\n        *   [Overview](https://www.microsoft.com/en-us/corporate-responsibility)\\n        *   [Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai?ef_id=_k_60dc31553aed12d2c21a573941cc3017_k_&OCID=AIDcmm1o1fzy5i_SEM__k_60dc31553aed12d2c21a573941cc3017_k_&msclkid=60dc31553aed12d2c21a573941cc3017)\\n        *   [Privacy & Cybersecurity](https://www.microsoft.com/en-us/corporate-responsibility/privacy)\\n        *   [Workplace & Culture](https://www.microsoft.com/en-us/corporate-responsibility/empowering-employees)\\n        *   [Diversity & Inclusion](https://www.microsoft.com/en-us/diversity/default.aspx)\\n        *   [Human Rights](https://www.microsoft.com/en-us/corporate-responsibility/human-rights)\\n        *   [Responsible Sourcing](https://www.microsoft.com/en-us/corporate-responsibility/responsible-sourcing)\\n\\n    *   [ESG Reports Hub](https://www.microsoft.com/en-us/corporate-responsibility/reports-hub)\\n    *   [Awards & Recognition](https://www.microsoft.com/en-us/corporate-responsibility/recognition)\\n\\n*   [Annual Reports](https://www.microsoft.com/en-us/Investor/annual-reports)\\n*   [SEC Filings](https://www.microsoft.com/en-us/Investor/sec-filings)\\n*   \\nInvestor Information\\n    *   [Information for Investors](https://www.microsoft.com/en-us/investor/investor-information)\\n    *   [Annual Meeting](https://www.microsoft.com/en-us/investor/annual-meeting)\\n    *   [Dividends & Stock History](https://www.microsoft.com/en-us/Investor/dividends-and-stock-history)\\n    *   [Investment History](https://www.microsoft.com/en-us/Investor/investment-history)\\n    *   [Acquisition History](https://www.microsoft.com/en-us/Investor/acquisition-history)\\n    *   [FAQ](https://www.microsoft.com/en-us/investor/faq)\\n\\n*   \\nEvents\\n    *   [All Events](https://www.microsoft.com/en-us/investor/events/default)\\n    *   [Past Events](https://www.microsoft.com/en-us/investor/events/events-recent)\\n    *   [Upcoming Events](https://www.microsoft.com/en-us/investor/events/events-upcoming)\\n\\n*   [Contacts](https://www.microsoft.com/en-us/Investor/contact-information)\\n*   More \\n\\n*   \\nAll Microsoft\\n    *   Global\\n------\\n\\n        *   [Microsoft 365](https://www.microsoft.com/microsoft-365)\\n        *   [Teams](https://www.microsoft.com/en-us/microsoft-teams/group-chat-software)\\n        *   [Copilot](https://copilot.microsoft.com/)\\n        *   [Windows](https://www.microsoft.com/en-us/windows/)\\n        *   [Surface](https://www.microsoft.com/surface)\\n        *   [Xbox](https://www.xbox.com/)\\n        *   [Deals](https://www.microsoft.com/en-us/store/b/sale?icid=DSM_TopNavDeals)\\n        *   [Small Business](https://www.microsoft.com/en-us/store/b/business)\\n        *   [Support](https://support.microsoft.com/en-us)\\n\\n    *   Software Software\\n        *   [Windows Apps](https://apps.microsoft.com/home)\\n        *   [Outlook](https://www.microsoft.com/en-us/microsoft-365/outlook/email-and-calendar-software-microsoft-outlook)\\n        *   [OneDrive](https://www.microsoft.com/en-us/microsoft-365/onedrive/online-cloud-storage)\\n        *   [Microsoft Teams](https://www.microsoft.com/en-us/microsoft-teams/group-chat-software)\\n        *   [OneNote](https://www.microsoft.com/en-us/microsoft-365/onenote/digital-note-taking-app)\\n        *   [Microsoft Edge](https://www.microsoft.com/edge)\\n        *   [Moving from Skype to Teams](https://support.microsoft.com/en-us/office/moving-from-skype-to-microsoft-teams-free-3c0caa26-d9db-4179-bcb3-930ae2c87570?icid=DSM_All_Skype)\\n\\n    *   PCs & Devices PCs & Devices \\n        *   [Computers](https://www.microsoft.com/en-us/store/b/pc?icid=CNavDevicesPC)\\n        *   [Shop Xbox](https://www.microsoft.com/en-us/store/b/xbox?icid=CNavDevicesXbox)\\n        *   [Accessories](https://www.microsoft.com/en-us/store/b/accessories?icid=CNavDevicesAccessories)\\n        *   [VR & mixed reality](https://www.microsoft.com/en-us/store/b/virtualreality?icid=CNavVirtualReality)\\n        *   [Certified Refurbished](https://www.microsoft.com/en-us/store/b/certified-refurbished-products)\\n        *   [Trade-in for cash](https://www.microsoft.com/en-us/store/b/microsoft-trade-in)\\n\\n    *   Entertainment Entertainment\\n        *   [Xbox Game Pass Ultimate](https://www.xbox.com/en-us/games/store/xbox-game-pass-ultimate/cfq7ttc0khs0?icid=CNavAllXboxGamePassUltimate)\\n        *   [PC Game Pass](https://www.xbox.com/en-us/games/store/pc-game-pass/cfq7ttc0kgq8?icid=CNavAllPCGamePass)\\n        *   [Xbox games](https://www.microsoft.com/en-us/store/b/xboxgames?icid=CNavGamesXboxGames)\\n        *   [PC games](https://apps.microsoft.com/games)\\n\\n    *   Business Business\\n        *   [Microsoft AI](https://www.microsoft.com/en-us/ai?icid=DSM_All_AI)\\n        *   [Microsoft Security](https://www.microsoft.com/en-us/security)\\n        *   [Dynamics 365](https://www.microsoft.com/en-us/dynamics-365)\\n        *   [Microsoft 365 for business](https://www.microsoft.com/en-us/microsoft-365/business)\\n        *   [Microsoft Power Platform](https://www.microsoft.com/en-us/power-platform)\\n        *   [Windows 365](https://www.microsoft.com/en-us/windows-365)\\n        *   [Small Business](https://www.microsoft.com/en-us/store/b/business?icid=CNavBusinessStore)\\n\\n    *   Developer & IT Developer & IT \\n        *   [Azure](https://azure.microsoft.com/en-us/)\\n        *   [Microsoft Developer](https://developer.microsoft.com/en-us/)\\n        *   [Microsoft Learn](https://learn.microsoft.com/)\\n        *   [Support for AI marketplace apps](https://www.microsoft.com/software-development-companies/offers-benefits/isv-success?icid=DSM_All_SupportAIMarketplace&ocid=cmm3atxvn98)\\n        *   [Microsoft Tech Community](https://techcommunity.microsoft.com/)\\n        *   [Microsoft Marketplace](https://marketplace.microsoft.com/?icid=DSM_All_Marketplace&ocid=cmm3atxvn98)\\n        *   [Marketplace Rewards](https://www.microsoft.com/software-development-companies/offers-benefits/marketplace-rewards?icid=DSM_All_MarketplaceRewards&ocid=cmm3atxvn98)\\n        *   [Visual Studio](https://visualstudio.microsoft.com/)\\n\\n    *   Other Other\\n        *   [Microsoft Rewards](https://www.microsoft.com/rewards)\\n        *   [Free downloads & security](https://www.microsoft.com/en-us/download)\\n        *   [Education](https://www.microsoft.com/en-us/education)\\n        *   [Gift cards](https://www.microsoft.com/en-us/store/b/gift-cards?icid=DSM_All_GiftCards)\\n        *   [Licensing](https://www.microsoft.com/licensing/)\\n        *   [Unlocked stories](https://unlocked.microsoft.com/)\\n\\n    *   [View Sitemap](https://www.microsoft.com/en-us/sitemap)\\n\\nSearch Search or ask a question\\n\\n*   No results\\n\\nCancel\\n\\nMicrosoft Fiscal Year 2025 First Quarter Earnings Conference Call\\n\\n_Wednesday, October 30, 2024_\\n\\n Satya Nadella, Chairman and CEO and Amy Hood, EVP & CFO\\n\\nTranscript\\n\\n[![Image 3: icon_word](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/ICON_Word)](https://aka.ms/transcriptfy25q1)\\n\\nMicrosoft FY25 First Quarter Earnings Conference Call\\n=====================================================\\n\\nBrett Iversen, Satya Nadella, Amy Hood\\n\\nWednesday October 30, 2024\\n\\n**BRETT IVERSEN:**\\n\\nGood afternoon and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer, Amy Hood, chief financial officer, Alice Jolla, chief accounting officer, and Keith Dolliver, corporate secretary and deputy general counsel.\\n\\nOn the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today’s call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. We have recast certain prior period amounts to reflect the FY25 changes to the composition of our segments announced in August 2024. Additional details including FY23 and FY24 recast segment revenue, operating income, and product and service level revenue can be found in the financial statements file on the Investor Relations website. More detailed outlook slides will also be available on the Microsoft Investor Relations website when we provide outlook commentary on today’s call.\\n\\nOn this call we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP.They are included as additional clarifying items to aid investors in further understanding the company's first quarter performance in addition to the impact these items and events have on the financial results.\\n\\nAll growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted. We will also provide growth rates in constant currency, when available, as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only.\\n\\nWe will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript, and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website.\\n\\nDuring this call, we will be making forward-looking statements which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the risk factor section of our Form 10-K, Forms 10-Q, and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement.\\n\\nAnd with that, I’ll turn the call over to Satya.\\n\\n**SATYA NADELLA:**\\n\\nThank you, Brett.\\n\\nWe are off to a solid start to our fiscal year, driven by continued strength of the Microsoft Cloud, which surpassed $38.9 billion in revenue, up 22%.\\n\\nAI-driven transformation is changing work, work artifacts, and workflow across every role, function, and business process, helping customers drive new growth and operating leverage.\\n\\nAll-up, our AI business is on track to surpass an annual revenue run rate of $10 billion next quarter, which will make it the fastest business in our history to reach this milestone.\\n\\nNow, I will highlight examples of our progress, starting with infrastructure.\\n\\nAzure took share this quarter.\\n\\nWe are seeing continued growth in cloud migration.\\n\\nAzure Arc now has over 39,000 customers across every industry, including American Tower, CTT, L’Oreal, up more than 80% year-over-year.\\n\\nWe now have datacenters in over 60 regions around the world, and this quarter we announced new cloud and AI infrastructure investments in Brazil, Italy, Mexico, and Sweden, as we expand our capacity in line with long-term demand signals.\\n\\nAt the silicon layer, our new Cobalt 100 VMs are being used by companies like Databricks, Elastic, Siemens, Snowflake, and Synopsys to power their general-purpose workloads at up to 50% better price-performance than previous generations.\\n\\nOn top of this, we are building out our next generation AI infrastructure, innovating across the full stack to optimize our fleet for AI workloads.\\n\\nWe offer the broadest selection of AI accelerators, including our first party accelerator Maia 100, as well as the latest GPUs from AMD and NVIDIA.\\n\\nIn fact, we were the first cloud to bring up NVIDIA’s Blackwell system with GB200-powered AI servers.\\n\\nOur partnership with OpenAI also continues to deliver results.\\n\\nWe have an economic interest in a company that has grown significantly in value.\\n\\nAnd we have built differentiated IP and are driving revenue momentum.\\n\\nMore broadly, with Azure AI, we are building an end-to-end app platform to help customers build their own copilots and agents.\\n\\nAzure OpenAI usage more than doubled over the past six months, as both digital natives like Grammarly and Harvey, as well as established enterprises like Bajaj Finance, Hitachi, KT, and LG, move apps from test to production.\\n\\nGE Aerospace, for example, used Azure OpenAI to build a new digital assistant for all 52,000 of its employees. In just three months, it has been used to conduct over 500,000 internal queries, and process more than 200,000 documents.\\n\\nAnd this quarter, we added support for OpenAI’s newest model family “o1.”\\n\\nWe are also bringing industry-specific models to Azure AI, including a collection of best-in-class multimodal models for medical imaging.\\n\\nAnd, with GitHub Models, we now provide access to our full model catalog directly within the GitHub developer workflow.\\n\\nAzure AI is also increasingly an on-ramp to our data and analytics services.\\n\\nAs developers build new AI apps on Azure, we have seen an acceleration of Azure Cosmos DB and Azure SQL DB Hyperscale usage, as customers like Air India, Novo Nordisk, Telefonica, Toyota Motor North America, and Uniper take advantage of capabilities purpose-built for AI applications.\\n\\nAnd with Microsoft Fabric we provide a single AI-powered platform to help customers like Chanel, EY, KPMG, Swiss Air, and Syndigo unify their data across clouds.\\n\\nWe now have over 16,000 paid Fabric customers, including over 70% of the Fortune 500.\\n\\nNow, on to developers.\\n\\nGitHub Copilot is changing the way the world builds software.\\n\\nCopilot Enterprise customers increased 55% quarter-over-quarter as companies like AMD and Flutter Entertainment tailor Copilot to their own codebase.\\n\\nAnd we are introducing the next phase of AI code generation, making GitHub Copilot agentic across the developer workflow.\\n\\nGitHub Copilot Workspace is a developer environment which leverages agents from start to finish, so developers can go from spec, to plan, to code, all in natural language.\\n\\nCopilot Autofix is an AI agent that helps developers at companies like Asurion and Otto Group fix vulnerabilities in their code over three times faster than it would take them on their own.\\n\\nWe are also continuing to build on GitHub’s open platform ethos by making more models available via GitHub Copilot.\\n\\nAnd we are expanding the reach of GitHub to a new segment of developers, introducing GitHub Spark, which enables anyone to build apps in natural language.\\n\\nAlready, we have brought generative AI to Power Platform to help customers use our low-code/no-code tools to cut costs and development time.\\n\\nTo date, nearly 600,000 organizations have used AI-powered capabilities in Power Platform, up 4X year-over-year.\\n\\nCitizen developers at ZF, for example, build apps simply by describing what they need using natural language.\\n\\nAnd this quarter we introduced new ways for customers to apply AI to streamline complex workflows with Power Automate.\\n\\nNow, on to work.\\n\\nWe launched the next wave of Microsoft 365 Copilot innovation last month, bringing together web, work, and Pages as a new design system for knowledge work.\\n\\nPages is the first new digital artifact for the AI age, and it is designed to help you ideate with AI and collaborate with other people.\\n\\nWe have also made Microsoft 365 Copilot responses 2X faster and improved response quality by nearly 3X.\\n\\nThis innovation is driving accelerated usage, and the number of people who use Microsoft 365 Copilot daily more than doubled quarter-over-quarter.\\n\\nWe are also seeing increased adoption from customers in every industry as they use Microsoft 365 Copilot to drive real business value.\\n\\nVodafone, for example, will roll out Microsoft 365 Copilot to 68,000 employees after a trial showed that on average they saved three hours per person per week. And UBS will deploy 50,000 seats, in our largest FinServ deal to date.\\n\\nAnd we continue to see enterprise customers coming back to buy more seats.\\n\\nAll-up, nearly 70% of the Fortune 500 now use Microsoft 365 Copilot, and customers continue to adopt it at a faster rate than any other new Microsoft 365 suite.\\n\\nCopilot is the UI for AI, and with Microsoft 365 Copilot, Copilot Studio, agents, and now autonomous agents we have built an end-to-end system for AI business transformation.\\n\\nWith Copilot Studio, organizations can build and connect Microsoft 365 Copilot to autonomous agents, which then delegate to Copilot when there is an exception.\\n\\nMore than 100,000 organizations, from Nsure, Standard Bank, and Thomson Reuters, to Virgin Money and Zurich Insurance have used Copilot Studio to date, up over 2X quarter-over-quarter.\\n\\nMore broadly, we are seeing AI drive a fundamental change in the business applications market, as customers shift from legacy apps to AI-first business process.\\n\\nDynamics 365 continues to take share as organizations like Everon, HEINEKEN, and Lexmark choose our apps over other providers.\\n\\nAnd monthly active users of Copilot across our CRM and ERP portfolio increased over 60% quarter-over-quarter.\\n\\nOur Dynamics 365 Contact Center is also winning customers like Currys, Le Creuset, and RXO, as it brings generative AI to every customer engagement channel.\\n\\nAnd just last week, we added 10 out-of-the-box autonomous agents to Dynamics 365 that help customers automatically qualify sales leads, track suppliers, and work hand in hand with service reps to resolve issues.\\n\\nWe are also bringing AI to industry-specific workflows.\\n\\nOne year in, DAX Copilot is now documenting over 1.3 million physician-patient encounters each month at over 500 healthcare organizations like Baptist Medical Group, Baylor Scott & White, Greater Baltimore Medical Center, Novant Health, and Overlake Medical Center.\\n\\nIt is showing faster revenue growth than GitHub Copilot did in its first year.\\n\\nAnd new features extend DAX beyond notes, helping physicians automatically draft referrals, after visit instructions, and diagnostic evidence.\\n\\nOn top of all of this AI innovation, Microsoft Teams usage remains at all-time highs as people use it to streamline all their communications.\\n\\nNearly 75% of our Teams Enterprise customers now buy Premium, Phone, or Rooms.\\n\\nWhen it comes to Windows, our new class of Copilot+ PCs is winning new customers.\\n\\nThey offer best-in-class AI capability, performance, and value.\\n\\nAMD, Intel, and Qualcomm now all support Copilot+ PCs.\\n\\nThis quarter we also introduced new AI experiences only available on Copilot+ PCs, like Click to Do, which places an interactive overlay over your desktop to suggest “next best actions.”\\n\\nAnd, as we approach the end of support for Windows 10 a year from now, we are well positioned to transition our customers to Windows 11, ensuring they benefit from the enhanced features and security improvements we have introduced over the past few years.\\n\\nNow, on to security.\\n\\nWe continue to prioritize security above all else.\\n\\nWith our Secure Future Initiative, we have dedicated the equivalent of 34,000 full-time engineers to address the highest priority security tasks.\\n\\nWe have made significant progress to better protect tenants, identities, networks, and engineering systems, and have created new processes to ensure security is prioritized at every level of the company.\\n\\nAnd we continue to take what we learn and turn it into innovation across our products.\\n\\nSecurity Copilot, for example, is being used by companies in every industry, including Clifford Chance, Intesa Sanpaolo, and Shell, to perform SecOps tasks faster and more accurately.\\n\\nAnd we are helping customers protect their AI deployments too.\\n\\nCustomers have used Defender to discover and secure more than 750,000 GenAI app instances; and used Purview to audit over a billion Copilot interactions to meet their compliance obligations.\\n\\nAnd, all up, we continue to take share across all major categories we serve and are consistently recognized by top analysts as the leader in 20 categories, more than any other vendor.\\n\\nNow, let me turn to our consumer businesses, starting with LinkedIn.\\n\\nMember growth continues to accelerate, with markets like India and Brazil both growing at double digits.\\n\\nWe are also seeing record engagement as we introduce new ways for our more than one billion members to connect, sell services, get hired, and share knowledge.\\n\\nOur investments in rich formats, like video, strengthen our leadership in B2B advertising and amplify the value we deliver to our customers. Weekly immersive video views increased 6x quarter-over-quarter and total video viewership on LinkedIn is up 36% year-over-year.\\n\\nOur AI-powered tools also continue to transform how people sell, learn, and hire.\\n\\nIn sales, new AI features help every team member perform at the level of top sellers and drive more profitable growth.\\n\\nIn learning, just yesterday, we announced updates to our coaching experience, including personalized career development plans.\\n\\nLinkedIn’s first agent, Hiring Assistant, will help hirers find qualified candidates faster by tackling the most time-consuming tasks.\\n\\nAlready, hirers who use AI-assisted messages see a 44% higher acceptance rate compared to those who don’t.\\n\\nAnd, our hiring business continues to take share.\\n\\nNow, on to Search, Advertising and News.\\n\\nWith Copilot, we are taking the first steps towards creating an AI companion for everyone.\\n\\nThe new Copilot experience we introduced earlier this month includes a refreshed design and tone, along with improved speed and fluency across web and mobile.\\n\\nAnd it includes advanced capabilities like Voice and Vision that make it more delightful and useful, and feel more natural. You can both browse and converse with Copilot simultaneously, because Copilot sees what you see.\\n\\nMore broadly, AI is also transforming search, browsers, and digital advertising, and we continue to take share across Bing and Edge.\\n\\nBing ex-TAC revenue growth outpaced the Search market.\\n\\nNow, on to gaming.\\n\\nOne year since we closed our acquisition of Activision Blizzard King, we are focused on building a business positioned for long-term growth, driven by higher-margin content and services.\\n\\nYou already see this transformation in our results, as we diversify the ways that gamers access our content.\\n\\nWe set new records for monthly active users in the quarter, as more players than ever play our games across devices and on the Xbox platform.\\n\\nGame Pass also set a new Q1 record for total revenue and average revenue per subscriber.\\n\\nAnd, as we look ahead, our IP across our studios has never been stronger.\\n\\nLast week’s launch of Black Ops 6 was the biggest Call of Duty release ever, setting a record for day one players, as well as Game Pass subscriber adds on launch day. And unit sales on PlayStation and Steam were also up over 60% year-over-year.\\n\\nThis speaks to our strategy of meeting gamers where they are by enabling them to play more games across the screens they spend their time on.\\n\\nIn closing, we are rapidly innovating to expand our opportunity across our commercial and consumer businesses.\\n\\nIn three weeks time, we will hold our Ignite conference, and I look forward to sharing more then about how we are helping every business function use AI to drive growth in this new era.\\n\\nWith that, let me turn it over to Amy.\\n\\n**AMY HOOD:**\\n\\nThank you, Satya, and good afternoon everyone. This quarter, revenue was $65.6 billion, up 16%, and earnings per share was $3.30, an increase of 10%.\\n\\nWith strong execution by our sales teams and partners, we delivered a solid start to our fiscal year with double-digit top and bottom-line growth. We also saw continued share gains across many of our businesses. In our commercial business, increased demand and growth in long-term commitments to our Microsoft Cloud platform drove our results.\\n\\nCommercial bookings were ahead of expectations and increased 30% and 23% in constant currency. Results were driven by strong execution across our core annuity sales motions and growth in the number of 10-million-dollar-plus contracts for both Azure and Microsoft 365. Additionally, we also saw an increase in the number of 100-million-dollar-plus contracts for Azure.\\n\\nCommercial remaining performance obligation increased 22% and 21% in constant currency to $259 billion. Roughly 40% will be recognized in revenue in the next 12 months, up 17% year-over-year. The remaining portion, recognized beyond the next 12 months, increased 27%. And this quarter, our annuity mix increased to 98%.\\n\\nIn addition to commercial results that were in line with expectations, we also saw some benefit from in-period revenue recognition across Microsoft 365 commercial, Azure, and our on-premises server business.\\n\\nAt a company level, Activision contributed a net impact of approximately 3 points to revenue growth, was a 2 point drag on operating income growth, and had a negative 5 cent impact to earnings per share. A reminder that this net impact includes adjusting for the movement of Activision content from our prior relationship as a third-party partner to first-party and includes $911 million from purchase accounting adjustments, integration, and transaction-related costs.\\n\\nFX did not have a significant impact on our results and was roughly in line with expectations on total company revenue, segment level revenue, COGS, and operating expense growth.\\n\\nMicrosoft Cloud revenue was $38.9 billion and grew 22%, roughly in line with expectations. Microsoft Cloud gross margin percentage decreased 2 points year-over-year to 71%. This was slightly better than expected due to improvement in Azure, although the gross margin percentage decrease year-over-year continues to be driven by scaling our AI infrastructure.\\n\\nCompany gross margin dollars increased 13% and 14% in constant currency and gross margin percentage was 69%, down 2 points year-over-year driven by the lower Microsoft Cloud gross margin noted earlier, as well as the impact from purchase accounting adjustments, integration, and transaction-related costs from the Activision acquisition.\\n\\nOperating expenses increased 12%, lower than expected due to our focus on cost efficiencies and ongoing prioritization work. Operating expense growth included 9 points from the Activision acquisition.\\n\\nAt a total company level, headcount at the end of September was 8% higher than a year ago. Excluding the growth from the Activision acquisition, headcount was 2% higher.\\n\\nOperating income increased 14% and operating margins were 47%, down 1 point year-over-year. Excluding the net impact from the Activision acquisition, operating margins were up 1 point as we continue to drive efficiencies across our businesses as we invest in AI infrastructure and capabilities.\\n\\nNow to our segment results.\\n\\nRevenue from Productivity and Business Processes was $28.3 billion and grew 12% and 13% in constant currency, ahead of expectations driven by better-than-expected results across all businesses.\\n\\nM365 commercial cloud revenue increased 15% and 16% in constant currency with business trends that were as expected. The better-than-expected result was due to a small benefit from the in-period revenue recognition noted earlier. ARPU growth was primarily driven by E5 as well as M365 Copilot. Paid M365 commercial seats grew 8% year-over-year with installed base expansion across all customer segments. Seat growth was driven by our small and medium business and frontline worker offerings. M365 commercial cloud revenue represents nearly 90% of total M365 commercial products and cloud services.\\n\\nM365 commercial products revenue increased 2% and 3% in constant currency, ahead of expectations primarily due to the benefit from in-period revenue recognition noted earlier.\\n\\nM365 consumer products and cloud services revenue increased 5% and 6% in constant currency. M365 consumer cloud revenue increased 6% and 7% in constant currency with continued momentum in M365 consumer subscriptions, which grew 10% to 84.4 million. M365 consumer cloud revenue represents 85% of total M365 consumer products and cloud services.\\n\\nLinkedIn revenue increased 10% and 9% in constant currency, slightly ahead of expectations, with growth across all lines of business.\\n\\nDynamics revenue grew 14%, driven by Dynamics 365 which grew 18% and 19% in constant currency with continued growth across all workloads and continued share gains. As a reminder, Dynamics 365 represents about 90% of total Dynamics revenue.\\n\\nSegment gross margin dollars increased 11% and 12% in constant currency and gross margin percentage decreased slightly year-over-year driven by scaling our AI infrastructure. Operating expenses increased 2% and operating income increased 16%.\\n\\nNext, the Intelligent Cloud segment. Revenue was $24.1 billion, increasing 20% and 21% in constant currency, in line with expectations.\\n\\nAzure and other cloud services revenue grew 33% and 34% in constant currency, with healthy consumption trends that were in line with expectations. The better-than-expected result was due to the small benefit from in-period revenue recognition noted earlier. Azure growth included roughly 12 points from AI services, similar to last quarter. Demand continues to be higher than our available capacity. Non-AI growth trends were also in line with expectations in total and across regions as customers continue to migrate and modernize on the Azure platform. The non-AI point contribution to Azure growth was sequentially lower by approximately 1 point.\\n\\nIn our on-premises server business, revenue decreased 1%. Lower-than-expected transactional purchasing ahead of the Windows Server 2025 launch, as well as lower purchasing of licenses running in multi-cloud environments, was mostly offset by the benefit from in-period revenue recognition noted earlier.\\n\\nEnterprise and partner services revenue decreased 1% and was relatively unchanged in constant currency.\\n\\nSegment gross margin dollars increased 15% and gross margin percentage decreased 3 points year-over-year driven by scaling our AI infrastructure. Operating expenses increased 8% and operating income grew 18%.\\n\\nNow to More Personal Computing. Revenue was $13.2 billion, increasing 17%, with 15 points of net impact from the Activision acquisition. Results were above expectations driven by Gaming and Search.\\n\\nWindows OEM and Devices revenue increased 2% year-over-year as better-than-expected results in Windows OEM due to mix shift to higher monetizing markets was partially offset by the lower-than-expected results in Devices due to execution challenges in the commercial segment.\\n\\nSearch and news advertising revenue ex-TAC increased 18% and 19% in constant currency, ahead of expectations primarily due to continued execution improvement. We saw rate expansion in addition to healthy volume growth in both Edge and Bing.\\n\\nAnd in Gaming, revenue increased 43% and 44% in constant currency, with 43 points of net impact from the Activision acquisition. Results were ahead of expectations driven by stronger-than-expected performance in both first- and third-party content as well as consoles. Xbox content and services revenue increased 61% with 53 points of net impact from the Activision acquisition.\\n\\nSegment gross margin dollars increased 16% and 17% in constant currency, with 12 points of net impact from the Activision acquisition. Gross margin percentage was relatively unchanged year-over-year. Our strong execution on margin improvement in Gaming and Search was offset by sales mix shift to those businesses.\\n\\nOperating expenses increased 49% with 51 points from the Activision acquisition. Operating income decreased 4%.\\n\\nNow back to total company results.\\n\\nCapital expenditures including finance leases were $20 billion, in line with expectations, and cash paid for P, P, and E was $14.9 billion. Roughly half of our cloud and AI related spend continues to be for long-lived assets that will support monetization over the next 15 years and beyond. The remaining cloud and AI spend is primarily for servers, both CPUs and GPUs, to serve customers based on demand signals.\\n\\nCash flow from operations was $34.2 billion, up 12% driven by strong cloud billings and collections, partially offset by higher supplier, employee, and tax payments. Free cash flow was $19.3 billion, down 7% year-over-year, reflecting higher capital expenditures to support our cloud and AI offerings.\\n\\nThis quarter, other income and expense was negative $283 million, significantly more favorable than anticipated due to foreign currency remeasurement and net gains on investments. Our losses on investments accounted for under the equity method were as expected.\\n\\nOur effective tax rate was approximately 19%.\\n\\nAnd finally, we returned $9 billion to shareholders through dividends and share repurchases.\\n\\nNow, moving to our Q2 outlook, which unless specifically noted otherwise, is on a US dollar basis.\\n\\nFirst, FX. With the weaker US dollar and assuming current rates remain stable, we expect FX to increase total revenue and segment level revenue growth by less than one point. We expect FX to have no meaningful impact to COGS or operating expense growth.\\n\\nOur outlook has many of the trends we saw in Q1 continue thru Q2. Customer demand for our differentiated solutions should drive another quarter of strong growth.\\n\\nIn commercial bookings, we expect strong growth on a growing expiry base driven by increased long-term commitments to our platform and strong execution across core annuity sales motions. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, can drive increased quarterly volatility in our bookings growth rate.\\n\\nMicrosoft Cloud gross margin percentage should be roughly 70%, down year-over-year driven by the impact of scaling our AI infrastructure.\\n\\nWe expect capital expenditures to increase on a sequential basis given our cloud and AI demand signals. As I said last quarter, we will stay aligned, and if needed adjust, to the demand signals we see. As a reminder, there can be quarterly spend variability from cloud infrastructure buildouts and the timing of delivery of finance leases.\\n\\nNext to segment guidance, starting with Productivity and Business Processes.\\n\\nWe are the market leader when it comes to knowledge-based copilots and agents in the enterprise space, and we are focused on continuing to gain share across our productivity solutions. Therefore, we expect revenue in Productivity and Business Processes to grow between 10% and 11% in constant currency, or $28.7 to $29 billion.\\n\\nM365 commercial cloud revenue growth should be approximately 14% in constant currency with moderating seat growth across customer segments and ARPU growth thru E5 and M365 Copilot. For H2, we expect revenue growth to remain relatively stable compared to Q2. We continue to see growth in M365 Copilot seats and we expect the related revenue to continue to grow gradually over time.\\n\\nFor M365 commercial products, we expect revenue to decline in the low single digits. As a reminder, M365 commercial products include on-premises components of M365 suites so our quarterly revenue growth can have variability primarily from in-period revenue recognition depending on the mix of contracts.\\n\\nM365 consumer cloud revenue growth should be in the mid-single digits driven by M365 subscriptions.\\n\\nFor LinkedIn, we expect revenue growth of approximately 10% driven by continued growth across all businesses.\\n\\nAnd in Dynamics 365, we expect revenue growth to be in the mid to high teens driven by continued growth across all workloads.\\n\\nNext, Intelligent Cloud. Helping our customers transform and grow with innovative cloud and AI solutions is driving continued growth in Azure. Therefore, we expect revenue in Intelligent Cloud to grow between 18% and 20% in constant currency, or $25.55 to $25.85 billion.\\n\\nRevenue will continue to be driven by Azure which, as a reminder, can have quarterly variability primarily from in-period revenue recognition depending on the mix of contracts.\\n\\nIn Azure, we expect Q2 revenue growth to be 31% to 32% in constant currency driven by strong demand for our portfolio of services. We expect consumption growth to be stable compared to Q1 and we expect to add more sequential dollars to Azure than any other quarter in history. We expect the contribution from AI services to be similar to last quarter given the continued capacity constraints, as well as some capacity that shifted out of Q2. And in H2, we still expect Azure growth to accelerate from H1 as our capital investments create an increase in available AI capacity to serve more of the growing demand.\\n\\nAnd in our on-premises server business, we expect revenue to decline in the low to mid-single digits on a prior year comparable that benefited from purchasing ahead of Windows Server 2012 end of support.\\n\\nAnd in Enterprise and partner services, we expect revenue growth to be in the low single digits.\\n\\nNow to More Personal Computing. We continue to make decisions to prioritize strategic higher margin opportunities within each of our consumer businesses. Our outlook reflects the improvement in gross and operating margins from this prioritization work across Gaming, Search, and Devices. We expect revenue in More Personal Computing to be $13.85 to $14.25 billion.\\n\\nWindows OEM and Devices revenue should decline in the low to mid-single digits. We expect Windows OEM revenue growth, in line with the PC market, to be more than offset by a decline in Devices as the trends from Q1 continue.\\n\\nSearch and news advertising ex-TAC revenue growth should be in the high teens with continued growth in both volume and revenue per search. This will be higher than overall Search and news advertising revenue growth, which we expect to be in the high single digits.\\n\\nAnd in Gaming, we expect revenue to decline in the high single digits due to hardware. We expect Xbox content and services revenue growth to be relatively flat. We’re excited about last week’s launch of Call of Duty where we saw the most Game Pass subscriber adds we’ve ever seen on a launch day. There are two things about the launch that are different than the Call of Duty launch a year ago where revenue was mostly recognized in the quarter of purchase. First, the game is available on Game Pass so for players who play through Game Pass, the subscription revenue is recognized over time. Second, the game requires an online connection to play so even for players who purchase the standalone game, revenue recognition will also occur ratably over time.\\n\\nNow back to company guidance.\\n\\nWe expect COGS to grow between 11% and 13% in constant currency or to be between $21.9 to $22.1 billion and operating expense to grow approximately 7% in constant currency or to be between $16.4 and $16.5 billion. This should result in another quarter of operating margin expansion.\\n\\nOther income and expense is expected to be roughly negative $1.5 billion primarily driven by our share of the expected loss from OpenAI which is accounted for under the equity method. As a reminder, we do not recognize mark-to-market gains or losses on equity method investments. As you heard from Satya, our strategic partnership and investment in OpenAI has been pivotal in building and scaling our AI business, and positioning us as the leader in the AI platform wave.\\n\\nAnd lastly, we expect our Q2 effective tax rate to be approximately 19%.\\n\\nIn closing, we remain focused on strategically investing in the long-term opportunities that we believe drive shareholder value. Monetization from these investments continues to grow and we’re excited that only two and half years in, our AI business is on track to surpass $10 billion of annual revenue run rate in Q2. This will be the fastest business in our history to reach this milestone. We are committed to growing this leadership position across our entire Microsoft Cloud while maintaining our disciplined focus on cost management and prioritization across every team.\\n\\nWith that, let’s go to Q&A, Brett.\\n\\n**BRETT IVERSEN:**Thanks, Amy. We’ll now move over to Q&A. Out of respect for others of the call, we request the participants please only ask one question.\\n\\nOperator, can you please repeat your instructions?\\n\\n(Operator Direction.)\\n\\n**KEITH WEISS, Morgan Stanley:**Excellent. Thank you, guys, for taking the question, and congratulations on a really solid quarter.\\n\\nSatya, the expansion of capabilities, the speed of innovation, the magnitude of the opportunities ahead for generative AI makes this the most exciting period for software I’ve seen in my 25 years of covering this space. And based upon this call, it seems like you share that excitement.\\n\\nBut in my investor conversation, that excitement also feeds two related questions, and they both have to do with constraints. And the first is what are the internal constraints or guardrails that Microsoft has when it comes to investing behind these innovations, particularly in relation to the funding of a future generations of foundational models, where people are talking about price tags growing to tens of billions or even $100 billion plus.\\n\\nAnd then on the other side of the spectrum, what are the external constraints that Microsoft sees in building out this capacity to meet the demand and capture the opportunity, particularly constraints in your ability to power all these new data centers being built out and power it in an environmentally sustainable fashion? I’d love to get the Microsoft perspective on both those questions.\\n\\n**SATYA NADELLA:**Thank you, Keith, for those questions. I think on the first point, ultimately when you think about, let’s say, a capital outlay for training, because that’s essentially what you’re asking, it is going to be very limited by your monetization of inference in a given generation. Just like in the past, we would allocate capital to build out cloud based on the demand signal we were seeing, and then we would then project the demand, and that’s what we would build for.\\n\\nYou can think of training essentially as that, which is you’re building the next generation model so that then, you have a more capable model that then drives more inference demand. Ultimately, even with all the scaling laws and what have you, I think you ultimately will normalize to having a pace.\\n\\nIn fact, I think the best way to think about even, is given the Moore’s Law effectively is working on the silicon and system side, it’s just not compute, it’s efficiencies in compute, it’s data as well as algorithms, you will want to keep on that curve, which is you really want to refresh your fleet with the Moore’s Law every year and then effectively depreciate it over the period of the life cycle of it. And then the inference demand ultimately will govern how much we invest in training, because that’s, I think, at the end of the day, you’re all subject to ultimately demand.\\n\\nThe second piece of the external constraints, we have run into, obviously, lots of external constraints because this demand all showed up pretty fast. I mean, if you think about even the most hit products of this generation, all are in our cloud, whether it’s ChatGPT, whether it’s Copilot, whether it’s GitHub Copilot or even DAX Copilot. I mean, pick the top 4 or 5 products of this generation, they’re all in and around our ecosystem.\\n\\nAnd so, therefore, we ran into a set of constraints which are everything because DCs don’t get built overnight. There is DCs. There is power. And so, that’s been the short-term constraint. Even in Q2, for example, some of the demand issues we have, or rather our ability to fulfill demand is because of, in fact, external third-party stuff that we leased moving up. That’s the constraints we have.\\n\\nBut in the long run, we do need effectively power, and we need DCs. And some of these things are more long lead, but I feel pretty good that going into the second half of even this fiscal year, that some of that supply demand will match up.\\n\\n**KEITH WEISS:**Excellent. Thank you, guys.\\n\\n**BRETT IVERSEN:**Thanks, Keith. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**BRENT THILL, Jefferies:**Thanks. Amy, good to hear the acceleration in the back half for Azure. I guess many are asking 34% growth in Q1 falling to low 30s, I know the comp is a couple of points harder, but is there anything else you’re contemplating in that guide for Q2 to see that deceleration other than a tougher comp? Thank you.\\n\\n**AMY HOOD:**Thanks, Brent. Maybe, this is a great question, because I can reiterate some of the points I made and tie them together a little bit.\\n\\nIn Q1, the 34 in CC, as we talked about, that upside versus the 33 that we had guided to was primarily due to some revenue recognition benefits. And so, I think about that on a pure consumption basis and AI as being 33. And you think about a point or two of decel that we guided to and the majority of that is due to, unfortunately, some supply push outs that I mentioned, and then Satya reiterated, in terms of AI supply coming online that we counted on.\\n\\nThe underlying consumption growth is stable Q1 to Q2. And so, to your question on some ins and outs, it is certainly some ins and outs. I do, as you heard, have confidence as we get a good influx of supply across the second half of the year, particularly on the AI side, that we’ll be better able to do some supply demand matching.\\n\\nAnd hence, while we’re talking about acceleration in the back half, I’ll also take the opportunity to say when you see usage in AI workloads, we always intend to think about that as just a GPU exercise. The importance of having GPUs and CPUs be able to run these workloads is also important. That’s a piece of the acceleration H2 as well.\\n\\n**BRETT IVERSEN:**Thanks, Brent. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**MARK MOERDLER, Bernstein:**Thank you very much for taking my question, and congratulations on the quarter. The question every investor obviously asks is the question on the CapEx growth and the CapEx spend. Obviously, half of that’s facilities and equivalent that have a longer life, but the other half is the rest of the components.\\n\\nCan you give any color on how you think of that growth? Does it return to the traditional approach, where basically CapEx is going to grow in line with slightly slower than cloud revenue? And if so, any sense of the timing? Do we do we have enough facilities online by some time next year, etcetera? Any color would be appreciated.\\n\\n**AMY HOOD:**Thanks, Mark. I think in some ways, it’s helpful to go back to the cloud transitions that we worked on over a decade ago, I think, in the early stages. And what you did see and you’ll see us do in the same time is you have to build to meet demand. Unlike the cloud transition, we’re doing it on a global basis in parallel, as opposed to sequential, given the nature of the demand.\\n\\nAnd then as long as we continue to see that demand grow, you’re right, the growth in CapEx will slow and the revenue growth will increase. And those two things, to your point, get closer and closer together over time. The pace of that entirely depends really on the pace of adoption. And to Satya’s point, some of that spend goes toward building the next training infrastructure, so you won’t see all of it in COGS. Some of it goes to OpEx when you’re spending it on training. But in general, that’s a healthy way to think about the balance as it over time, those do and should, like the last cycle, get closer together.\\n\\n**MARK MOERDLER** Thank you very much. That’s very helpful.\\n\\n**BRETT IVERSEN:**Thanks, Mark. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**KARL KEIRSTEAD, UBS:**Okay, great. Thank you. I’m actually not going out to a question about the numbers, but Satya and Amy, I’d love to ask a question about OpenAI.\\n\\nSince the print three months ago, we investors have been hit with a torrent of media stories about OpenAI and Microsoft. And I’d love to give Microsoft an opportunity to frame the relationship. It seems to me it’s critically important, but we have been, I think, everyone on the line, picking up signals that perhaps Microsoft wants to diversify somewhat at the model layer and offer customers choice. Satya, I’d love to get your framing of the relationship.\\n\\nAnd then in terms of the numbers, maybe this is a little bit more for you, Amy, but how does Microsoft manage the demands on CapEx from helping OpenAI with its scaling ambitions? And how do you manage the impact on other income that you just gave us some color on? Thank you so much.\\n\\n**SATYA NADELLA:**Sure. Thanks, Karl. I’d say first, the partnership for both sides, that’s OpenAI and Microsoft, has been super beneficial. After all, we effectively sponsored what is one of the most, highest valued private companies today when we invested in them, and really took a bet on them and their innovation four or five years ago. And that has led to great success for Microsoft. That’s led to great success for OpenAI. And we continue to build on it.\\n\\nWe serve them with world-class infrastructure on which they do their innovation in terms of models, on top of which we innovate on both the model layer with some of the post-training stuff we do, as well as some of the small models we build, and then, of course, all of the product innovation. One of the things that my own conviction of OpenAI and what they were doing came about when I started seeing something like GitHub Copilot as a product get built or DAX Copilot get built or M365 Copilot get built, we have a fantastic portfolio of innovation that we build on top of that.\\n\\nAnd at the same, also, I would say we are investors. We feel very, very good about our investment stake in OpenAI. And so, our focus and we’re always in constant dialogue with them. In a partnership like this, when both sides have achieved mutual success at the pace at which we’ve achieved it, that means we need to push each other to do more to capture the moment. And that’s what we plan to do, and we intend to keep building on it.\\n\\n**AMY HOOD:**And maybe to your other two questions, Karl, listen, I’m thrilled with their success and need for supply from Azure and infrastructure and really, what it’s meant in terms of being able to also serve other customers for us. It’s important that we continue to invest capital to meet not only their demand signal and needs for compute, but also from our broader customers. That’s partially why you’ve seen us committing the amounts of capital we’ve seen over the past few quarters, is our commitment to both grow together and for us to continue to grow the Azure platform for customers beyond them.\\n\\nAnd so, I don’t really think of it as how do you balance it? It’s just we have customers who have needs and real use cases and delivering value today. And if we can’t meet that, we need to work to meet it. And that means working harder and faster to make sure we do that, which is what the team is committed to do.\\n\\nThe second piece of your question, I think, was on the impact to other income. And not to get to accounting heavy on the earnings phone call, but I would say just a reminder, this is under the equity method, which means we just take our percentage of losses every quarter. And those losses, of course, are capped by the amount of investment we make in total, which we did talk about in Q this quarter as being $13 billion.\\n\\nAnd so, over time, that’s just the constraint. And it’s a bit of a mechanical entry. And so, I don’t really think about managing that. That’s the investment and acceleration that OpenAI is making in themselves, and we take a percentage of that.\\n\\n**KARL KEIRSTEAD** Got it. Okay, very helpful. Thank you both.\\n\\n**BRETT IVERSEN:**Thanks, Karl. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**KASH RANGAN, Goldman Sachs:**Hi, thank you very much. Satya, when you talked about the investment cycle, these models are getting bigger and more expensive, but you also pointed out to how in the inference phase, we’re likely to get paid. How does that cycle look like an inference from Microsoft? Where are the products and the applications that will show up on the Microsoft P&L as a result of the inference phase of AI kicking in? Thank you very much.\\n\\n**SATYA NADELLA:**Thanks, Kash. I mean, the good news for us is that we’re not waiting for that inference to show up. If you think about the point we even made, that this is going to be the fastest growth to $10 billion of any business in our history, it’s all inference.\\n\\nOne of the things that may not be as evident is that we are not actually selling raw GPUs for other people to train. In fact, that’s a business we turn away, because we have so much demand on inference that we are not taking what I would – in fact, there’s a huge adverse selection problem today where people, it’s just a bunch of tech companies still using VC money to buy a bunch of GPUs. We really are not even participating in most of that, because we are literally going to the real demand, which is in the enterprise space, or our own products like GitHub Copilot or M365 Copilot.\\n\\nI feel the quality of our revenue is also pretty superior in that context. And that’s what gives us even the conviction, to even Amy’s answers previously about our capital spend, is if this was just all about a bunch of people training large models and that was all we got, then that would be, ultimately still waiting, to your point, for someone to actually have demand, which is real. And in our case, the good news here is we have a diversified portfolio. We’re seeing real demand across all of that portfolio.\\n\\n**AMY HOOD:**And Kash, maybe just to add a little bit to what Satya is saying, I think a part of his two answers is that what you’re seeing is this number we’re talking about, the $10 billion across inference and our apps is already what that momentum, and that investment, and that progress and that revenue is what builds the next cycle of training. And so, it’s that circle as opposed to, oh, we’re doing training now and then inference. Much of the training investments that fueled this revenue growth came before, and we already funded that work. And so, that’s an important point.\\n\\n**KASH RANGAN:**Got it. And that’s to your point that you invest now and you can get the growth later, even if you slow down the CapEx. That’s what you’re trying to tell us.\\n\\n**AMY HOOD:**That’s the cycle that is important to understand.\\n\\n**KASH RANGAN:**Got it. Thank you so much.\\n\\n**BRETT IVERSEN:**Thanks, Kash. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**MARK MURPHY, JP Morgan:**Thank you very much. I’m wondering if you can shed any more light just on the nature of the supply limitations that you’re mentioning, that are impacting Azure and Q2, where that impact might be incrementally, just a touch more than we expected. Is it more the GPU supply? Is there some element of power cooling or the ability to wire up the networks?\\n\\nAnd, Amy, should we infer that the supply is constraining Azure growth by roughly a couple of few points in Q2, or am I overestimating that?\\n\\n**AMY HOOD:**Maybe to answer both those questions, Mark, very directly, I wouldn’t think about it component logic in my Q2 answer. The supply push out, as Satya said, with third parties that are delivering later than we had expected. That gets pushed mainly into the second half of the year and in general, Q3. That’s third parties where we have tended to buy supply inclusive of kits. It’s complete end-to-end, third-party deliveries.\\n\\nIn terms of the impact, as I was saying, when you think about having flat consumption Q1 to Q2, there really are only two things that impact that difference. And one was the help we got in Q1 from the revenue and revenue in accounting help. And then Q2 has been the supply push out.\\n\\n**MARK MURPHY:**Thank you.\\n\\n**BRETT IVERSEN:**Thanks, Mark. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**RAIMO LENSCHOW, Barclays:**Perfect. Thank you. If you talk about the market at the moment, because you were first with Copilot, you had identified along with Copilot, and now we’re talking agents.\\n\\nSatya, how do you think about that? To me, it looks like an evolution that we’re discovering how to productize AI better, etcetera. How do you think about that journey between Copilot agents and maybe what’s coming next? Thank you.\\n\\n**SATYA NADELLA:**Sure. The system we have built is Copilot, Copilot Studio, agents and autonomous agents. You should think of that as the spectrum of things. Ultimately, the way we think about how this all comes together is you need humans to be able to interface with AI. The UI layer for AI is Copilot. You can then use the Copilot Studio to extend Copilot. For example, you want to connect it to your CRM system, to your Office system, to your HR system. You do that through Copilot Studio by building agents, effectively.\\n\\nYou also build autonomous agents, so you can use even – that’s the announcement we made a couple of weeks ago, is you can even use Copilot Studio to build autonomous agents. Now, these autonomous agents are working independently, but from time to time, they need to raise an exception. Autonomous agents are not fully autonomous because at some point, they need to either notify someone or have someone input something. And when they need to do that, they need a UI layer. And that’s where, again, it’s Copilot.\\n\\nCopilot, Copilot agents, built in Copilot Studio, autonomous agents built in Copilot Studio, that’s the full system, we think, that comes together. And we feel very, very good about the positioning.\\n\\nAnd then, of course, we are taking the underlying system services across that entire stack that I just talked about and are making it available in Azure. You have the raw infrastructure if you want it. You have the model layer independent of it. You have the AI app server in Azure AI. Everything is also a building block service in Azure for you to be able to build. In fact, if you want to build everything that we have built in the Copilot Stack, you can build it yourself using the AI platform. That’s in simple terms, our strategy, and that’s how it all comes together.\\n\\n**RAIMO LENSCHOW:**Okay, perfect. Very clear.\\n\\n**BRETT IVERSEN:**Thanks, Raimo. Operator, we have time for one last question.\\n\\n(Operator Direction.)\\n\\n**RISHI JALURIA, RBC:**Oh, wonderful. Thanks. Hi, Satya. Hi, Amy. I appreciate the question. I want to go and think a little bit about Copilot, how we should be thinking about numbers here with the recategorization. It seems like that was maybe softer in the past than expected, but maybe with the numbers this quarter starting to pick up.\\n\\nCan you maybe walk us through what you’re seeing on that, and maybe more importantly, how we should be thinking about your overall AI strategy on consumer versus enterprise, especially now with Mustafa in the fold. Thanks so much.\\n\\n**SATYA NADELLA:**Yeah. On the first part, Rishi, to your question, I think we feel very, very good about the momentum we have in the Commercial Copilot. As I said in my remarks, and Amy talked about, this is the fastest growth of a new suite in M365. If I compare it to what we saw even back, way back in E3 or E5, or the transition from O to M, this is really much faster. It’s the numbers of penetration of the Fortune 500 and then the fact that they’re coming back for more seats and what have you. It’s very strong in that context.\\n\\nThe other thing I’ll also mention is that we want this to be something that is systemic, because people need to be able to put the security controls. Then they need to deploy. Then there’s skilling and then there’s change management. This is not like you’re just – it’s not a tool.\\n\\nWhen I talk about Copilot, Copilot Studio, agents, it’s really as much about a new way to work. And sometimes I describe it as what happened throughout the ‘90s with PC penetration. After all, if you take a business process like forecasting, what was it like pre-email and Excel and post-email and Excel. That’s the type of change that you see with Copilot. But overall we feel great about the rate of progress and the penetration.\\n\\nAnd then on the consumer side, look, for us, the exciting part here is to be able to use the same investment we are making in the commercial, where we have structural strength, and then be on the offense. One of the things that I think I hope you all catch in our earnings is ex-TAC our revenue, when it comes to what we describe as search, news and ads, is growing faster than market.\\n\\nIt’s fantastic to see that. And so, that’s what consumer business, which in Microsoft’s large scope, it’s even a $10+ billion business sometimes goes missing. But in our case, it is actually a fantastic growth business that’s growing faster than market.\\n\\nWe feel good about how we will use AI in LinkedIn. In fact, LinkedIn is a consumer business, as you know. You saw even today, this week, they announced some new capabilities for both consumers, and in their case, even recruiting. We think that AI, the same investment gets monetized even through LinkedIn’s innovation.\\n\\nAnd Gaming, of course, is another place where you’ll will see some of these things apply, and Windows. The place where I think I’m excited about is Copilot+ PCs. For us, it’s not about having a disconnected edge. It’s about having hybrid AI where the rebirth of the PC as the edge of AI is going to be one of the most exciting things for developers.\\n\\nWe feel well positioned, quite frankly with the same investments. That’s the thing. We’re not a conglomerate here. We are one company. That means we invest once, and then we have all these categories that benefit from that. And that’s the theory of the firm here for us. And so, we feel good about all of that coming together.\\n\\n**AMY HOOD:**And maybe just to add one piece, because I think, Rishi, now that I’m listening and thinking through the question, it feels like you’re wondering, why am I not seeing the Copilot if you’ve made all this progress and the results. And the answer is you already are.\\n\\nIn that M365 Commercial number. we’ve seen that seat growth, but those seats that we’re adding, the majority of them are driven by frontline worker and small businesses. Those have a lower RPU point. And so, it masks some of the RPU that we’re already seeing, not just from E5, which continues to contribute, but also this quarter, additional impact from Copilot. As we go forward, that is where you’re going to see the impact will be in RPU in M365 Commercial. And as Satya said, I think you’ll see the impact of Copilot engagement, frankly, across the same exact number.\\n\\n**RISHI JALURIA:**Wonderful. Thank you.\\n\\n**BRETT IVERSEN:**Thanks, Rishi. That wraps up the Q&A portion of today’s earnings call. Thank you for joining us today, and we look forward to speaking with all of you again soon.\\n\\n**AMY HOOD:**Thanks.\\n\\n(Operator Direction.)\\n\\nEND\\n\\nMicrosoft Corp (MSFT)\\n---------------------\\n\\n[![Image 4: ar2025](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/AR_2025)](https://www.microsoft.com/investor/reports/ar25/index.html)\\n###### 2025 ANNUAL REPORT\\n\\n[VIEW ONLINE](https://www.microsoft.com/investor/reports/ar25/index.html)\\n\\n[DOWNLOAD NOW](https://www.microsoft.com/investor/reports/ar25/download-center/index.html)\\n\\n Follow us \\n\\n*   [![Image 5: Facebook](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/Icon_Facebook_2x-1?scl=1)](https://www.facebook.com/Microsoft)\\n*   [![Image 6: X](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/Accessibility_Icon_X_40x40_v1?scl=1)](https://x.com/Microsoft?mx=2)\\n*   [![Image 7: LinkedIn](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/LinkedIn_64x64?scl=1)](https://www.linkedin.com/company/microsoft)\\n*   [![Image 8: youtube](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/youtube-flat-64x64?scl=1)](https://www.youtube.com/microsoft)\\n\\n Share this page \\n\\n*   [![Image 9: Facebook](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/Icon_Facebook_2x-1?scl=1)](http://www.facebook.com/sharer.php?u=https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1)\\n*   [![Image 10: LinkedIn](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/LinkedIn_64x64?scl=1)](http://www.linkedin.com/shareArticle?url=https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1)\\n*   [![Image 11: Email](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/email-8?scl=1)](mailto:?subject=Microsoft%20Investor%20Relations%20%20Link&body=Here%20is%20some%20information%20from%20the%20Microsoft%20Investor%20Relations%20website%20that%20I%20thought%20you%27d%20be%20interested%20in:%20%0A%0Ahttps://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1)\\n\\nWhat's new\\n\\n*   [Surface Pro](https://www.microsoft.com/surface/devices/surface-pro)\\n*   [Surface Laptop](https://www.microsoft.com/surface/devices/surface-laptop)\\n*   [Surface Laptop Studio 2](https://www.microsoft.com/en-us/d/Surface-Laptop-Studio-2/8rqr54krf1dz)\\n*   [Copilot for organizations](https://www.microsoft.com/en-us/microsoft-copilot/organizations?icid=DSM_Footer_CopilotOrganizations)\\n*   [Copilot for personal use](https://www.microsoft.com/en-us/microsoft-copilot/for-individuals?form=MY02PT&OCID=GE_web_Copilot_Free_868g3t5nj)\\n*   [AI in Windows](https://www.microsoft.com/en-us/windows/ai-features?icid=DSM_Footer_WhatsNew_AIinWindows)\\n*   [Explore Microsoft products](https://www.microsoft.com/en-us/microsoft-products-and-apps)\\n*   [Windows 11 apps](https://www.microsoft.com/en-us/windows/apps-for-windows?icid=DSM_Footer_WhatsNew_Windows11apps)\\n\\nMicrosoft Store\\n\\n*   [Account profile](https://account.microsoft.com/)\\n*   [Download Center](https://www.microsoft.com/en-us/download)\\n*   [Microsoft Store support](https://go.microsoft.com/fwlink/?linkid=2139749)\\n*   [Returns](https://www.microsoft.com/en-us/store/b/returns)\\n*   [Order tracking](https://www.microsoft.com/en-us/store/b/order-tracking)\\n*   [Certified Refurbished](https://www.microsoft.com/en-us/store/b/certified-refurbished-products)\\n*   [Microsoft Store Promise](https://www.microsoft.com/en-us/store/b/why-microsoft-store?icid=footer_why-msft-store_7102020)\\n*   [Flexible Payments](https://www.microsoft.com/en-us/store/b/payment-financing-options?icid=footer_financing_vcc)\\n\\nEducation\\n\\n*   [Microsoft in education](https://www.microsoft.com/en-us/education)\\n*   [Devices for education](https://www.microsoft.com/en-us/education/devices/overview)\\n*   [Microsoft Teams for Education](https://www.microsoft.com/en-us/education/products/teams)\\n*   [Microsoft 365 Education](https://www.microsoft.com/en-us/education/products/microsoft-365)\\n*   [How to buy for your school](https://www.microsoft.com/education/how-to-buy)\\n*   [Educator training and development](https://education.microsoft.com/)\\n*   [Deals for students and parents](https://www.microsoft.com/en-us/store/b/education)\\n*   [AI for education](https://www.microsoft.com/en-us/education/ai-in-education)\\n\\nBusiness\\n\\n*   [Microsoft AI](https://www.microsoft.com/en-us/ai?icid=DSM_Footer_AI)\\n*   [Microsoft Security](https://www.microsoft.com/en-us/security)\\n*   [Dynamics 365](https://www.microsoft.com/en-us/dynamics-365)\\n*   [Microsoft 365](https://www.microsoft.com/en-us/microsoft-365/business)\\n*   [Microsoft Power Platform](https://www.microsoft.com/en-us/power-platform)\\n*   [Microsoft Teams](https://www.microsoft.com/en-us/microsoft-teams/group-chat-software)\\n*   [Microsoft 365 Copilot](https://www.microsoft.com/en-us/microsoft-365-copilot?icid=DSM_Footer_Microsoft365Copilot)\\n*   [Small Business](https://www.microsoft.com/en-us/store/b/business?icid=CNavBusinessStore)\\n\\nDeveloper & IT\\n\\n*   [Azure](https://azure.microsoft.com/en-us/)\\n*   [Microsoft Developer](https://developer.microsoft.com/en-us/)\\n*   [Microsoft Learn](https://learn.microsoft.com/)\\n*   [Support for AI marketplace apps](https://www.microsoft.com/software-development-companies/offers-benefits/isv-success?icid=DSM_Footer_SupportAIMarketplace&ocid=cmm3atxvn98)\\n*   [Microsoft Tech Community](https://techcommunity.microsoft.com/)\\n*   [Microsoft Marketplace](https://marketplace.microsoft.com/?icid=DSM_Footer_Marketplace&ocid=cmm3atxvn98)\\n*   [Marketplace Rewards](https://www.microsoft.com/software-development-companies/offers-benefits/marketplace-rewards?icid=DSM_Footer_MarketplaceRewards&ocid=cmm3atxvn98)\\n*   [Visual Studio](https://visualstudio.microsoft.com/)\\n\\nCompany\\n\\n*   [Careers](https://careers.microsoft.com/)\\n*   [About Microsoft](https://www.microsoft.com/about)\\n*   [Company news](https://news.microsoft.com/source/?icid=DSM_Footer_Company_CompanyNews)\\n*   [Privacy at Microsoft](https://www.microsoft.com/en-us/privacy?icid=DSM_Footer_Company_Privacy)\\n*   [Investors](https://www.microsoft.com/investor/default.aspx)\\n*   [Diversity and inclusion](https://www.microsoft.com/en-us/diversity/default?icid=DSM_Footer_Company_Diversity)\\n*   [Accessibility](https://www.microsoft.com/en-us/accessibility)\\n*   [Sustainability](https://www.microsoft.com/en-us/sustainability/)\\n\\n[English (United States)](http://www.microsoft.com/en-us/locale.aspx)[Your Privacy Choices](https://aka.ms/yourcaliforniaprivacychoices)[Consumer Health Privacy](https://go.microsoft.com/fwlink/?linkid=2259814)\\n*   [Sitemap](https://www.microsoft.com/en-us/sitemap1.aspx)\\n*   [Contact Microsoft](https://support.microsoft.com/contactus)\\n*   [Privacy](https://go.microsoft.com/fwlink/?LinkId=521839)\\n*   [Manage cookies](https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1#)\\n*   [Terms of use](https://go.microsoft.com/fwlink/?LinkID=206977)\\n*   [Trademarks](https://go.microsoft.com/fwlink/?linkid=2196228)\\n*   [Safety & eco](https://go.microsoft.com/fwlink/?linkid=2196227)\\n*   [Recycling](https://www.microsoft.com/en-us/legal/compliance/recycling)\\n*   [About our ads](https://choice.microsoft.com/)\\n*   © Microsoft 2026\"},\n",
              " {'title': 'FY25 Q1 - Performance - Investor Relations',\n",
              "  'url': 'https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance',\n",
              "  'content': 'This is the Trace Id: 5c0e1f1ec4cd70761caa4d17aa386175   \\n\\nMicrosoft \\n\\nInvestor Relations\\n\\nInvestor Relations\\n\\n# Earnings Release FY25 Q1\\n\\n## Performance\\n\\nRevenue increased $9.1 billion or 16% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure. Productivity and Business Processes revenue increased driven by Microsoft 365 Commercial cloud. More Personal Computing revenue increased driven by Gaming.\\n\\nCost of revenue increased $3.8 billion or 23% driven by growth in Microsoft Cloud and Gaming.\\n\\nGross margin increased $5.3 billion or 13% driven by growth across each of our segments.\\n\\n•  Gross margin percentage decreased driven by Intelligent Cloud. [...] •  Microsoft Cloud gross margin percentage decreased to 71% driven by scaling our AI infrastructure.\\n\\nOperating expenses increased $1.6 billion or 12% driven by Gaming, with 9 points of growth from the Activision Blizzard acquisition, and investments in cloud engineering.\\n\\nOperating income increased $3.7 billion or 14% driven by growth in Productivity and Business Processes and Intelligent Cloud.',\n",
              "  'score': 0.9195344,\n",
              "  'raw_content': ' This is the Trace Id: 5c0e1f1ec4cd70761caa4d17aa386175   \\n\\n[Microsoft](https://www.microsoft.com) \\n\\nInvestor Relations\\n\\n[Investor Relations](/en-us/Investor/default)\\n\\n# Earnings Release FY25 Q1\\n\\n## Performance\\n\\nRevenue increased $9.1 billion or 16% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure. Productivity and Business Processes revenue increased driven by Microsoft 365 Commercial cloud. More Personal Computing revenue increased driven by Gaming.\\n\\nCost of revenue increased $3.8 billion or 23% driven by growth in Microsoft Cloud and Gaming.\\n\\nGross margin increased $5.3 billion or 13% driven by growth across each of our segments.\\n\\n•  Gross margin percentage decreased driven by Intelligent Cloud.\\n\\n•  Microsoft Cloud gross margin percentage decreased to 71% driven by scaling our AI infrastructure.\\n\\nOperating expenses increased $1.6 billion or 12% driven by Gaming, with 9 points of growth from the Activision Blizzard acquisition, and investments in cloud engineering.\\n\\nOperating income increased $3.7 billion or 14% driven by growth in Productivity and Business Processes and Intelligent Cloud.\\n\\n*IMPORTANT NOTICE TO USERS (summary only,  [click here](https://www.microsoft.com/en-us/Investor/long-disclaimer.html)  for full text of notice)* All information is unaudited unless otherwise noted or accompanied by an audit opinion and is subject to the more comprehensive information contained in our SEC reports and filings. We do not endorse third-party information. All information speaks as of the last fiscal quarter or year for which we have filed a Form 10-K or 10-Q, or for historical information the date or period expressly indicated in or with such information. We undertake no duty to update the information. Forward-looking statements are subject to risks and uncertainties described in our  [Forms 10-Q and 10-K.](https://www.microsoft.com/en-us/Investor/sec-filings.aspx)\\n\\n### Download Earnings Related Files\\n\\nInformation contained in these documents is current as of the earnings date, and not restated for new accounting standards\\n\\n- Earnings Call Slides\\n- Earnings Call Transcript\\n- Financial Statements\\n- Outlook\\n- Press Release\\n- 10Q\\n- FY25Q1 Product Release List\\n ASSET PACKAGE\\n\\n#### Earnings Release Pages\\n\\n* [Metrics](/en-us/investor/earnings/fy-2025-q1/metrics)\\n\\n* [Performance](/en-us/investor/earnings/fy-2025-q1/performance)\\n\\n* [Press Release & Webcast](/en-us/investor/earnings/fy-2025-q1/press-release-webcast)\\n\\n* [Financial Statements](/en-us/investor/earnings/fy-2025-q1/income-statements)\\n\\n* [Segment Results](/en-us/investor/earnings/fy-2025-q1/productivity-and-business-processes-performance)\\n\\n* [Customer & Partner Highlights](https://aka.ms/FY25Q1Blog)\\n\\n#### Related Information\\n\\n* [Webcast](/en-us/investor/events/fy-2025/earnings-fy-2025-q1)\\n\\n* [SEC Filings](/en-us/investor/sec-filings)\\n\\n* [XBRL](/en-us/investor/sec-filings?year=2025&filing=xbrl)\\n\\n## Microsoft Corp (MSFT)\\n\\n###### 2025 ANNUAL REPORT\\n\\n[VIEW ONLINE](https://www.microsoft.com/investor/reports/ar25/index.html)\\n\\n[DOWNLOAD NOW](https://www.microsoft.com/investor/reports/ar25/download-center/index.html)\\n\\nFollow us\\n\\nShare this page\\n\\n '}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0]['url']"
      ],
      "metadata": {
        "id": "xZ-WELThiwjK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ab9c48c4-b3c3-4d38-9e80-0676c8e73158"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://finance.yahoo.com/news/microsoft-corp-msft-q1-2025-072133599.html'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from markitdown import MarkItDown\n",
        "\n",
        "md = MarkItDown()\n",
        "doc_content = md.convert(result[1]['url'])"
      ],
      "metadata": {
        "id": "IXfm6C2UizLk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_content = md.convert(result[1]['url'])"
      ],
      "metadata": {
        "id": "cK2iU3buYDsB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc_content.title.strip())"
      ],
      "metadata": {
        "id": "4iNDFm3qk-Em",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a78f663-ac88-4189-d481-4490b657fd3a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔴WATCH LIVE: Microsoft Q1 2025 Earnings Call | $MSFT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc_content.text_content)"
      ],
      "metadata": {
        "id": "O7ok0mAqi9Oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1ab280-d14e-4a4a-b923-a9382f385829"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YouTube\n",
            "\n",
            "## 🔴WATCH LIVE: Microsoft Q1 2025 Earnings Call | $MSFT\n",
            "\n",
            "### Video Metadata\n",
            "- **Keywords:** video, sharing, camera phone, video phone, free, upload\n",
            "- **Runtime:** PT73M52S\n",
            "\n",
            "### Description\n",
            "Microsoft Q1 Earnings Highlights: 'AI-Driven Transformation Is Changing Work,' Company Beats Revenue, EPS Estimates - https://www.benzinga.com/news/earning...\n",
            "\n",
            "Microsoft Q1 2025 GAAP EPS $3.30 Beats $3.09 Estimate, Sales $65.60B Beat $64.51B Estimate\n",
            "\n",
            "Looking for a transcript of this call? Check out the Benzinga Earnings Call Transcripts API - https://www.benzinga.com/apis/cloud-p...\n",
            "\n",
            "🌐💻Find more coverage on www.benzinga.com\n",
            "\n",
            "📃🖊 Sign up for Benzinga's Trading Competition Powered by TradeZero for your chance to win up to $30,000! - https://benzingapartners.go2cloud.org...\n",
            "\n",
            "Follow us on socials:\n",
            "📷 Instagram: www.instagram.com/benzinga\n",
            "👨‍👩‍👦📕Facebook: www.facebook.com/benzinga\n",
            "⏱TikTok: www.tiktok.com/benzinga\n",
            "🐤Twitter: twitter.com/benzinga\n",
            "\n",
            "Disclaimer: This live stream is for informational and educational purposes only. The content featured, including earnings calls, is publicly available and sourced from respective company disclosures. Benzinga is not affiliated with the companies being discussed, nor do we claim ownership of the material presented. Trading in financial markets involves significant risk, and there is no guarantee of profit. The information provided by any financial product or service is for educational purposes and should not be considered as financial advice. Before making any investment decisions, it's important to conduct thorough research and consult with a qualified financial advisor. Past performance is not indicative of future results. Always invest what you can afford to lose and be aware of the potential for loss in any investment strategy.\n",
            "\n",
            "#Microsoft #ArtificialIntelligence $MSFT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from markitdown import MarkItDown\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_answer=False,\n",
        "                                  include_raw_content=True)\n",
        "md = MarkItDown()\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query and extracts useful information from the search links\"\"\"\n",
        "    results = tavily_tool.invoke(query)\n",
        "    docs = []\n",
        "    for result in tqdm(results):\n",
        "        # Extracting all text content from the URL\n",
        "        try:\n",
        "            extracted_info = md.convert(result['url'])\n",
        "            text_title = extracted_info.title.strip()\n",
        "            text_content = extracted_info.text_content.strip()\n",
        "            docs.append(text_title + '\\n' + text_content)\n",
        "        except:\n",
        "            print('Extraction blocked for url: ', result['url'])\n",
        "            pass\n",
        "\n",
        "    return docs"
      ],
      "metadata": {
        "id": "0G6V3Kv1jwU0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = search_web_extract_info.invoke('Model Context Protocol')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwardY8JhcMZ",
        "outputId": "49442495-9f6c-465a-cfba-3985e5020f41"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:00<00:00,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction blocked for url:  https://en.wikipedia.org/wiki/Model_Context_Protocol\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:03<00:00,  1.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(docs[3]))"
      ],
      "metadata": {
        "id": "jHJb63LQm2If",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03891710-4a4c-4792-8fb8-51c058e82926"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Specification - Model Context Protocol\n[Skip to main content](#content-area)\n\n[Model Context Protocol home page![light logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/light.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=4498cb8a57d574005f3dca62bdd49c95)![dark logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/dark.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=c0687c003f8f2cbdb24772ab4c8a522c)](/)\n\nVersion 2025-06-18\n\nSearch...\n\n⌘K\n\n* [Blog](https://blog.modelcontextprotocol.io)\n* [GitHub](https://github.com/modelcontextprotocol)\n\nSearch...\n\nNavigation\n\nSpecification\n\n[Documentation](/docs/getting-started/intro)[Specification](/specification/2025-11-25)[Registry](/registry/about)[Community](/community/contributing)\n\n* [Specification](/specification/2025-06-18)\n\n* [Key Changes](/specification/2025-06-18/changelog)\n\n* [Architecture](/specification/2025-06-18/architecture)\n\n##### Base Protocol\n\n* [Overview](/specification/2025-06-18/basic)\n* [Lifecycle](/specification/2025-06-18/basic/lifecycle)\n* [Transports](/specification/2025-06-18/basic/transports)\n* [Authorization](/specification/2025-06-18/basic/authorization)\n* [Security Best Practices](/specification/2025-06-18/basic/security_best_practices)\n* Utilities\n\n##### Client Features\n\n* [Roots](/specification/2025-06-18/client/roots)\n* [Sampling](/specification/2025-06-18/client/sampling)\n* [Elicitation](/specification/2025-06-18/client/elicitation)\n\n##### Server Features\n\n* [Overview](/specification/2025-06-18/server)\n* [Prompts](/specification/2025-06-18/server/prompts)\n* [Resources](/specification/2025-06-18/server/resources)\n* [Tools](/specification/2025-06-18/server/tools)\n* Utilities\n\n* [Schema Reference](/specification/2025-06-18/schema)\n\nOn this page\n\n* [Overview](#overview)\n* [Key Details](#key-details)\n* [Base Protocol](#base-protocol)\n* [Features](#features)\n* [Additional Utilities](#additional-utilities)\n* [Security and Trust & Safety](#security-and-trust-%26-safety)\n* [Key Principles](#key-principles)\n* [Implementation Guidelines](#implementation-guidelines)\n* [Learn More](#learn-more)\n\n# Specification\n\nCopy page\n\nCopy page\n\n[Model Context Protocol](https://modelcontextprotocol.io) (MCP) is an open protocol that\nenables seamless integration between LLM applications and external data sources and\ntools. Whether you’re building an AI-powered IDE, enhancing a chat interface, or creating\ncustom AI workflows, MCP provides a standardized way to connect LLMs with the context\nthey need.\nThis specification defines the authoritative protocol requirements, based on the\nTypeScript schema in\n[schema.ts](https://github.com/modelcontextprotocol/specification/blob/main/schema/2025-06-18/schema.ts).\nFor implementation guides and examples, visit\n[modelcontextprotocol.io](https://modelcontextprotocol.io).\nThe key words “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD\nNOT”, “RECOMMENDED”, “NOT RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be\ninterpreted as described in [BCP 14](https://datatracker.ietf.org/doc/html/bcp14)\n[[RFC2119](https://datatracker.ietf.org/doc/html/rfc2119)]\n[[RFC8174](https://datatracker.ietf.org/doc/html/rfc8174)] when, and only when, they\nappear in all capitals, as shown here.\n\n## [​](#overview) Overview\n\nMCP provides a standardized way for applications to:\n\n* Share contextual information with language models\n* Expose tools and capabilities to AI systems\n* Build composable integrations and workflows\n\nThe protocol uses [JSON-RPC](https://www.jsonrpc.org/) 2.0 messages to establish\ncommunication between:\n\n* **Hosts**: LLM applications that initiate connections\n* **Clients**: Connectors within the host application\n* **Servers**: Services that provide context and capabilities\n\nMCP takes some inspiration from the\n[Language Server Protocol](https://microsoft.github.io/language-server-protocol/), which\nstandardizes how to add support for programming languages across a whole ecosystem of\ndevelopment tools. In a similar way, MCP standardizes how to integrate additional context\nand tools into the ecosystem of AI applications.\n\n## [​](#key-details) Key Details\n\n### [​](#base-protocol) Base Protocol\n\n* [JSON-RPC](https://www.jsonrpc.org/) message format\n* Stateful connections\n* Server and client capability negotiation\n\n### [​](#features) Features\n\nServers offer any of the following features to clients:\n\n* **Resources**: Context and data, for the user or the AI model to use\n* **Prompts**: Templated messages and workflows for users\n* **Tools**: Functions for the AI model to execute\n\nClients may offer the following features to servers:\n\n* **Sampling**: Server-initiated agentic behaviors and recursive LLM interactions\n* **Roots**: Server-initiated inquiries into uri or filesystem boundaries to operate in\n* **Elicitation**: Server-initiated requests for additional information from users\n\n### [​](#additional-utilities) Additional Utilities\n\n* Configuration\n* Progress tracking\n* Cancellation\n* Error reporting\n* Logging\n\n## [​](#security-and-trust-&-safety) Security and Trust & Safety\n\nThe Model Context Protocol enables powerful capabilities through arbitrary data access\nand code execution paths. With this power comes important security and trust\nconsiderations that all implementors must carefully address.\n\n### [​](#key-principles) Key Principles\n\n1. **User Consent and Control**\n   * Users must explicitly consent to and understand all data access and operations\n   * Users must retain control over what data is shared and what actions are taken\n   * Implementors should provide clear UIs for reviewing and authorizing activities\n2. **Data Privacy**\n   * Hosts must obtain explicit user consent before exposing user data to servers\n   * Hosts must not transmit resource data elsewhere without user consent\n   * User data should be protected with appropriate access controls\n3. **Tool Safety**\n   * Tools represent arbitrary code execution and must be treated with appropriate\n     caution.\n     + In particular, descriptions of tool behavior such as annotations should be\n       considered untrusted, unless obtained from a trusted server.\n   * Hosts must obtain explicit user consent before invoking any tool\n   * Users should understand what each tool does before authorizing its use\n4. **LLM Sampling Controls**\n   * Users must explicitly approve any LLM sampling requests\n   * Users should control:\n     + Whether sampling occurs at all\n     + The actual prompt that will be sent\n     + What results the server can see\n   * The protocol intentionally limits server visibility into prompts\n\n### [​](#implementation-guidelines) Implementation Guidelines\n\nWhile MCP itself cannot enforce these security principles at the protocol level,\nimplementors **SHOULD**:\n\n1. Build robust consent and authorization flows into their applications\n2. Provide clear documentation of security implications\n3. Implement appropriate access controls and data protections\n4. Follow security best practices in their integrations\n5. Consider privacy implications in their feature designs\n\n## [​](#learn-more) Learn More\n\nExplore the detailed specification for each protocol component:\n\n[## Architecture](/specification/2025-06-18/architecture)[## Base Protocol](/specification/2025-06-18/basic)[## Server Features](/specification/2025-06-18/server)[## Client Features](/specification/2025-06-18/client)[## Contributing](/community/contributing)\n\nWas this page helpful?\n\nYesNo\n\n[Key Changes](/specification/2025-06-18/changelog)\n\n⌘I\n\n[github](https://github.com/modelcontextprotocol)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a Weather Tool"
      ],
      "metadata": {
        "id": "3km3-7WcnYk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEATHER_API_KEY = os.environ['WEATHER_API_KEY']"
      ],
      "metadata": {
        "id": "2uxqtaTuIExS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Mumbai\"\n",
        "base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "response = requests.get(complete_url)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh36NighIhhQ",
        "outputId": "63472a69-ecc9-4ce7-d057-62aa9028a16e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgXDB6UyJUSF",
        "outputId": "03162228-6768-44b6-f2c9-eb0320c94900"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'location': {'name': 'Mumbai', 'region': 'Maharashtra', 'country': 'India', 'lat': 18.975, 'lon': 72.826, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1770508774, 'localtime': '2026-02-08 05:29'}, 'current': {'last_updated_epoch': 1770507900, 'last_updated': '2026-02-08 05:15', 'temp_c': 26.0, 'temp_f': 78.8, 'is_day': 0, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/night/122.png', 'code': 1009}, 'wind_mph': 5.8, 'wind_kph': 9.4, 'wind_degree': 76, 'wind_dir': 'ENE', 'pressure_mb': 1013.0, 'pressure_in': 29.91, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 45, 'cloud': 0, 'feelslike_c': 26.8, 'feelslike_f': 80.2, 'windchill_c': 25.0, 'windchill_f': 77.0, 'heatindex_c': 25.9, 'heatindex_f': 78.7, 'dewpoint_c': 14.6, 'dewpoint_f': 58.3, 'vis_km': 2.5, 'vis_miles': 1.0, 'uv': 0.0, 'gust_mph': 10.5, 'gust_kph': 16.9, 'short_rad': 0, 'diff_rad': 0, 'dni': 0, 'gti': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather.\"\"\"\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ],
      "metadata": {
        "id": "ZM8R-JgOnXdN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather.invoke(\"Fairmont\")"
      ],
      "metadata": {
        "id": "12xdLSJ3ZUiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd529b6-eff3-48c7-a263-90cbbdd42653"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'location': {'name': 'Fairmont',\n",
              "  'region': 'West Virginia',\n",
              "  'country': 'United States of America',\n",
              "  'lat': 39.485,\n",
              "  'lon': -80.1428,\n",
              "  'tz_id': 'America/New_York',\n",
              "  'localtime_epoch': 1770508770,\n",
              "  'localtime': '2026-02-07 18:59'},\n",
              " 'current': {'last_updated_epoch': 1770507900,\n",
              "  'last_updated': '2026-02-07 18:45',\n",
              "  'temp_c': -8.9,\n",
              "  'temp_f': 16.0,\n",
              "  'is_day': 0,\n",
              "  'condition': {'text': 'Light freezing rain',\n",
              "   'icon': '//cdn.weatherapi.com/weather/64x64/night/311.png',\n",
              "   'code': 1198},\n",
              "  'wind_mph': 10.5,\n",
              "  'wind_kph': 16.9,\n",
              "  'wind_degree': 307,\n",
              "  'wind_dir': 'NW',\n",
              "  'pressure_mb': 1024.0,\n",
              "  'pressure_in': 30.25,\n",
              "  'precip_mm': 0.01,\n",
              "  'precip_in': 0.0,\n",
              "  'humidity': 31,\n",
              "  'cloud': 0,\n",
              "  'feelslike_c': -15.8,\n",
              "  'feelslike_f': 3.5,\n",
              "  'windchill_c': -16.1,\n",
              "  'windchill_f': 3.1,\n",
              "  'heatindex_c': -9.6,\n",
              "  'heatindex_f': 14.8,\n",
              "  'dewpoint_c': -14.0,\n",
              "  'dewpoint_f': 6.8,\n",
              "  'vis_km': 16.0,\n",
              "  'vis_miles': 9.0,\n",
              "  'uv': 0.0,\n",
              "  'gust_mph': 15.6,\n",
              "  'gust_kph': 25.1,\n",
              "  'short_rad': 0,\n",
              "  'diff_rad': 0,\n",
              "  'dni': 0,\n",
              "  'gti': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rich\n",
        "\n",
        "result = get_weather.invoke(\"Fairmont\")\n",
        "rich.print_json(data=result)"
      ],
      "metadata": {
        "id": "dyL1L1ifn0mj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "52092231-1bc0-4d95-b32c-6531044074a6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "  \u001b[1;34m\"location\"\u001b[0m: \u001b[1m{\u001b[0m\n",
              "    \u001b[1;34m\"name\"\u001b[0m: \u001b[32m\"Fairmont\"\u001b[0m,\n",
              "    \u001b[1;34m\"region\"\u001b[0m: \u001b[32m\"West Virginia\"\u001b[0m,\n",
              "    \u001b[1;34m\"country\"\u001b[0m: \u001b[32m\"United States of America\"\u001b[0m,\n",
              "    \u001b[1;34m\"lat\"\u001b[0m: \u001b[1;36m39.485\u001b[0m,\n",
              "    \u001b[1;34m\"lon\"\u001b[0m: \u001b[1;36m-80.1428\u001b[0m,\n",
              "    \u001b[1;34m\"tz_id\"\u001b[0m: \u001b[32m\"America/New_York\"\u001b[0m,\n",
              "    \u001b[1;34m\"localtime_epoch\"\u001b[0m: \u001b[1;36m1770508770\u001b[0m,\n",
              "    \u001b[1;34m\"localtime\"\u001b[0m: \u001b[32m\"2026-02-07 18:59\"\u001b[0m\n",
              "  \u001b[1m}\u001b[0m,\n",
              "  \u001b[1;34m\"current\"\u001b[0m: \u001b[1m{\u001b[0m\n",
              "    \u001b[1;34m\"last_updated_epoch\"\u001b[0m: \u001b[1;36m1770507900\u001b[0m,\n",
              "    \u001b[1;34m\"last_updated\"\u001b[0m: \u001b[32m\"2026-02-07 18:45\"\u001b[0m,\n",
              "    \u001b[1;34m\"temp_c\"\u001b[0m: \u001b[1;36m-8.9\u001b[0m,\n",
              "    \u001b[1;34m\"temp_f\"\u001b[0m: \u001b[1;36m16.0\u001b[0m,\n",
              "    \u001b[1;34m\"is_day\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"condition\"\u001b[0m: \u001b[1m{\u001b[0m\n",
              "      \u001b[1;34m\"text\"\u001b[0m: \u001b[32m\"Light freezing rain\"\u001b[0m,\n",
              "      \u001b[1;34m\"icon\"\u001b[0m: \u001b[32m\"//cdn.weatherapi.com/weather/64x64/night/311.png\"\u001b[0m,\n",
              "      \u001b[1;34m\"code\"\u001b[0m: \u001b[1;36m1198\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1;34m\"wind_mph\"\u001b[0m: \u001b[1;36m10.5\u001b[0m,\n",
              "    \u001b[1;34m\"wind_kph\"\u001b[0m: \u001b[1;36m16.9\u001b[0m,\n",
              "    \u001b[1;34m\"wind_degree\"\u001b[0m: \u001b[1;36m307\u001b[0m,\n",
              "    \u001b[1;34m\"wind_dir\"\u001b[0m: \u001b[32m\"NW\"\u001b[0m,\n",
              "    \u001b[1;34m\"pressure_mb\"\u001b[0m: \u001b[1;36m1024.0\u001b[0m,\n",
              "    \u001b[1;34m\"pressure_in\"\u001b[0m: \u001b[1;36m30.25\u001b[0m,\n",
              "    \u001b[1;34m\"precip_mm\"\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
              "    \u001b[1;34m\"precip_in\"\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
              "    \u001b[1;34m\"humidity\"\u001b[0m: \u001b[1;36m31\u001b[0m,\n",
              "    \u001b[1;34m\"cloud\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"feelslike_c\"\u001b[0m: \u001b[1;36m-15.8\u001b[0m,\n",
              "    \u001b[1;34m\"feelslike_f\"\u001b[0m: \u001b[1;36m3.5\u001b[0m,\n",
              "    \u001b[1;34m\"windchill_c\"\u001b[0m: \u001b[1;36m-16.1\u001b[0m,\n",
              "    \u001b[1;34m\"windchill_f\"\u001b[0m: \u001b[1;36m3.1\u001b[0m,\n",
              "    \u001b[1;34m\"heatindex_c\"\u001b[0m: \u001b[1;36m-9.6\u001b[0m,\n",
              "    \u001b[1;34m\"heatindex_f\"\u001b[0m: \u001b[1;36m14.8\u001b[0m,\n",
              "    \u001b[1;34m\"dewpoint_c\"\u001b[0m: \u001b[1;36m-14.0\u001b[0m,\n",
              "    \u001b[1;34m\"dewpoint_f\"\u001b[0m: \u001b[1;36m6.8\u001b[0m,\n",
              "    \u001b[1;34m\"vis_km\"\u001b[0m: \u001b[1;36m16.0\u001b[0m,\n",
              "    \u001b[1;34m\"vis_miles\"\u001b[0m: \u001b[1;36m9.0\u001b[0m,\n",
              "    \u001b[1;34m\"uv\"\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
              "    \u001b[1;34m\"gust_mph\"\u001b[0m: \u001b[1;36m15.6\u001b[0m,\n",
              "    \u001b[1;34m\"gust_kph\"\u001b[0m: \u001b[1;36m25.1\u001b[0m,\n",
              "    \u001b[1;34m\"short_rad\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"diff_rad\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"dni\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"gti\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
              "  \u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"location\"</span>: <span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Fairmont\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"region\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"West Virginia\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"country\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"United States of America\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"lat\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39.485</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"lon\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-80.1428</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"tz_id\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"America/New_York\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"localtime_epoch\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1770508770</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"localtime\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2026-02-07 18:59\"</span>\n",
              "  <span style=\"font-weight: bold\">}</span>,\n",
              "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"current\"</span>: <span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"last_updated_epoch\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1770507900</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"last_updated\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2026-02-07 18:45\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"temp_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8.9</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"temp_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"is_day\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"condition\"</span>: <span style=\"font-weight: bold\">{</span>\n",
              "      <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"text\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Light freezing rain\"</span>,\n",
              "      <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"icon\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"//cdn.weatherapi.com/weather/64x64/night/311.png\"</span>,\n",
              "      <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"code\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1198</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"wind_mph\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.5</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"wind_kph\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.9</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"wind_degree\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">307</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"wind_dir\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"NW\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pressure_mb\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pressure_in\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30.25</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"precip_mm\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"precip_in\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"humidity\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"cloud\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"feelslike_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-15.8</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"feelslike_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"windchill_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-16.1</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"windchill_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"heatindex_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9.6</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"heatindex_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.8</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"dewpoint_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-14.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"dewpoint_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.8</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"vis_km\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"vis_miles\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"uv\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"gust_mph\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.6</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"gust_kph\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25.1</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"short_rad\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"diff_rad\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"dni\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"gti\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "  <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore LLM tool calling with custom tools\n",
        "\n",
        "An agent is basically an LLM which has the capability to automatically call relevant functions to perform complex or tool-based tasks based on input human prompts.\n",
        "\n",
        "Tool calling also popularly known as function calling is the ability to reliably enable such LLMs to call external tools and APIs.\n",
        "\n",
        "We will leverage the custom tools we created earlier in the previous section and try to see if the LLM can automatically call the right tools based on input prompts"
      ],
      "metadata": {
        "id": "bIOhB430gpW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool calling for LLMs with native support for tool or function calling"
      ],
      "metadata": {
        "id": "4Y26Ohn3P54j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tool calling allows a model to respond to a given prompt by generating output that matches a user-defined schema. While the name implies that the model is performing some action, this is actually not the case! The model is coming up with the arguments to a tool, and actually running the tool (or not) is up to the user or agent defined by the user.\n",
        "\n",
        "Many LLM providers, including Anthropic, Cohere, Google, Mistral, OpenAI, and others, support variants of a tool calling feature. These features typically allow requests to the LLM to include available tools and their schemas, and for responses to include calls to these tools.\n",
        "\n"
      ],
      "metadata": {
        "id": "1nACq0NgL5yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "s0wCNpzCBvtS"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [multiply, search_web_extract_info, get_weather]\n",
        "chatgpt_with_tools = chatgpt.bind_tools(tools)"
      ],
      "metadata": {
        "id": "rjKWxFNgB2t_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "96uFeXk5PV_4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the chatprompttemplate from langchain and pass the user query to the langchain chain\n",
        "# also create a chain with this prmpt template and the chatgpt_with_tools\n",
        "# might need to use RunnablePassThrough"
      ],
      "metadata": {
        "id": "BRpkO9wPN5VQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIMC_uHcOhXD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMs are still not perfect in tool calling so you might need to play around with the following prompt\n",
        "prompt = \"\"\"\n",
        "            Given only the tools at your disposal, mention tool calls for the following tasks:\n",
        "            Do not change the query given for any search tasks\n",
        "            1. What is 3.14 times 2.718\n",
        "            2. What is the current weather in Fairmont today\n",
        "            3. What are the 4 major Agentic AI Design Patterns\n",
        "         \"\"\"\n",
        "\n",
        "results = chatgpt_with_tools.invoke(prompt)"
      ],
      "metadata": {
        "id": "hJ271K_tB9K7"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "kLoZWknjCNlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda7ef84-905a-4135-e234-eea85af5cce1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 183, 'total_tokens': 257, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D6mbRO8jnTUxgO6XzbXfw4YIJXOeK', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c3a91-f258-71c0-9a81-934f2b0f8011-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3.14, 'b': 2.718}, 'id': 'call_Fn2rhquKdW7LvTXR1MAvNvcg', 'type': 'tool_call'}, {'name': 'get_weather', 'args': {'query': 'Fairmont'}, 'id': 'call_2Ua8gcXEET2KszUewN4vqu91', 'type': 'tool_call'}, {'name': 'search_web_extract_info', 'args': {'query': '4 major Agentic AI Design Patterns'}, 'id': 'call_m3YrtmM1TgZCTOdFSVYIbGZC', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 183, 'output_tokens': 74, 'total_tokens': 257, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.tool_calls"
      ],
      "metadata": {
        "id": "ckZz5pcpCQau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e320a180-2326-44bf-b7c4-3540f35acc86"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'multiply',\n",
              "  'args': {'a': 3.14, 'b': 2.718},\n",
              "  'id': 'call_Fn2rhquKdW7LvTXR1MAvNvcg',\n",
              "  'type': 'tool_call'},\n",
              " {'name': 'get_weather',\n",
              "  'args': {'query': 'Fairmont'},\n",
              "  'id': 'call_2Ua8gcXEET2KszUewN4vqu91',\n",
              "  'type': 'tool_call'},\n",
              " {'name': 'search_web_extract_info',\n",
              "  'args': {'query': '4 major Agentic AI Design Patterns'},\n",
              "  'id': 'call_m3YrtmM1TgZCTOdFSVYIbGZC',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply"
      ],
      "metadata": {
        "id": "tLxNMPTegDed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623008ca-7ea0-42c6-822a-326bdc0e83f6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='multiply', description='use to multiply numbers', args_schema=<class '__main__.CalculatorInput'>, return_direct=True, func=<function multiply at 0x78820e0ca520>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toolkit = {\n",
        "    \"multiply\": multiply,\n",
        "    \"search_web_extract_info\": search_web_extract_info,\n",
        "    \"get_weather\": get_weather\n",
        "}\n",
        "\n",
        "for tool_call in results.tool_calls:\n",
        "    selected_tool = toolkit[tool_call[\"name\"].lower()]\n",
        "    print(f\"Calling tool: {tool_call['name']}\")\n",
        "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
        "    print(tool_output)\n",
        "    print()"
      ],
      "metadata": {
        "id": "POvGp_xZCpSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74962e8a-6bd0-4fcc-bd60-9802a9a7a16e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling tool: multiply\n",
            "8.53452\n",
            "\n",
            "Calling tool: get_weather\n",
            "{'location': {'name': 'Fairmont', 'region': 'West Virginia', 'country': 'United States of America', 'lat': 39.485, 'lon': -80.1428, 'tz_id': 'America/New_York', 'localtime_epoch': 1770509258, 'localtime': '2026-02-07 19:07'}, 'current': {'last_updated_epoch': 1770512400, 'last_updated': '2026-02-07 20:00', 'temp_c': -8.9, 'temp_f': 16.0, 'is_day': 0, 'condition': {'text': 'Light freezing rain', 'icon': '//cdn.weatherapi.com/weather/64x64/night/311.png', 'code': 1198}, 'wind_mph': 9.2, 'wind_kph': 14.8, 'wind_degree': 310, 'wind_dir': 'NW', 'pressure_mb': 1024.0, 'pressure_in': 30.25, 'precip_mm': 0.01, 'precip_in': 0.0, 'humidity': 31, 'cloud': 0, 'feelslike_c': -15.3, 'feelslike_f': 4.4, 'windchill_c': -16.2, 'windchill_f': 2.8, 'heatindex_c': -10.9, 'heatindex_f': 12.3, 'dewpoint_c': -13.7, 'dewpoint_f': 7.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 13.9, 'gust_kph': 22.3, 'short_rad': 0, 'diff_rad': 0, 'dni': 0, 'gti': 0}}\n",
            "\n",
            "Calling tool: search_web_extract_info\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2/5 [00:00<00:00,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction blocked for url:  https://medium.com/@bijit211987/agentic-design-patterns-cbd0aae2962f\n",
            "Extraction blocked for url:  https://medium.com/mongodb/here-are-7-design-patterns-for-agentic-systems-you-need-to-know-d74a4b5835a5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Choose a design pattern for your agentic AI system \\xa0|\\xa0 Cloud Architecture Center \\xa0|\\xa0 Google Cloud Documentation\\n[Skip to main content](#main-content)\\n\\n[![Google Cloud Documentation](https://www.gstatic.com/devrel-devsite/prod/v9fbf2fc2e9c6161a9e3b16cd1fa448d29a6cc4e24bc54c4db944aa5e75d4972d/clouddocs/images/lockup.svg)](/)\\n\\n[Technology areas](https://docs.cloud.google.com/docs)\\n\\n* [AI and ML](https://docs.cloud.google.com/docs/ai-ml)\\n* [Application development](https://docs.cloud.google.com/docs/application-development)\\n* [Application hosting](https://docs.cloud.google.com/docs/application-hosting)\\n* [Compute](https://docs.cloud.google.com/docs/compute-area)\\n* [Data analytics and pipelines](https://docs.cloud.google.com/docs/data)\\n* [Databases](https://docs.cloud.google.com/docs/databases)\\n* [Distributed, hybrid, and multicloud](https://docs.cloud.google.com/docs/dhm-cloud)\\n* [Generative AI](https://docs.cloud.google.com/docs/generative-ai)\\n* [Industry solutions](https://docs.cloud.google.com/docs/industry)\\n* [Migration](https://docs.cloud.google.com/docs/migration)\\n* [Networking](https://docs.cloud.google.com/docs/networking)\\n* [Observability and monitoring](https://docs.cloud.google.com/docs/observability)\\n* [Security](https://docs.cloud.google.com/docs/security)\\n* [Storage](https://docs.cloud.google.com/docs/storage)\\n\\n[Cross-product tools](https://docs.cloud.google.com/docs/cross-product-overviews)\\n\\n* [Access and resources management](https://docs.cloud.google.com/docs/access-resources)\\n* [Costs and usage management](https://docs.cloud.google.com/docs/costs-usage)\\n* [Infrastructure as code](https://docs.cloud.google.com/docs/iac)\\n* [SDK, languages, frameworks, and tools](https://docs.cloud.google.com/docs/devtools)\\n\\n`/`\\n\\n[Console](//console.cloud.google.com/)\\n\\n* English\\n* Deutsch\\n* Español\\n* Español – América Latina\\n* Français\\n* Indonesia\\n* Italiano\\n* Português\\n* Português – Brasil\\n* 中文 – 简体\\n* 中文 – 繁體\\n* 日本語\\n* 한국어\\n\\nSign in\\n\\n[![](https://docs.cloud.google.com/_static/clouddocs/images/icons/cloud.svg)](https://docs.cloud.google.com/architecture)\\n\\n* [Cloud Architecture Center](https://docs.cloud.google.com/architecture)\\n\\n[Start free](//console.cloud.google.com/freetrial)\\n\\n[![Google Cloud Documentation](https://www.gstatic.com/devrel-devsite/prod/v9fbf2fc2e9c6161a9e3b16cd1fa448d29a6cc4e24bc54c4db944aa5e75d4972d/clouddocs/images/lockup.svg)](/)\\n\\n* [Technology areas](/docs)\\n  + More\\n* [Cross-product tools](/docs/cross-product-overviews)\\n  + More\\n* [Console](//console.cloud.google.com/)\\n\\n* [< Architecture Center home](/architecture)\\n* [What\\'s new](/architecture/release-notes)\\n* Fundamentals\\n\\n  + [Content overview](/architecture/fundamentals)\\n  + Well-Architected Framework\\n\\n    - [Overview](/architecture/framework)\\n    - [What\\'s new](/architecture/framework/whats-new)\\n    - Pillars\\n    - Operational excellence\\n\\n      * [Overview](/architecture/framework/operational-excellence)\\n      * [Ensure operational readiness and performance using CloudOps](/architecture/framework/operational-excellence/operational-readiness-and-performance-using-cloudops)\\n      * [Manage incidents and problems](/architecture/framework/operational-excellence/manage-incidents-and-problems)\\n      * [Manage and optimize cloud resources](/architecture/framework/operational-excellence/manage-and-optimize-cloud-resources)\\n      * [Automate and manage change](/architecture/framework/operational-excellence/automate-and-manage-change)\\n      * [Continuously improve and innovate](/architecture/framework/operational-excellence/continuously-improve-and-innovate)\\n      * [View on one page](/architecture/framework/operational-excellence/printable)\\n    - Security, privacy, and compliance\\n\\n      * [Overview](/architecture/framework/security)\\n      * [Implement security by design](/architecture/framework/security/implement-security-by-design)\\n      * [Implement zero trust](/architecture/framework/security/implement-zero-trust)\\n      * [Implement shift-left security](/architecture/framework/security/implement-shift-left-security)\\n      * [Implement preemptive cyber defense](/architecture/framework/security/implement-preemptive-cyber-defense)\\n      * [Use AI securely and responsibly](/architecture/framework/security/use-ai-securely-and-responsibly)\\n      * [Use AI for security](/architecture/framework/security/use-ai-for-security)\\n      * [Meet regulatory, compliance, and privacy needs](/architecture/framework/security/meet-regulatory-compliance-and-privacy-needs)\\n      * [Shared responsibility and shared fate](/architecture/framework/security/shared-responsibility-shared-fate)\\n      * [View on one page](/architecture/framework/security/printable)\\n    - Reliability\\n\\n      * [Overview](/architecture/framework/reliability)\\n      * [Define reliability based on user-experience goals](/architecture/framework/reliability/define-reliability-based-on-user-experience-goals)\\n      * [Set realistic targets for reliability](/architecture/framework/reliability/set-targets)\\n      * [Build high availability through redundancy](/architecture/framework/reliability/build-highly-available-systems)\\n      * [Take advantage of horizontal scalability](/architecture/framework/reliability/horizontal-scalability)\\n      * [Detect potential failures by using observability](/architecture/framework/reliability/observability)\\n      * [Design for graceful degradation](/architecture/framework/reliability/graceful-degradation)\\n      * [Perform testing for recovery from failures](/architecture/framework/reliability/perform-testing-for-recovery-from-failures)\\n      * [Perform testing for recovery from data loss](/architecture/framework/reliability/perform-testing-for-recovery-from-data-loss)\\n      * [Conduct thorough postmortems](/architecture/framework/reliability/conduct-postmortems)\\n      * [View on one page](/architecture/framework/reliability/printable)\\n    - Cost optimization\\n\\n      * [Overview](/architecture/framework/cost-optimization)\\n      * [Align spending with business value](/architecture/framework/cost-optimization/align-cloud-spending-business-value)\\n      * [Foster a culture of cost awareness](/architecture/framework/cost-optimization/foster-culture-cost-awareness)\\n      * [Optimize resource usage](/architecture/framework/cost-optimization/optimize-resource-usage)\\n      * [Optimize continuously](/architecture/framework/cost-optimization/optimize-continuously)\\n      * [View on one page](/architecture/framework/cost-optimization/printable)\\n    - Performance optimization\\n\\n      * [Overview](/architecture/framework/performance-optimization)\\n      * [Plan resource allocation](/architecture/framework/performance-optimization/plan-resource-allocation)\\n      * [Take advantage of elasticity](/architecture/framework/performance-optimization/elasticity)\\n      * [Promote modular design](/architecture/framework/performance-optimization/promote-modular-design)\\n      * [Continuously monitor and improve performance](/architecture/framework/performance-optimization/continuously-monitor-and-improve-performance)\\n      * [View on one page](/architecture/framework/performance-optimization/printable)\\n    - Sustainability\\n\\n      * [Overview](/architecture/framework/sustainability)\\n      * [Use low-carbon regions](/architecture/framework/sustainability/low-carbon-regions)\\n      * [Optimize AI and ML workloads](/architecture/framework/sustainability/ai-ml-energy-efficiency)\\n      * [Optimize resource usage](/architecture/framework/sustainability/optimize-resource-usage)\\n      * [Develop energy-efficient software](/architecture/framework/sustainability/energy-efficient-software)\\n      * [Optimize data and storage](/architecture/framework/sustainability/optimize-storage)\\n      * [Continuously measure and improve](/architecture/framework/sustainability/continuously-measure-improve)\\n      * [Promote a culture of sustainability](/architecture/framework/sustainability/culture)\\n      * [Align with industry guidelines](/architecture/framework/sustainability/industry-guidelines)\\n      * [View on one page](/architecture/framework/sustainability/printable)\\n    - [View all the pillars on one page](/architecture/framework/printable)\\n    - Cross-pillar perspectives\\n    - AI and ML\\n\\n      * [Overview](/architecture/framework/perspectives/ai-ml)\\n      * [Operational excellence](/architecture/framework/perspectives/ai-ml/operational-excellence)\\n      * [Security](/architecture/framework/perspectives/ai-ml/security)\\n      * [Reliability](/architecture/framework/perspectives/ai-ml/reliability)\\n      * [Cost optimization](/architecture/framework/perspectives/ai-ml/cost-optimization)\\n      * [Performance optimization](/architecture/framework/perspectives/ai-ml/performance-optimization)\\n      * [View on one page](/architecture/framework/perspectives/ai-ml/printable)\\n    - Financial services industry (FSI)\\n\\n      * [Overview](/architecture/framework/perspectives/fsi)\\n      * [Operational excellence](/architecture/framework/perspectives/fsi/operational-excellence)\\n      * [Security](/architecture/framework/perspectives/fsi/security)\\n      * [Reliability](/architecture/framework/perspectives/fsi/reliability)\\n      * [Cost optimization](/architecture/framework/perspectives/fsi/cost-optimization)\\n      * [Performance optimization](/architecture/framework/perspectives/fsi/performance-optimization)\\n      * [View on one page](/architecture/framework/perspectives/fsi/printable)\\n  + Deployment archetypes\\n\\n    - [Overview](/architecture/deployment-archetypes)\\n    - [Zonal](/architecture/deployment-archetypes/zonal)\\n    - [Regional](/architecture/deployment-archetypes/regional)\\n    - [Multi-regional](/architecture/deployment-archetypes/multiregional)\\n    - [Global](/architecture/deployment-archetypes/global)\\n    - [Hybrid](/architecture/deployment-archetypes/hybrid)\\n    - [Multicloud](/architecture/deployment-archetypes/multicloud)\\n    - [Comparative analysis](/architecture/deployment-archetypes/comparison)\\n    - [What\\'s next](/architecture/deployment-archetypes/whats-next)\\n    - Reference architectures\\n\\n      * [Single-zone deployment on Compute Engine](/architecture/single-zone-deployment-compute-engine)\\n      * [Regional deployment on Compute Engine](/architecture/regional-deployment-compute-engine)\\n      * [Multi-regional deployment on Compute Engine](/architecture/multiregional-vms)\\n      * [Global deployment on Compute Engine and Spanner](/architecture/global-deployment-compute-engine-spanner)\\n  + Landing zone design\\n\\n    - [Landing zones overview](/architecture/landing-zones)\\n    - [Decide identity onboarding](/architecture/landing-zones/decide-how-to-onboard-identities)\\n    - [Decide resource hierarchy](/architecture/landing-zones/decide-resource-hierarchy)\\n    - Network design\\n\\n      * [Decide network design](/architecture/landing-zones/decide-network-design)\\n      * [Implement network design](/architecture/landing-zones/implement-network-design)\\n    - [Decide security](/architecture/landing-zones/decide-security)\\n  + Enterprise foundations blueprint\\n\\n    - [Overview](/architecture/blueprints/security-foundations)\\n    - Architecture\\n\\n      * [Authentication and authorization](/architecture/blueprints/security-foundations/authentication-authorization)\\n      * [Organization structure](/architecture/blueprints/security-foundations/organization-structure)\\n      * [Networking](/architecture/blueprints/security-foundations/networking)\\n      * [Detective controls](/architecture/blueprints/security-foundations/detective-controls)\\n      * [Preventative controls](/architecture/blueprints/security-foundations/preventative-controls)\\n    - [Deployment methodology](/architecture/blueprints/security-foundations/deployment-methodology)\\n    - [Operations best practices](/architecture/blueprints/security-foundations/operation-best-practices)\\n    - [Deploy the blueprint](/architecture/blueprints/security-foundations/summary)\\n* AI and machine learning\\n\\n  + [Content overview](/architecture/ai-ml)\\n  + Agentic AI\\n\\n    - [Overview](/architecture/agentic-ai-overview)\\n    - [Choose agentic architecture components](/architecture/choose-agentic-ai-architecture-components)\\n    - [Choose an agent design pattern](/architecture/choose-design-pattern-agentic-ai-system)\\n    - [Multi-agent AI system](/architecture/multiagent-ai-system)\\n    - [Single-agent AI system using ADK and Cloud Run](/architecture/single-agent-ai-system-adk-cloud-run)\\n    - Use cases\\n\\n      * [Administer interactive learning](/architecture/agentic-ai-interactive-learning)\\n      * [Automate data science workflows](/architecture/agentic-ai-data-science)\\n      * [Orchestrate access to disparate systems](/architecture/agenticai-orchestrate-access-disparate-systems)\\n  + Generative AI\\n\\n    - [Overview](/architecture/genai-overview)\\n    - Generative AI with RAG\\n\\n      * [Overview](/architecture/rag-reference-architectures)\\n      * [Private connectivity for RAG-capable generative AI applications](/architecture/private-connectivity-rag-capable-gen-ai)\\n      * [RAG infrastructure using Gemini Enterprise and Vertex AI](/architecture/rag-genai-gemini-enterprise-vertexai)\\n      * [RAG infrastructure using Vertex AI and Vector Search](/architecture/gen-ai-rag-vertex-ai-vector-search)\\n      * [RAG infrastructure using Vertex AI and AlloyDB](/architecture/rag-capable-gen-ai-app-using-vertex-ai)\\n      * [RAG infrastructure using Vertex AI and Cloud SQL](/architecture/ai-ml/generative-ai-rag)\\n      * [RAG infrastructure using GKE and Cloud SQL](/architecture/rag-capable-gen-ai-app-using-gke)\\n      * [GraphRAG infrastructure using Vertex AI and Spanner Graph](/architecture/gen-ai-graphrag-spanner)\\n      * [Harness CI/CD pipeline for RAG applications](/architecture/partners/harness-cicd-pipeline-for-rag-app)\\n    - [Deploy an enterprise generative AI and ML model](/architecture/blueprints/genai-mlops-blueprint)\\n    - [Deploy and operate generative AI applications](/architecture/deploy-operate-generative-ai-applications)\\n    - Use cases\\n\\n      * [Automate utilization-review of health insurance claims](/architecture/use-generative-ai-utilization-management)\\n      * [Build a knowledge base](/architecture/ai-ml/generative-ai-knowledge-base)\\n      * [Generate personalized marketing campaigns](/architecture/genai-marketing-campaigns)\\n      * [Generate personalized product recommendations](/architecture/genai-product-recommendations)\\n      * [Generate podcasts from audio](/architecture/genai-podcasts-from-commentary)\\n      * [Generate solutions for customer support questions](/architecture/genai-customer-support)\\n      * [Summarize documents on demand](/architecture/ai-ml/generative-ai-document-summarization)\\n  + ML applications and operations\\n\\n    - [Overview](/architecture/ai-ml/ml-application-operations-architecture-guides)\\n    - [Best practices for implementing ML on Google Cloud](/architecture/ml-on-gcp-best-practices)\\n    - [Guidelines for high-quality, predictive ML solutions](/architecture/guidelines-for-developing-high-quality-ml-solutions)\\n    - [MLOps using TensorFlow Extended, Vertex AI Pipelines, and Cloud Build](/architecture/architecture-for-mlops-using-tfx-kubeflow-pipelines-and-cloud-build)\\n    - [MLOps: Continuous delivery and automation pipelines in machine learning](/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)\\n    - Build an ML vision analytics solution with Dataflow and Cloud Vision API\\n\\n      * [Reference architecture](/architecture/building-a-vision-analytics-solution)\\n      * [Deploy the architecture](/architecture/building-a-vision-analytics-solution/deployment)\\n    - [Confidential computing for data analytics and AI](/architecture/security/confidential-computing-analytics-ai)\\n    - [Cross-silo and cross-device federated learning](/architecture/cross-silo-cross-device-federated-learning-google-cloud)\\n    - [Implement two-tower retrieval with large-scale candidate generation](/architecture/implement-two-tower-retrieval-large-scale-candidate-generation)\\n    - [Model development and data labeling with Labelbox](/architecture/partners/model-development-data-labeling-labelbox-google-cloud)\\n    - [Use Vertex AI Pipelines for propensity modeling](/architecture/use-vertex-ai-pipelines-for-propensity-modeling)\\n    - [C3 AI architecture](/architecture/partners/c3-ai-architecture)\\n  + AI and ML infrastructure\\n\\n    - [Design storage for AI and ML workloads in Google Cloud](/architecture/ai-ml/storage-for-ai-ml)\\n    - [Optimize AI and ML workloads with Cloud Storage FUSE](/architecture/optimize-ai-ml-workloads-cloud-storage-fuse)\\n    - [Optimize AI and ML workloads with Managed Lustre](/architecture/optimize-ai-ml-workloads-managed-lustre)\\n* Application development\\n\\n  + [Content overview](/architecture/application-development)\\n  + Development approaches and styles\\n\\n    - [Patterns for scalable and resilient apps](/architecture/scalable-and-resilient-apps)\\n  + Development platform management\\n\\n    - Deploy an enterprise developer platform\\n\\n      * [Overview](/architecture/blueprints/enterprise-application-blueprint)\\n      * [Architecture](/architecture/blueprints/enterprise-application-blueprint/architecture)\\n      * [Developer platform controls](/architecture/blueprints/enterprise-application-blueprint/developer-platform-controls)\\n      * [Service architecture](/architecture/blueprints/enterprise-application-blueprint/service-architecture)\\n      * [Logging and monitoring](/architecture/blueprints/enterprise-application-blueprint/logging-monitoring)\\n      * [Operations](/architecture/blueprints/enterprise-application-blueprint/ops-developer-platform-applications)\\n      * [Costs and attributions](/architecture/blueprints/enterprise-application-blueprint/manage-costs-attributions)\\n      * [Deployment methodology](/architecture/blueprints/enterprise-application-blueprint/deployment-methodology)\\n      * [Cymbal Bank example](/architecture/blueprints/enterprise-application-blueprint/cymbal-bank)\\n      * [Mapping BeyondProd principles](/architecture/blueprints/enterprise-application-blueprint/mapping-beyondprod-security-principles)\\n      * [Deploy the blueprint](/architecture/blueprints/enterprise-application-blueprint/deploy-blueprint)\\n    - [Best practices for cost-optimized Kubernetes applications on GKE](/architecture/best-practices-for-running-cost-effective-kubernetes-applications-on-gke)\\n    - Expose service mesh applications through GKE Gateway\\n\\n      * [Reference architecture](/architecture/exposing-service-mesh-apps-through-gke-ingress)\\n      * [Deploy the architecture](/architecture/exposing-service-mesh-apps-through-gke-ingress/deployment)\\n    - Build globally distributed applications using GKE Gateway and Cloud Service Mesh\\n\\n      * [Reference architecture](/architecture/build-apps-using-gateway-and-cloud-service)\\n      * [Deploy the architecture](/architecture/build-apps-using-gateway-and-cloud-service/deployment)\\n    - [Patterns and practices for identity and access governance on Google Cloud](/architecture/patterns-practices-identity-access-governance-google-cloud)\\n    - [Resource management with ServiceNow](/architecture/resource-management-with-servicenow)\\n    - [Select a managed container runtime environment](/architecture/select-managed-container-runtime-environment)\\n  + DevOps and development lifecycle\\n\\n    - [Architecture decision records overview](/architecture/architecture-decision-records)\\n    - Develop and deliver apps with a deployment pipeline\\n\\n      * [Reference architecture](/architecture/app-development-and-delivery-with-cloud-code-gcb-cd-and-gke)\\n      * [Deploy the architecture](/architecture/app-development-and-delivery-with-cloud-code-gcb-cd-and-gke/deployment)\\n    - [DevOps Research and Assessment (DORA) capabilities](/architecture/devops)\\n  + Application architectures\\n\\n    - Apache Guacamole on GKE and Cloud SQL\\n\\n      * [Reference architecture](/architecture/deploy-guacamole-gke)\\n      * [Deploy the architecture](/architecture/deploy-guacamole-gke/deployment)\\n    - Chrome Remote Desktop on Compute Engine\\n\\n      * [Set up for Linux](/architecture/chrome-desktop-remote-on-compute-engine)\\n      * [Set up for Windows](/architecture/chrome-desktop-remote-windows-compute-engine)\\n    - Connected device architectures on Google Cloud\\n\\n      * [Overview](/architecture/connected-devices)\\n      * [Standalone MQTT broker](/architecture/connected-devices/mqtt-broker-architecture)\\n      * [IoT platform product](/architecture/connected-devices/iot-platform-product-architecture)\\n      * [Device to Pub/Sub connection to Google Cloud](/architecture/connected-devices/device-pubsub-architecture)\\n      * [Best practices for running an IoT backend](/architecture/connected-devices/bps-running-iot-backend-securely)\\n      * [Best practices for automatically provisioning and configuring edge and bare metal systems and servers](/architecture/connected-devices/best-practices-provisioning-configuring-bare-metal)\\n    - [Ecommerce platform with serverless computing](/architecture/application-development/ecommerce-serverless)\\n    - Manage and scale networking for Windows applications that run on managed Kubernetes\\n\\n      * [Reference architecture](/architecture/manage-and-scale-windows-networking)\\n      * [Deploy the architecture](/architecture/manage-and-scale-windows-networking/deployment)\\n    - [Dynamic web application with Python and JavaScript](/architecture/application-development/dynamic-app-python)\\n    - [Use a Cloud SDK Client Library](/architecture/application-development/cloud-client-api)\\n    - [Three-tier web app](/architecture/application-development/three-tier-web-app)\\n    - [Website hosting](/architecture/web-serving-overview)\\n* Big data and analytics\\n\\n  + [Content overview](/architecture/big-data-analytics)\\n  + End-to-end architectures\\n\\n    - [Analytics lakehouse](/architecture/big-data-analytics/analytics-lakehouse)\\n    - [Import data into a secured BigQuery data warehouse](/architecture/blueprints/confidential-data-warehouse-blueprint)\\n    - Data mesh on Google Cloud\\n\\n      * [Architecture and functions in a data mesh](/architecture/data-mesh)\\n      * [Design a self-service data platform for a data mesh](/architecture/design-self-service-data-platform-data-mesh)\\n      * [Build data products in a data mesh](/architecture/build-data-products-data-mesh)\\n      * [Discover and consume data products in a data mesh](/architecture/discover-consume-data-products-data-mesh)\\n    - [Enterprise data management and analytics platform](/architecture/blueprints/deploy_enterprise_data_mesh)\\n    - [Data warehouse with BigQuery](/architecture/big-data-analytics/data-warehouse)\\n    - BigQuery backup automation\\n\\n      * [Reference architecture](/architecture/scalable-bigquery-backup-automation)\\n      * [Deploy the architecture](/architecture/scalable-bigquery-backup-automation/deployment)\\n  + Load and process data\\n\\n    - [Continuous data replication to BigQuery using Striim](/architecture/partners/continuous-data-replication-bigquery-striim)\\n  + Analyze data\\n\\n    - [Data science with R: exploratory data analysis](/architecture/data-science-with-r-on-gcp-eda)\\n* Databases\\n\\n  + [Content overview](/architecture/databases)\\n  + Oracle workloads\\n\\n    - [Overview](/architecture/oracle-workloads)\\n    - [Enterprise application with Oracle Database on Compute Engine](/architecture/enterprise-app-oracle-database-compute-engine)\\n    - [Enterprise application on Compute Engine with Oracle Exadata](/architecture/enterprise-app-oracle-exadata-database-compute-engine)\\n    - [Oracle E-Business Suite with Oracle Database on Compute Engine](/architecture/oracle-ebs-on-compute-engine-vm)\\n    - [Oracle E-Business Suite on Compute Engine with Oracle Exadata](/architecture/oracle-ebs-with-oci-exadata)\\n    - [Oracle PeopleSoft on Compute Engine with Oracle Exadata](/architecture/oracle-peoplesoft-with-oci-exadata)\\n  + [Multi-cloud database management](/architecture/multi-cloud-database-management)\\n* Hybrid and multicloud\\n\\n  + [Content overview](/architecture/hybrid-multicloud)\\n  + Build hybrid and multicloud architectures\\n\\n    - [Overview](/architecture/hybrid-multicloud-patterns)\\n    - [Drivers, considerations, strategy, and patterns](/architecture/hybrid-multicloud-patterns/drivers)\\n    - [Plan a hybrid and multicloud strategy](/architecture/hybrid-multicloud-patterns/strategy)\\n    - [Architectural approaches to adopt a hybrid or multicloud architecture](/architecture/hybrid-multicloud-patterns/adopt)\\n    - [Other considerations](/architecture/hybrid-multicloud-patterns/other-considerations)\\n    - [What\\'s next](/architecture/hybrid-multicloud-patterns/whats-next)\\n    - [View the guide as a single page](/architecture/hybrid-multicloud-patterns/one-page-view)\\n  + Hybrid and multicloud architecture patterns\\n\\n    - [Overview](/architecture/hybrid-multicloud-patterns-and-practices)\\n    - [Distributed architecture patterns](/architecture/hybrid-multicloud-patterns-and-practices/distributed-patterns)\\n    - [Tiered hybrid pattern](/architecture/hybrid-multicloud-patterns-and-practices/tiered-hybrid-pattern)\\n    - [Partitioned multicloud pattern](/architecture/hybrid-multicloud-patterns-and-practices/partitioned-multicloud-pattern)\\n    - [Analytics hybrid and multicloud patterns](/architecture/hybrid-multicloud-patterns-and-practices/analytics-hybrid-multicloud-pattern)\\n    - [Edge hybrid pattern](/architecture/hybrid-multicloud-patterns-and-practices/edge-hybrid-pattern)\\n    - [Environment hybrid pattern](/architecture/hybrid-multicloud-patterns-and-practices/environment-hybrid-pattern)\\n    - [Business continuity hybrid and multicloud patterns](/architecture/hybrid-multicloud-patterns-and-practices/business-continuity-patterns)\\n    - [Cloud bursting pattern](/architecture/hybrid-multicloud-patterns-and-practices/cloud-bursting-pattern)\\n    - [What\\'s next](/architecture/hybrid-multicloud-patterns-and-practices/whats-next)\\n    - [View the guide as a single page](/architecture/hybrid-multicloud-patterns-and-practices/one-page-view)\\n  + Hybrid and multicloud secure networking architecture patterns\\n\\n    - [Overview](/architecture/hybrid-multicloud-secure-networking-patterns)\\n    - [Design considerations](/architecture/hybrid-multicloud-secure-networking-patterns/design-considerations)\\n    - [Architecture patterns](/architecture/hybrid-multicloud-secure-networking-patterns/architecture-patterns)\\n    - [Mirrored pattern](/architecture/hybrid-multicloud-secure-networking-patterns/mirrored-pattern)\\n    - [Meshed pattern](/architecture/hybrid-multicloud-secure-networking-patterns/meshed-pattern)\\n    - [Gated patterns](/architecture/hybrid-multicloud-secure-networking-patterns/gated-patterns)\\n    - [Gated egress](/architecture/hybrid-multicloud-secure-networking-patterns/gated-egress)\\n    - [Gated ingress](/architecture/hybrid-multicloud-secure-networking-patterns/gated-ingress)\\n    - [Gated egress and gated ingress](/architecture/hybrid-multicloud-secure-networking-patterns/gated-egress-ingress)\\n    - [Handover pattern](/architecture/hybrid-multicloud-secure-networking-patterns/handover-pattern)\\n    - [General best practices](/architecture/hybrid-multicloud-secure-networking-patterns/general-best-practices)\\n    - [What\\'s next](/architecture/hybrid-multicloud-secure-networking-patterns/whats-next)\\n    - [View the guide as a single page](/architecture/hybrid-multicloud-secure-networking-patterns/one-page-view)\\n  + Cross-Cloud Network for distributed applications\\n\\n    - [Overview](/architecture/ccn-distributed-apps-design)\\n    - [Connectivity](/architecture/ccn-distributed-apps-design/connectivity)\\n    - [Service networking](/architecture/ccn-distributed-apps-design/service-networking)\\n    - [Network security](/architecture/ccn-distributed-apps-design/security)\\n    - [Cross-Cloud Network inter-VPC connectivity using Network Connectivity Center](/architecture/ccn-distributed-apps-design/ccn-ncc-vpn-ra)\\n    - [Cross-Cloud Network inter-VPC connectivity with VPC Network Peering](/architecture/ccn-distributed-apps-design/ccn-vnp-vpn-ra)\\n    - [VPC Network Peering Cross-Cloud Network with NVAs and regional affinity](/architecture/ccn-distributed-apps-design/ccn-nva-ra)\\n  + Hybrid and multicloud applications\\n\\n    - Hybrid render farm\\n\\n      * [Build a hybrid render farm](/architecture/building-a-hybrid-render-farm)\\n    - [Patterns for connecting other cloud service providers with Google Cloud](/architecture/patterns-for-connecting-other-csps-with-gcp)\\n  + Identity and access management\\n\\n    - Authenticate workforce users in a hybrid environment\\n\\n      * [Overview](/architecture/authenticating-corporate-users-in-a-hybrid-environment)\\n      * [Implementation patterns](/architecture/patterns-for-authenticating-corporate-users-in-a-hybrid-environment)\\n    - [Configure Active Directory for VMs to automatically join a domain](/architecture/configuring-active-directory-for-vms-to-automatically-join-the-domain)\\n    - [Deploy an Active Directory forest on Compute Engine](/architecture/deploy-an-active-directory-forest-on-compute-engine)\\n    - [Patterns for using Active Directory in a hybrid environment](/architecture/patterns-for-using-active-directory-in-a-hybrid-environment)\\n  + Third-party product integrations\\n\\n    - [Data management with Cohesity Helios and Google Cloud](/architecture/partners/using-cohesity-with-cloud-storage-for-enterprise-hybrid-data-protection)\\n* Migration\\n\\n  + [Content overview](/architecture/migrations)\\n  + Migrate to Google Cloud\\n\\n    - [Get started](/architecture/migration-to-gcp-getting-started)\\n    - [Assess and discover your workloads](/architecture/migration-to-gcp-assessing-and-discovering-your-workloads)\\n    - [Plan and build your foundation](/architecture/migration-to-google-cloud-building-your-foundation)\\n    - [Transfer your large datasets](/architecture/migration-to-google-cloud-transferring-your-large-datasets)\\n    - [Deploy your workloads](/architecture/migration-to-gcp-deploying-your-workloads)\\n    - [Migrate from manual deployments to automated, containerized deployments](/architecture/migration-to-google-cloud-automated-containerized-deployments)\\n    - [Optimize your environment](/architecture/migration-to-google-cloud-optimizing-your-environment)\\n    - [Best practices for validating a migration plan](/architecture/migration-to-google-cloud-best-practices)\\n    - [Minimize costs](/architecture/migration-to-google-cloud-minimize-costs)\\n  + Migrate from AWS to Google Cloud\\n\\n    - [Get started](/architecture/migration-from-aws-get-started)\\n    - [Migrate Amazon EC2 to Compute Engine](/architecture/migrate-amazon-ec2-to-compute-engine)\\n    - [Migrate Amazon S3 to Cloud Storage](/architecture/migrate-amazon-s3-to-cloud-storage)\\n    - [Migrate Amazon EKS to GKE](/architecture/migrate-amazon-eks-to-gke)\\n    - [Migrate from Amazon RDS and Amazon Aurora for MySQL to Cloud SQL for MySQL](/architecture/migrate-aws-rds-to-sql-mysql)\\n    - [Migrate from Amazon RDS and Amazon Aurora for PostgreSQL to Cloud SQL and AlloyDB for PostgreSQL](/architecture/migrate-aws-rds-aurora-to-postgresql)\\n    - [Migrate from Amazon RDS for SQL Server to Cloud SQL for SQL Server](/architecture/migrate-aws-rds-to-cloudsql-for-sqlserver)\\n    - [Migrate from AWS Lambda to Cloud Run](/architecture/migrate-aws-lambda-to-cloudrun)\\n  + Migrate from Azure to Google Cloud\\n\\n    - [Get started](/architecture/migration-from-azure-get-started)\\n  + [Migrate to a Google Cloud VMware Engine platform](/architecture/blueprints/vmware-engine-blueprint)\\n  + Application migration\\n\\n    - Migrate containers to Google Cloud\\n\\n      * [Migrate from Kubernetes to GKE](/architecture/migrating-containers-kubernetes-gke)\\n    - Migrate across Google Cloud regions\\n\\n      * [Get started](/architecture/migrate-across-regions)\\n      * [Design resilient single-region environments on Google Cloud](/architecture/migrate-across-regions/design-resilient-single-region-environments)\\n      * [Architect your workloads](/architecture/migrate-across-regions/architect-workloads)\\n      * [Prepare data and batch workloads for migration across regions](/architecture/migrate-across-regions/prepare-data-and-batch-workloads)\\n  + Data and Database migration\\n\\n    - Database migration guide\\n\\n      * [Concepts, principles, and terminology](/architecture/database-migration-concepts-principles-part-1)\\n      * [Set up and run a database migration process](/architecture/database-migration-concepts-principles-part-2)\\n    - Networks for migrating enterprise workloads\\n\\n      * [Architectural approaches](/architecture/network-architecture)\\n      * [Networking for secure intra-cloud access](/architecture/network-secure-intra-cloud-access)\\n      * [Networking for internet-facing application delivery](/architecture/network-application-delivery)\\n      * [Networking for hybrid and multicloud workloads](/architecture/network-hybrid-multicloud)\\n    - Use RIOT Live Migration to migrate to Redis Enterprise Cloud\\n\\n      * [Reference architecture](/architecture/partners/riot-live-migration-redis-enterprise-cloud)\\n      * [Deploy the architecture](/architecture/partners/riot-live-migration-redis-enterprise-cloud/deployment)\\n      * [Define migration scope](/architecture/partners/riot-live-migration-redis-enterprise-cloud/assessment)\\n* Monitoring and logging\\n\\n  + [Content overview](/architecture/monitoring)\\n  + Export logs and metrics\\n\\n    - [Cloud Monitoring metric export](/architecture/monitoring-metric-export)\\n    - Import logs from Cloud Storage to Cloud Logging\\n\\n      * [Reference architecture](/architecture/import-logs-from-storage-to-logging)\\n      * [Deploy the architecture](/architecture/import-logs-from-storage-to-logging/deployment)\\n    - [Stream logs from Google Cloud to Splunk](/architecture/stream-logs-from-google-cloud-to-splunk)\\n  + Hybrid and multicloud monitoring\\n\\n    - [Hybrid and multicloud monitoring and logging patterns](/architecture/hybrid-and-multi-cloud-monitoring-and-logging-patterns)\\n    - Log and monitor on-premises resources with BindPlane\\n\\n      * [Overview](/architecture/logging-and-monitoring-on-premises-resources-with-bindplane)\\n      * [Log on-premises resources](/architecture/logging-on-premises-resources-with-bindplane)\\n      * [Monitor on-premises resources](/architecture/monitoring-on-premises-resources-with-bindplane)\\n    - Stream logs from Google Cloud to Datadog\\n\\n      * [Reference architecture](/architecture/partners/stream-cloud-logs-to-datadog)\\n      * [Deploy the architecture](/architecture/partners/stream-cloud-logs-to-datadog/deployment)\\n* Networking\\n\\n  + [Content overview](/architecture/networking)\\n  + [Best practices and reference architectures for VPC design](/architecture/best-practices-vpc-design)\\n  + Connect\\n\\n    - [Hub-and-spoke network architecture](/architecture/deploy-hub-spoke-vpc-network-topology)\\n    - [Patterns for connecting other cloud service providers with Google Cloud](/architecture/patterns-for-connecting-other-csps-with-gcp)\\n  + Secure\\n\\n    - [Fortigate architecture in Google Cloud](/architecture/partners/fortigate-architecture-in-cloud)\\n    - [Secure virtual private cloud networks with the Palo Alto VM-Series NGFW](/architecture/partners/palo-alto-networks-ngfw)\\n    - [VMware Engine network security using centralized appliances](/architecture/gcve-advanced-network-security)\\n* Reliability and disaster recovery\\n\\n  + [Content overview](/architecture/reliability)\\n  + Infrastructure reliability guide\\n\\n    - [Overview of reliability](/architecture/infra-reliability-guide)\\n    - [Building blocks of reliability](/architecture/infra-reliability-guide/building-blocks)\\n    - [Assess reliability requirements](/architecture/infra-reliability-guide/requirements)\\n    - [Design reliable infrastructure](/architecture/infra-reliability-guide/design)\\n    - [Manage traffic and load](/architecture/infra-reliability-guide/traffic-load)\\n    - [Manage and monitor infrastructure](/architecture/infra-reliability-guide/manage-and-monitor)\\n    - [What\\'s next](/architecture/infra-reliability-guide/whats-next)\\n  + Disaster recovery planning guide\\n\\n    - [Overview](/architecture/dr-scenarios-planning-guide)\\n    - [Building blocks](/architecture/dr-scenarios-building-blocks)\\n    - [Scenarios for data](/architecture/dr-scenarios-for-data)\\n    - [Scenarios for applications](/architecture/dr-scenarios-for-applications)\\n    - [Architecting for locality-restricted workloads](/architecture/architecting-disaster-recovery-for-locality-restricted-workloads)\\n    - [Use cases: locality-restricted data analytics applications](/architecture/dr-scenarios-locality-restricted-data-analytics)\\n    - [Architecting for cloud infrastructure outages](/architecture/disaster-recovery)\\n  + Application availability\\n\\n    - [Load balanced managed VMs](/architecture/reliability/load-balanced-vms)\\n    - [Patterns for using floating IP addresses in Compute Engine](/architecture/patterns-for-floating-ip-addresses-in-compute-engine)\\n  + Data availability\\n\\n    - [Continuous data replication to Cloud Spanner using Striim](/architecture/partners/continuous-data-replication-cloud-spanner-striim)\\n    - [Google Workspace Backup with Afi.ai](/architecture/partners/google-workspace-backup-with-afi-ai)\\n    - [High availability of PostgreSQL clusters on Compute Engine](/architecture/architectures-high-availability-postgresql-clusters-compute-engine)\\n  + [Business continuity with CI/CD on Google Cloud](/architecture/business-continuity-with-cicd-on-google-cloud)\\n* Security and IAM\\n\\n  + [Content overview](/architecture/security-iam)\\n  + Identity and access management overview\\n\\n    - [Overview](/architecture/identity)\\n    - Concepts\\n\\n      * [Overview of Google identity management](/architecture/identity/overview-google-authentication)\\n      * [Reference architectures](/architecture/identity/reference-architectures)\\n      * [Single sign-on](/architecture/identity/single-sign-on)\\n    - Best practices\\n\\n      * [Best practices for planning accounts and organizations](/architecture/identity/best-practices-for-planning)\\n      * [Best practices for federating Google Cloud with an external identity provider](/architecture/identity/best-practices-for-federating)\\n    - Assess and plan\\n\\n      * [Plan the onboarding process](/architecture/identity/overview-assess-and-plan)\\n      * [Federate with Active Directory](/architecture/identity/federating-gcp-with-active-directory-introduction)\\n      * [Federate with Microsoft Entra ID](/architecture/identity/federating-gcp-with-azure-active-directory)\\n      * [Assess existing user accounts](/architecture/identity/assessing-existing-user-accounts)\\n      * [Assess onboarding plans](/architecture/identity/assessing-onboarding-plans)\\n      * [Assess the impact of user account consolidation on federation](/architecture/identity/assessing-consolidation-impact-on-federation)\\n    - Deploy\\n\\n      * [Prepare your Google Workspace or Cloud Identity account](/architecture/identity/preparing-your-g-suite-or-cloud-identity-account)\\n      * Set up federation\\n\\n        + [Microsoft Entra ID user provisioning and single sign-on](/architecture/identity/federating-gcp-with-azure-ad-configuring-provisioning-and-single-sign-on)\\n        + [Microsoft Entra ID B2B user provisioning and single sign-on](/architecture/identity/azure-ad-b2b-user-provisioning-and-sso)\\n        + [Microsoft Entra ID My Apps portal integration](/architecture/identity/integrating-google-services-and-apps-with-azure-ad-portal)\\n        + [Active Directory user account provisioning](/architecture/identity/federating-gcp-with-active-directory-synchronizing-user-accounts)\\n        + [Active Directory single sign-on](/architecture/identity/federating-gcp-with-active-directory-configuring-single-sign-on)\\n        + [Keycloak single sign-on](/architecture/identity/keycloak-single-sign-on)\\n        + [Okta user provisioning and single sign-on](/architecture/identity/okta-provisioning-and-single-sign-on)\\n      * Consolidate accounts\\n\\n        + [Overview](/architecture/identity/overview-consolidating-accounts)\\n        + [Migrate consumer accounts](/architecture/identity/migrating-consumer-accounts)\\n        + [Evict unwanted consumer accounts](/architecture/identity/evicting-consumer-accounts)\\n        + [Sanitize Gmail accounts](/architecture/identity/sanitizing-gmail-accounts)\\n        + [Remove Gmail from consumer accounts](/architecture/identity/removing-gmail-from-consumer-accounts)\\n        + [Reconcile orphaned managed user accounts](/architecture/identity/reconciling-orphaned-managed-user-accounts)\\n    - Resources\\n\\n      * [Example announcement](/architecture/identity/example-announcement)\\n  + Application security\\n\\n    - [Best practices for securing your applications and APIs using Apigee](/architecture/best-practices-securing-applications-and-apis-using-apigee)\\n    - Use context-aware access to secure apps and resources\\n\\n      * [Secure apps and resources](/architecture/secure-apps-resources-using-context-aware-access)\\n      * [Best practices](/architecture/secure-apps-resources-using-context-aware-access/best-practices)\\n    - [Best practices for continuous access to Google Cloud](/architecture/security/best-practices-continuous-access-to-google-cloud)\\n    - [Design secure deployment pipelines](/architecture/design-secure-deployment-pipelines-bp)\\n    - [Use Google Cloud Armor, load balancing, and Cloud CDN to deploy programmable global front ends](/architecture/deploy-programmable-gfe-cloud-armor-lb-cdn)\\n    - Secured serverless architecture\\n\\n      * [Architecture using Cloud Functions](/architecture/blueprints/serverless-functions-blueprint)\\n      * [Architecture using Cloud Run](/architecture/blueprints/serverless-blueprint)\\n  + Compliance\\n\\n    - [Configure networks for FedRAMP and DoD in Google Cloud](/architecture/configure-networks-fedramp-dod-google-cloud)\\n    - [Google Cloud FedRAMP implementation guide](/architecture/fedramp-implementation-guide)\\n    - [FedRAMP and DoD compliance scope](/architecture/security/fedramp-dod-compliance-scope)\\n    - [Limit scope of compliance for PCI environments in Google Cloud](/architecture/limiting-compliance-scope-pci-environments-google-cloud)\\n    - [PCI Data Security Standard compliance](/architecture/pci-dss-compliance-in-gcp)\\n    - [PCI DSS compliance on GKE](/architecture/pci-dss-and-gke-guide)\\n    - [Security blueprint: PCI on GKE](/architecture/gke-pci-dss-blueprint)\\n    - [Tokenize sensitive cardholder data for PCI DSS](/architecture/tokenizing-sensitive-cardholder-data-for-pci-dss)\\n    - [Deployment guidance for Gemini for Government](/architecture/security/deploy-gemini-gov)\\n  + Data and identity protection\\n\\n    - [Configure SaaS data protection for Google Workspace data with SpinOne](/architecture/partners/backing-up-workspace-data-with-spinone)\\n    - [De-identification and re-identification of PII in large-scale datasets using Cloud DLP](/architecture/de-identification-re-identification-pii-using-cloud-dlp)\\n    - [Security log analytics in Google Cloud](/architecture/security-log-analytics)\\n  + Mitigation and avoidance\\n\\n    - Automate malware scanning for files uploaded to Cloud Storage\\n\\n      * [Reference architecture](/architecture/automate-malware-scanning-for-documents-uploaded-to-cloud-storage)\\n      * [Deploy the architecture](/architecture/automate-malware-scanning-for-documents-uploaded-to-cloud-storage/deployment)\\n    - [Best practices for mitigating compromised OAuth tokens for Google Cloud CLI](/architecture/bps-for-mitigating-gcloud-oauth-tokens)\\n    - [Best practices for protecting against cryptocurrency mining attacks](/architecture/security/bps-for-protecting-against-crytocurrency-attacks)\\n    - [Mitigate ransomware attacks](/architecture/security/mitigating-ransomware-attacks)\\n    - [OWASP Top 10 2021 mitigation options on Google Cloud](/architecture/security/owasp-top-ten-mitigation)\\n    - [Identify and prioritize security risks with Wiz Security Graph and Google Cloud](/architecture/partners/id-prioritize-security-risks-with-wiz)\\n  + Network security\\n\\n    - [Secure virtual private cloud networks with the Palo Alto VM-Series NGFW](/architecture/partners/palo-alto-networks-ngfw)\\n* Storage\\n\\n  + [Content overview](/architecture/storage)\\n  + [Design an optimal storage strategy for your cloud workload](/architecture/storage-advisor)\\n  + [Design storage for AI and ML workloads in Google Cloud](/architecture/ai-ml/storage-for-ai-ml)\\n  + [File storage on Compute Engine](/architecture/filers-on-compute-engine)\\n  + [Parallel file systems for HPC workloads](/architecture/parallel-file-systems-for-hpc)\\n  + [Optimize AI and ML workloads with Cloud Storage FUSE](/architecture/optimize-ai-ml-workloads-cloud-storage-fuse)\\n  + [Optimize AI and ML workloads with Managed Lustre](/architecture/optimize-ai-ml-workloads-managed-lustre)\\n\\n* [AI and ML](/docs/ai-ml)\\n* [Application development](/docs/application-development)\\n* [Application hosting](/docs/application-hosting)\\n* [Compute](/docs/compute-area)\\n* [Data analytics and pipelines](/docs/data)\\n* [Databases](/docs/databases)\\n* [Distributed, hybrid, and multicloud](/docs/dhm-cloud)\\n* [Generative AI](/docs/generative-ai)\\n* [Industry solutions](/docs/industry)\\n* [Migration](/docs/migration)\\n* [Networking](/docs/networking)\\n* [Observability and monitoring](/docs/observability)\\n* [Security](/docs/security)\\n* [Storage](/docs/storage)\\n\\n* [Access and resources management](/docs/access-resources)\\n* [Costs and usage management](/docs/costs-usage)\\n* [Infrastructure as code](/docs/iac)\\n* [SDK, languages, frameworks, and tools](/docs/devtools)\\n\\n* [Home](https://docs.cloud.google.com/)\\n* [Documentation](https://docs.cloud.google.com/docs)\\n* [Cloud Architecture Center](https://docs.cloud.google.com/architecture)\\n\\nSend feedback\\n\\n# Choose a design pattern for your agentic AI system Stay organized with collections Save and categorize content based on your preferences.\\n\\nLast reviewed 2025-10-08 UTC\\n\\nThis document provides guidance to help you choose a design pattern for your agentic AI system.\\n*Agent design patterns* are common\\narchitectural approaches to build agentic applications. An agent design pattern\\noffers a distinct framework for organizing a system\\'s components, integrating the\\nmodel, and orchestrating a single agent or multiple agents to accomplish a\\nworkflow.\\n\\n[AI agents](/docs/generative-ai/glossary#ai-agents)\\nare effective for applications that solve open-ended problems, which might require\\nautonomous decision-making and complex multi-step workflow management. Agents\\nexcel at solving problems in real-time by using external data and they excel at automating\\nknowledge-intensive tasks. AI agents are suitable when you need AI to complete\\ngoal-focused tasks with some degree of autonomy. For other use cases, you can\\nuse assistive and generative AI applications. To learn about the differences\\nbetween AI agents and non-agentic AI applications, see\\n[What is the difference between AI agents, AI assistants, and bots?](https://cloud.google.com/discover/what-are-ai-agents#what-is-the-difference-between-ai-agents-ai-assistants-and-bots)\\n\\nThis guide assumes that you have a foundational knowledge of agentic AI systems\\nand how their architecture differs from that of non-agentic systems, such as\\nthose that use direct model reasoning or\\n[retrieval-augmented generation (RAG)](/docs/generative-ai/glossary#retrieval-augmented-generation).\\n\\nFor a summary of the agent pattern guidance, see the\\n[compare design patterns](#compare-design-patterns) section later in this document.\\n\\n## Overview of the design process\\n\\nThe following are the high-level steps to choose a design pattern for your agentic AI system. These steps are described in detail later in this document.\\n\\n1. **Define your requirements**: Assess the characteristics of your workload, including task complexity,\\n   latency and performance expectations, cost budget, and the need for\\n   human involvement.\\n2. **Review the common agent design patterns**:\\n   Learn about the common design patterns in this guide, which include both\\n   single-agent systems and multi-agent systems.\\n3. **Select a pattern**:\\n   Select the appropriate [design pattern](#compare-design-patterns) based on your workload characteristics.\\n\\nThis process isn\\'t a one-time decision. You should periodically revisit these\\nsteps to refine your architecture as your workload characteristics change, your\\nrequirements evolve, or new Google Cloud features become available.\\n\\n## Define your requirements\\n\\nThe questions that follow aren\\'t exhaustive checklists for planning. Use these\\nquestions as a starting point to identify the primary goal of your agentic\\nsystem and to select the best design pattern.\\n\\n* **Task characteristics**: Can your task be completed in predefined\\n  workflow steps or is the task open-ended? Does your task need to use an AI model to\\n  orchestrate the workflow?\\n* **Latency and performance**: Do you need to prioritize fast or interactive\\n  responses at the cost of accuracy or high-quality responses? Or can your\\n  application tolerate a delay to achieve a more accurate or thorough result?\\n* **Cost**: What is your budget for inference costs? Can you\\n  support patterns that require multiple calls to the model for a single request?\\n* **Human involvement**: Does your task involve high-stakes decisions,\\n  safety-critical operations, or subjective approvals that require human judgment?\\n\\nIf your workload is predictable or highly structured, or if it can be executed with a\\nsingle call to an AI model, it can be more cost effective to explore non-agentic\\nsolutions for your task. For example, you might not need an agentic workflow for\\ntasks like summarizing a document, translating text, or classifying customer\\nfeedback. For information about choosing architecture components for generative\\nAI applications that don\\'t require an agentic infrastructure, see\\n[Choose models and infrastructure for your generative AI application](/docs/generative-ai/choose-models-infra-for-ai).\\n\\nThe following sections describe common agent design patterns for building a\\nreliable and effective agentic AI system.\\n\\n## Single-agent system\\n\\nA *single-agent system* uses an AI model, a defined set of tools, and a comprehensive\\nsystem prompt to autonomously handle a user request or to complete a specific task.\\nIn this fundamental pattern, the agent relies on the model\\'s reasoning\\ncapabilities to interpret a user\\'s request, plan a sequence of steps, and decide\\nwhich tools to use from a defined set. The system prompt shapes the agent\\'s\\nbehavior by defining its core task, persona, and operations,\\nand the specific conditions for using each tool.\\n\\nThe following diagram shows a high-level view of a single agent pattern:\\n\\n![Architecture of the single-agent design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-single-agent.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-single-agent.svg)\\n\\nA single-agent system is ideal for tasks that require multiple steps and access\\nto external data. For example, a customer support agent must query a database to\\nfind an order status, or a research assistant needs to call APIs to summarize\\nrecent news. A non-agentic system can\\'t perform these tasks because it can\\'t\\nautonomously use tools or execute a multi-step plan to synthesize a final\\nanswer.\\n\\nIf you\\'re early in your agent development, we recommend that you start with a single agent.\\nWhen you start your agent development with a single-agent system, you can\\nfocus on refining the core logic, prompt, and tool definitions of your agent\\nbefore adding more complex architectural components.\\n\\nA single agent\\'s performance can be less effective when it uses more tools and\\nwhen tasks increase in complexity. You might observe this as increased latency, incorrect\\ntool selection or use, or a failure to complete the task. You can often mitigate\\nthese issues by refining the agent\\'s reasoning process with techniques like the\\n[Reason and Act (ReAct) pattern](#react-pattern).\\nHowever, if your workflow requires an agent to manage several distinct\\nresponsibilities, these techniques might not be sufficient. For these cases,\\nconsider a\\n[multi-agent system](#multi-agent-systems),\\nwhich can improve resilience and performance by delegating specific skills to\\nspecialized agents.\\n\\n## Multi-agent systems\\n\\nA *multi-agent system* orchestrates multiple specialized agents to solve a\\ncomplex problem that a single agent can\\'t easily manage. The core principle is to\\ndecompose a large objective into smaller sub-tasks and assign each sub-task to a\\ndedicated agent with a specific skill. These agents then interact through\\ncollaborative or hierarchical workflows to achieve the final goal. Multi-agent\\npatterns provide a modular design that can improve the scalability, reliability,\\nand maintainability of the overall system compared to a single agent with a\\nmonolithic prompt.\\n\\nIn a multi-agent system, each agent requires a specific context to perform its\\ntask effectively. Context can include documentation, historical preferences,\\nrelevant links, conversational history, or any operational constraints. The\\nprocess of managing this information flow is called\\n*context engineering*. Context engineering includes strategies such as isolating\\ncontext for a specific agent, persisting information across multiple steps, or\\ncompressing large amounts of data to improve efficiency.\\n\\nBuilding a multi-agent system requires additional evaluation, security,\\nreliability, and cost considerations when compared to a single-agent system. For\\nexample, multi-agent systems must implement precise access controls for each\\nspecialized agent, design a robust orchestration system to ensure reliable\\ninter-agent communication, and manage the increased operational costs from the\\ncomputational overhead of running multiple agents. For an example reference\\narchitecture to build a multi-agent system, see\\n[Multi-agent AI systems in Google Cloud](/architecture/multiagent-ai-system).\\n\\n### Sequential pattern\\n\\nThe *multi-agent sequential pattern* executes a series of specialized agents in a predefined, linear order where the\\noutput from one agent serves as the direct input for the next agent. This\\npattern uses a [sequential workflow agent](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/) that operates on predefined logic without having\\nto consult an AI model for the orchestration of its subagents.\\n\\nThe following diagram shows a high-level view of a multi-agent sequential\\npattern:\\n\\n![Architecture of the multi-agent sequential design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-sequential.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-sequential.svg)\\n\\nUse the sequential pattern for highly structured, repeatable processes where\\nthe sequence of operations doesn\\'t change. For example, a data processing\\npipeline might use this pattern to first have a data extraction agent pull raw\\ndata, then pass that data to a data cleaning agent for formatting, which in turn\\npasses the clean data to a data loading agent to save it in a database.\\n\\nThe sequential pattern can reduce latency and operational costs compared to a\\npattern that uses an AI model to orchestrate task workflow. However, this\\nefficiency comes at the cost of flexibility. The rigid, predefined structure of\\nthe pipeline makes it difficult to adapt to dynamic conditions or to skip\\nunnecessary steps, which can cause inefficient processing or lead to higher\\ncumulative latency if an unneeded step is slow.\\n\\n### Parallel pattern\\n\\nThe *multi-agent parallel pattern*,\\nalso known as a *concurrent pattern*, multiple specialized subagents perform a task or sub-tasks independently at the same time. The outputs of the subagents are then synthesized to produce the final consolidated response. Similar to a [sequential pattern](#sequential-pattern), the parallel pattern\\nuses a [parallel workflow agent](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/) to manage how and when the other agents run\\nwithout having to consult an AI model to orchestrate its subagents.\\n\\nThe following diagram shows a high-level view of a multi-agent parallel\\npattern:\\n\\n![Architecture of the multi-agent parallel design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-parallel.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-parallel.svg)\\n\\nUse the parallel pattern when sub-tasks can be executed concurrently to reduce\\nlatency or gather diverse perspectives, such as gathering data from disparate\\nsources or evaluating several options at once. For example, to analyze customer\\nfeedback, a parallel agent might fan out a single feedback entry to four\\nspecialized agents at the same time: a sentiment analysis agent, a keyword extraction\\nagent, a categorization agent, and an urgency detection agent. A final agent\\ngathers these four outputs into a single, comprehensive analysis of\\nthat feedback.\\n\\nThe parallel pattern can reduce overall latency compared to a sequential\\napproach because it can gather diverse information from multiple sources at the same time. However,\\nthis approach introduces trade-offs in cost and complexity. Running multiple\\nagents in parallel can increase immediate resource utilization and token\\nconsumption, which leads to higher operational costs. Furthermore, the gather\\nstep requires complex logic to synthesize potentially conflicting results, which\\nadds to the development and maintenance overhead of the system.\\n\\n### Loop pattern\\n\\nThe *multi-agent loop agent pattern* repeatedly executes a sequence of specialized subagents\\nuntil a specific termination condition is met. This pattern uses a\\n[loop workflow agent](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents)\\nthat, like other workflow agents, operates on predefined logic without\\nconsulting an AI model for orchestration. After all of the subagents complete\\ntheir tasks, the loop agent evaluates whether an exit condition is met. The\\ncondition can be a maximum number of iterations or a custom state. If the\\nexit condition isn\\'t met, then the loop agent starts the sequence of subagents\\nagain. You can implement a loop pattern where the exit condition is evaluated at\\nany point in the flow. Use the loop pattern for tasks that require\\n[iterative refinement](#iterative-refinement-pattern)\\nor self-correction, such as generating content and having a critic agent review\\nit until it meets a quality standard.\\n\\nThe following diagram shows a high-level view of a multi-agent loop pattern:\\n\\n![Architecture of the multi-agent loop design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-loop.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-loop.svg)\\n\\nThe loop agent pattern provides a way to build complex, iterative workflows. It\\nenables agents to refine their own work and continue processing until a specific\\nquality or state is achieved. However, this pattern\\'s primary trade-off is the\\nrisk of an infinite loop. If the termination condition isn\\'t correctly defined\\nor if the subagents fail to produce the state that\\'s required to stop, the loop can run\\nindefinitely. This can lead to excessive operational costs, high resource\\nconsumption, and potential system hangs.\\n\\n### Review and critique pattern\\n\\nThe *multi-agent review and critique pattern*, also known as the *generator and\\ncritic pattern*, improves the quality and reliability of generated content by\\nusing two specialized agents, typically in a sequential workflow. The review and\\ncritique pattern is an implementation of the\\n[loop agent pattern](#loop-pattern).\\n\\nIn the review and critique pattern, a generator agent creates an initial output,\\nsuch as a block of code or a summary of a document. Next, a critic agent\\nevaluates this output against a predefined set of criteria, such as factual\\naccuracy, adherence to formatting rules, or safety guidelines. Based on the\\nevaluation, the critic can approve the content, reject it, or return it to the\\ngenerator with feedback for revision.\\n\\nThe following diagram shows a high-level view of a multi-agent review and\\ncritique pattern:\\n\\n![Architecture of the multi-agent review-critique design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-review-critique.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-review-critique.svg)\\n\\nThis pattern is suitable for tasks where outputs must be highly accurate or must\\nconform to strict constraints before they\\'re presented to a user or used in a\\ndownstream process. For example, in a code generation workflow, a generator\\nagent might write a function to fulfill a user\\'s request. This generated code is\\nthen passed to a critic agent that acts as a security auditor. The critic\\nagent\\'s job is to check the code against a set of constraints, such as scanning\\nfor security vulnerabilities or verifying that it passes all of the unit tests,\\nbefore the code is approved for use.\\n\\nThe reviewer and critique pattern can improve output quality, accuracy, and\\nreliability because it adds a dedicated verification step. However, this quality\\nassurance comes at the direct cost of increased latency and operational\\nexpenses. The workflow requires at least one additional model call for the\\ncritic\\'s evaluation. If the process includes revision loops where content is\\nsent back for refinement, then both latency and costs accumulate with each\\niteration.\\n\\n### Iterative refinement pattern\\n\\nThe *iterative refinement pattern* uses a looping mechanism to progressively\\nimprove an output over multiple cycles. The iterative refinement pattern is an\\nimplementation of the [loop agent pattern](#loop-pattern).\\n\\nIn this pattern, one or more agents work within a loop to modify a result\\nthat\\'s stored in the session state during each iteration. The process continues until\\nthe output meets a predefined quality threshold or it reaches a maximum number of\\niterations, which prevents infinite loops.\\n\\nThe following diagram shows a high-level view of a multi-agent iterative\\nrefinement pattern:\\n\\n![Architecture of the multi-agent iterative refinement design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-iterative-refinement.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-iterative-refinement.svg)\\n\\nThis pattern is suitable for complex generation tasks where the output\\nis difficult to achieve in a single step. Examples of such tasks include writing and debugging a piece\\nof code, developing a detailed multi-part plan, or drafting and revising a\\nlong-form document. For example, in a creative writing workflow, an agent might\\ngenerate a draft of a blog post, critique the draft for flow and tone, and then\\nrewrite the draft based on that critique. This process repeats in a loop until\\nthe agent\\'s work meets a predefined quality standard or until the repetition reaches\\na maximum number of iterations.\\n\\nThe iterative refinement pattern can produce highly complex or polished outputs\\nthat would be difficult to achieve in a single step. However, the looping\\nmechanism directly increases latency and operational costs with each cycle. This\\npattern also adds architectural complexity, because it requires carefully designed\\nexit conditions—such as a quality evaluation or a maximum iteration limit—to\\nprevent excessive costs or uncontrolled execution.\\n\\n### Coordinator pattern\\n\\nThe *multi-agent coordinator pattern* uses a central agent, the *coordinator*, to\\ndirect a workflow. The coordinator analyzes and decomposes a user\\'s request into\\nsub-tasks, and then it dispatches each sub-task to a specialized agent for execution.\\nEach specialized agent is an expert in a specific function, such as querying a database or calling an API.\\n\\nA distinction of the coordinator pattern is its use of an AI model to orchestrate and dynamically route tasks. By contrast, the [parallel pattern](#parallel-pattern) relies on a hardcoded workflow to dispatch tasks for simultaneous execution without the need for AI model orchestration.\\n\\nThe following diagram shows a high-level view of a multi-agent coordinator pattern:\\n\\n![Architecture of the multi-agent coordinator design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-coordinator.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-coordinator.svg)\\n\\nUse the coordinator pattern for automating structured business processes that\\nrequire adaptive routing. For example, a customer service agent can act as the\\ncoordinator. The coordinator agent analyzes the request to determine whether it\\'s\\nan order status request, product return, or refund request. Based on\\nthe type of request, the coordinator routes the task to the appropriate specialized\\nagent.\\n\\nThe coordinator pattern offers flexibility compared to more rigid, predefined\\nworkflows. By using a model to route tasks, the coordinator can handle a wider\\nvariety of inputs and adapt the workflow at runtime. However, this approach also\\nintroduces trade-offs. Because the coordinator and each specialized agent rely\\non a model for reasoning, this pattern results in more model calls than a\\nsingle-agent system. Although the coordinator pattern can lead to higher-quality\\nreasoning, it also increases token throughput, operational costs, and\\noverall latency when compared to a single-agent system.\\n\\n### Hierarchical task decomposition pattern\\n\\nThe *multi-agent hierarchical task decomposition pattern*\\norganizes agents into a multi-level hierarchy to solve complex problems that\\nrequire extensive planning. The hierarchical task decomposition pattern is an\\nimplementation of the\\n[coordinator pattern](#coordinator-pattern).\\nA top-level parent, or *root*, agent receives a complex task and it\\'s responsible\\nfor decomposing the task into several smaller, manageable sub-tasks. The root agent delegates\\neach sub-task to a specialized subagent at a lower level. This process can\\nrepeat through multiple layers, with agents that progressively decompose their\\nassigned tasks until the tasks are simple enough for a worker agent at the lowest\\nlevel to execute directly.\\n\\nThe following diagram shows a high-level view of a multi-agent hierarchical\\ntask decomposition pattern:\\n\\n![Architecture of the multi-agent hierarchical task decomposition design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-hierarchical-task.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-hierarchical-task.svg)\\n\\nUse the hierarchical task decomposition pattern for ambiguous, open-ended\\nproblems that require multi-step reasoning, such as tasks that involve research,\\nplanning, and synthesis. For example, to complete a complex research project, a\\ncoordinator agent decomposes the high-level goal into multiple tasks such as\\ngathering information, analyzing the findings, and synthesizing the final\\nreport. The coordinator agent then delegate those tasks to specialized\\nsubagents, such as an agent for data gathering, an analysis agent, and an\\nagent that writes reports, to execute or further decompose.\\n\\nThe hierarchical task decomposition pattern is ideal for solving highly complex\\nand ambiguous problems because it systematically decomposes them into\\nmanageable sub-tasks. This pattern can result in more comprehensive and higher-quality\\nresults than simpler patterns. However, this advanced capability introduces\\nsignificant trade-offs. The multi-level structure adds considerable\\narchitectural complexity, which makes the system more difficult to design, debug, and\\nmaintain. The multiple layers of delegation and reasoning also result in a high\\nnumber of model calls, which significantly increases both overall latency and\\noperational costs compared to other patterns.\\n\\n### Swarm pattern\\n\\nThe *multi-agent swarm pattern* uses a collaborative, all-to-all communication\\napproach. In this pattern, multiple specialized agents work together to iteratively refine a\\nsolution to a complex problem.\\n\\nThe following diagram shows a high-level view of a multi-agent swarm pattern:\\n\\n![Architecture of the multi-agent swarm design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-swarm.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-swarm.svg)\\n\\nThe swarm pattern uses a dispatcher agent to route a user request\\nto a collaborative group of specialized agents. The dispatcher agent interprets\\nthe request and it determines which agent in the swarm is best suited to begin the\\ntask. In this pattern, each agent can communicate with every other agent,\\nwhich allows them to share findings, critique proposals, and build upon each other\\'s\\nwork to iteratively refine a solution. Any agent in the swarm can hand off the\\ntask to another agent that it determines is better suited to handle the next\\nstep, or it can communicate the final response back to the user through the\\ncoordinator agent.\\n\\nA swarm typically lacks a central supervisor or coordinator agent to keep the\\nprocess on track. The dispatcher agent doesn\\'t orchestrate the agentic workflow,\\nunlike the\\n[coordinator pattern](#coordinator-pattern).\\nInstead, the dispatcher agent facilitates communication between the swarm\\nsubagents and the user. To ensure that the swarm eventually stops and returns a\\nresult, you must define an explicit exit condition. This\\ncondition is often a maximum number of iterations, a time limit, or the\\nachievement of a specific goal, such as reaching a consensus.\\n\\nUse the swarm pattern for ambiguous or highly complex problems that benefit\\nfrom debate and iterative refinement. For example, designing a new product could\\ninvolve a market researcher agent, an engineering agent, and a financial\\nmodeling agent. The agents would share initial ideas, debate the trade-offs\\nbetween features and costs, and collectively converge on a final design\\nspecification that balances all of the competing requirements.\\n\\nThe swarm pattern simulates a collaborative team of experts, therefore it can\\nproduce exceptionally high-quality and creative solutions. However, it represents the\\nmost complex and costly multi-agent pattern to implement. The lack of an agent\\nthat uses an AI model to orchestrate can introduce the risk of unproductive loops\\nor the failure to converge on a solution. You must therefore design\\nsophisticated logic to manage the intricate inter-agent communication, control\\nthe iterative workflow, and handle the significant operational costs and latency\\nthat are associated with running a dynamic, multi-turn conversation between multiple\\nagents.\\n\\n## Reason and act (ReAct) pattern\\n\\nThe\\n[*ReAct pattern*](https://arxiv.org/abs/2210.03629)\\nis an approach that uses the AI model to frame its thought processes and actions\\nas a sequence of natural language interactions. In this pattern, the agent operates in an iterative loop of thought, action, and\\nobservation until an exit condition is met.\\n\\n* **Thought**: The model reasons about the task and it decides what to do next. The model evaluates all of the information that it\\'s gathered in order to determine whether the user\\'s request has been fully answered.\\n* **Action**: Based on its thought process, the model takes one of two actions:\\n  + If the task isn\\'t complete, it selects a tool and then it forms a query to gather more information.\\n  + If the task is complete, it formulates the final answer to send to the user, which ends the loop.\\n* **Observation**: The model receives the output from the tool and it saves relevant information in its memory. Because the model saves relevant output, it can build on previous observations, which helps to prevent the model from repeating itself or losing context.\\n\\nThe iterative loop terminates when\\nthe agent finds a conclusive answer, reaches a preset maximum number of\\niterations, or encounters an error that prevents it from continuing.\\nThis iterative loop lets the agent dynamically build a plan, gather evidence,\\nand adjust its approach as it works toward a final answer.\\n\\nThe following diagram shows a high-level view of the ReAct pattern:\\n\\n![Architecture of the ReAct design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-react.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-react.svg)\\n\\nUse the ReAct pattern for complex, dynamic tasks that require\\ncontinuous planning and adaptation. For example, consider a robotics agent that must generate a path to transition from an initial state to a goal state:\\n\\n* **Thought**: The model reasons about the optimal path to transition from its current state to the goal state. During the thought process, the model optimizes for metrics like time or energy.\\n* **Action**: The model executes the next step in its plan by moving along a calculated path segment.\\n* **Observation**: The model observes and saves the new state of the environment. The model saves its new position and any changes to the environment that it perceives.\\n\\nThis loop allows the agent to\\nadhere to dynamic constraints, such as avoiding new obstacles or following\\ntraffic regulations, by constantly updating its plan based on new observations. The agent continues through its iterative loop until it reaches its goal or encounters an error.\\n\\nA single ReAct agent can be simpler and more cost-effective to implement and\\nmaintain than a complex multi-agent system. Model thinking provides a transcript\\nof the model\\'s reasoning, which helps with debugging. However, this flexibility\\nintroduces trade-offs. The iterative, multi-step nature of the loop can lead to\\nhigher end-to-end latency compared to a single query. Furthermore, the agent\\'s\\neffectiveness is highly dependent on the quality of the AI model\\'s reasoning.\\nTherefore, an error or a misleading result from a tool in one observation step can\\npropagate and cause the final answer to be incorrect.\\n\\n## Human-in-the-loop pattern\\n\\nThe human-in-the-loop pattern integrates points for human intervention directly into an agent\\'s workflow. At a\\npredefined checkpoint, the agent pauses its execution and calls an external\\nsystem to wait for a person to review its work. This pattern lets a person\\napprove a decision, correct an error, or provide necessary input before the\\nagent can continue.\\n\\nThe following diagram shows a high-level view of a human-in-the-loop pattern:\\n\\n![Architecture of the multi-agent human-in-the-loop design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-human-in-the-loop.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-human-in-the-loop.svg)\\n\\nUse the human-in-the-loop pattern for tasks that require human oversight,\\nsubjective judgment, or final approval for critical actions. Such actions include approving a\\nlarge financial transaction, validating the summary of a sensitive document, or\\nproviding subjective feedback on generated creative content. For example, an\\nagent might be tasked with anonymizing a patient dataset for research. The agent\\nwould automatically identify and redact all protected health information, but it\\nwould pause at a final checkpoint. It would then wait for a human compliance\\nofficer to manually validate the dataset and approve its release, which helps to\\nensure that no sensitive data is exposed.\\n\\nThe human-in-the-loop pattern improves safety and reliability by inserting\\nhuman judgment into critical decision points within the workflow. This pattern\\ncan add significant architectural complexity because it requires you to build\\nand maintain the external system for user interaction.\\n\\n## Custom logic pattern\\n\\nThe custom logic pattern provides the maximum flexibility in your workflow\\ndesign. This approach lets you implement specific orchestration logic that uses\\ncode, such as conditional statements, to create complex workflows with multiple\\nbranching paths.\\n\\nThe following diagram illustrates an example use of a custom logic pattern to\\ncapture a refund process:\\n\\n![Architecture of the multi-agent custom design pattern.](/static/architecture/images/choose-design-pattern-agentic-ai-system-custom.svg)\\n\\n![](/static/architecture/images/choose-design-pattern-agentic-ai-system-custom.svg)\\n\\nIn the preceding diagram, the following is the agentic workflow for the example\\ncustomer refund agent:\\n\\n1. The user sends a query to the customer refund agent that acts as a\\n   coordinator agent.\\n2. The coordinator\\'s custom logic first invokes a parallel verifier agent,\\n   which simultaneously dispatches two subagents: the purchaser verifier agent\\n   and the refund eligibility agent.\\n3. After the results are gathered, the coordinator agent executes a tool to\\n   check whether the request is eligible for a refund.\\n   1. If the user is eligible, then the coordinator routes the task\\n      to a refund processor agent, which calls the `process_refund` tool.\\n   2. If the user isn\\'t eligible, then the coordinator routes the\\n      task to a separate sequential flow, starting with the store credit\\n      agent and the process credit decision agent.\\n4. The result from whichever path is taken is sent to the final response agent\\n   to formulate the answer for the user.\\n\\nThe customer refund agent example requires a unique solution for its\\nlogic-level orchestration, which goes beyond the structured approaches that other\\npatterns offer. This workflow mixes patterns because it runs a parallel check,\\nand then it executes a custom conditional branch that routes to two entirely different\\ndownstream processes. This type of complex, mixed-pattern workflow is the ideal\\nuse case for the custom logic pattern.\\n\\nUse the custom logic pattern when you need fine-grained control over the agent\\'s\\nexecution or when your workflow doesn\\'t fit one of the other patterns that\\'s\\ndescribed in this document. However, this approach increases development and\\nmaintenance complexity. You are responsible for designing, implementing, and\\ndebugging the entire orchestration flow, which requires more development effort\\nand can be more error-prone than using a predefined pattern that is supported by\\na tool like\\n[Agent Development Kit (ADK)](https://google.github.io/adk-docs/).\\n\\nFor information about custom agents and how to implement custom logic using ADK, see\\n[Custom agents](https://google.github.io/adk-docs/agents/custom-agents/).\\n\\n## Compare design patterns\\n\\nChoosing an agent pattern is a fundamental architectural decision. Each pattern offers different trade-offs in flexibility, complexity, and performance. To determine the appropriate pattern for your workload, consider the design patterns in the following sections.\\n\\n### Workflows that are deterministic\\n\\nWorkflow that are deterministic include tasks that are predictable and sequential, and that have a clearly defined workflow path from start to finish. The steps in your tasks are known in advance, and the process doesn\\'t change much from one run to the next. The following are agent design patterns for workflows that are deterministic:\\n\\n| Workload characteristics | Agent design pattern |\\n| --- | --- |\\n| * Multi-step tasks that follow a predefined, rigid workflow. * Doesn\\'t require model orchestration. * Fixed sequence of operations. The output of one agent   is the direct input of the next agent in the sequence. | [Multi-agent sequential pattern](#sequential-pattern) |\\n| * Independent tasks that can be executed at the same time. * Doesn\\'t require model orchestration. * Reduces overall latency by running sub-tasks simultaneously. | [Multi-agent parallel pattern](#parallel-pattern) |\\n| * Open-ended or complex generation tasks that are difficult to   complete in a single attempt. * Requires the agent to progressively improve the output   over multiple cycles. * Doesn\\'t require model orchestration. * Prioritizes output quality over latency. | [Multi-agent iterative refinement pattern](#iterative-refinement-pattern) |\\n\\n### Workflows that require dynamic orchestration\\n\\nWorkflows that require dynamic orchestration include complex problems where the agents must determine the best way to proceed. The agentic AI system needs to dynamically plan, delegate, and coordinate tasks without a predefined script. The following are agent design patterns for workflows that require autonomous and dynamic orchestration:\\n\\n| Workload characteristics | Agent design pattern |\\n| --- | --- |\\n| * Structured and multi-step tasks that require the use of external   tools. * Requires fast development for a prototype of a solution as a proof   of concept. | [Single agent pattern](#single-agent-system) |\\n| * Requires dynamic routing to an appropriate specialized subagent for   structured tasks with varied input. * High latency due to multiple calls to the coordinator AI model so that it   can direct tasks to the appropriate subagent. * Can incur high cost due to multiple calls to the coordinator   agent. | [Multi-agent coordinator pattern](#coordinator-pattern) |\\n| * Requires multi-level model orchestration for complex, open-ended, and ambiguous tasks. * Requires comprehensive, high-quality results where decomposing   ambiguity is the primary challenge. * High latency due to nested, multi-level decomposition that leads to   multiple calls to the AI model for reasoning. | [Multi-agent hierarchical task decomposition pattern](#hierarchical-task-decomposition-pattern) |\\n| * Requires collaborative debate and iterative refinement from multiple   specialized agents for highly complex, open-ended, or ambiguous tasks. * Prioritizes the synthesis of multiple perspectives to create a   comprehensive or creative solution. * High latency and operational costs due to dynamic, all-to-all   communication between agents. | [Multi-agent swarm pattern](#swarm-pattern) |\\n\\n### Workflows that involve iteration\\n\\nWorkflows that involve iteration include tasks where the final output is achieved through cycles of refinement, feedback, and improvement. The following are agent design patterns for workflows that involve iteration:\\n\\n| Workload characteristics | Agent design pattern |\\n| --- | --- |\\n| * Requires an agent to iteratively reason, act, and observe to build or adapt   a plan for complex, open-ended, and dynamic tasks. * Prioritizes a more accurate and thorough result over latency. | [ReAct pattern](#react-pattern) |\\n| * Requires monitoring or polling tasks that repeat a predefined action, such   as automated checks, until the agent meets an exit condition. * Unpredictable or long-running latency while waiting for an exit   condition to be met. | [Multi-agent loop pattern](#loop-pattern) |\\n| * Tasks require a distinct validation step before completion. | [Multi-agent review and critique pattern](#review-critique-pattern) |\\n| * Open-ended or complex generation tasks that are difficult to   complete in a single attempt. * Requires the agent to progressively improve the output   over multiple cycles. * Doesn\\'t require model orchestration. * Prioritizes output quality over latency. | [Multi-agent iterative refinement pattern](#iterative-refinement-pattern) |\\n\\n### Workflows that have special requirements\\n\\nWorkflows that have special requirements include tasks that don\\'t follow the common agentic patterns. Your tasks can include unique business logic or they can require human judgment and intervention at critical points. Your agentic AI system is a custom-built machine designed for a single, specific purpose. The following are agent design patterns for workflows that have special requirements:\\n\\n| Workload characteristics | Agent design pattern |\\n| --- | --- |\\n| * Requires human supervision due to high-stakes or subjective tasks   that might include safety, reliability, and compliance requirements. | [Human-in-the-loop pattern](#human-in-the-loop-pattern) |\\n| * Complex, branching logic that goes beyond a direct linear sequence. * Requires   maximum control to mix predefined rules with model reasoning. * Requires fine-grained process control for a workflow that doesn\\'t fit a   standard template. | [Custom logic pattern](#custom-logic-pattern) |\\n\\n## What\\'s next\\n\\n* Learn more about how to construct and manage [multi-agent systems using ADK primitives](https://google.github.io/adk-docs/agents/multi-agents/).\\n* Learn how to\\n  [host AI apps and agents on Cloud Run](/run/docs/ai-agents).\\n* Learn more about\\n  [Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems](https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/).\\n* Learn how to\\n  [build an agent with ADK](/agent-builder/agent-engine/quickstart-adk).\\n* Learn more about how to build\\n  [multi-agent AI systems in Google Cloud](/architecture/multiagent-ai-system).\\n* For more reference architectures, diagrams, and best practices, explore the\\n  [Cloud Architecture Center](/architecture).\\n\\n## Contributors\\n\\nAuthor: [Samantha He](https://www.linkedin.com/in/samantha-he-05a98173) | Technical Writer\\n\\nOther contributors:\\n\\n* [Abdul Saleh](https://www.linkedin.com/in/abdulsaleh/) | Software Engineer\\n* [Amina Mansour](https://www.linkedin.com/in/aminamansour/) | Head of Cloud Platform Evaluations Team\\n* [Amit Maraj](https://www.linkedin.com/in/amit-maraj) | Developer Relations Engineer\\n* [Casey West](https://www.linkedin.com/in/caseywest) | Architecture Advocate, Google Cloud\\n* [Jack Wotherspoon](https://www.linkedin.com/in/jack-wotherspoon) | Developer Advocate\\n* [Joe Fernandez](https://www.linkedin.com/in/joefernandez007/) | Staff Technical Writer\\n* [Joe Shirey](https://www.linkedin.com/in/jshirey) | Cloud Developer Relations Manager\\n* [Karl Weinmeister](https://www.linkedin.com/in/karlweinmeister/) | Director of Cloud Product Developer Relations\\n* [Kumar Dhanagopal](https://www.linkedin.com/in/kumardhanagopal) | Cross-Product Solution Developer\\n* [Lisa Shen](https://www.linkedin.com/in/lisa-shen-6167241/) | Senior Outbound Product Manager, Google Cloud\\n* [Mandy Grover](https://www.linkedin.com/in/mandygrovermatc/) | Head of Architecture Center\\n* [Mark Lu](https://www.linkedin.com/in/mmmarklu/) | Technical Writer\\n* [Megan O\\'Keefe](https://www.linkedin.com/in/askmeegs) | Developer Advocate\\n* [Olivier Bourgeois](https://www.linkedin.com/in/olivi-eh/) | Developer Relations Engineer\\n* [Shir Meir Lador](https://www.linkedin.com/in/shirmeirlador) | Developer Relations Engineering Manager\\n* [Vlad Kolesnikov](https://www.linkedin.com/in/vkolesnikov) | Developer Relations Engineer\\n\\nSend feedback\\n\\nExcept as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.\\n\\nLast updated 2025-10-08 UTC.\\n\\nNeed to tell us more?\\n\\n[[[\"Easy to understand\",\"easyToUnderstand\",\"thumb-up\"],[\"Solved my problem\",\"solvedMyProblem\",\"thumb-up\"],[\"Other\",\"otherUp\",\"thumb-up\"]],[[\"Hard to understand\",\"hardToUnderstand\",\"thumb-down\"],[\"Incorrect information or sample code\",\"incorrectInformationOrSampleCode\",\"thumb-down\"],[\"Missing the information/samples I need\",\"missingTheInformationSamplesINeed\",\"thumb-down\"],[\"Other\",\"otherDown\",\"thumb-down\"]],[\"Last updated 2025-10-08 UTC.\"],[],[]]\\n\\n* ### Products and pricing\\n\\n  + [See all products](//cloud.google.com/products/)\\n  + [Google Cloud pricing](//cloud.google.com/pricing/)\\n  + [Google Cloud Marketplace](//cloud.google.com/marketplace/)\\n  + [Contact sales](//cloud.google.com/contact/)\\n* ### Support\\n\\n  + [Community forums](//discuss.google.dev/c/google-cloud/14/)\\n  + [Support](//cloud.google.com/support-hub/)\\n  + [Release Notes](//docs.cloud.google.com/release-notes)\\n  + [System status](//status.cloud.google.com)\\n* ### Resources\\n\\n  + [GitHub](//github.com/googlecloudPlatform/)\\n  + [Getting Started with Google Cloud](/docs/get-started/)\\n  + [Code samples](/docs/samples)\\n  + [Cloud Architecture Center](/architecture/)\\n  + [Training and Certification](//cloud.google.com/learn/training/)\\n* ### Engage\\n\\n  + [Blog](//cloud.google.com/blog/)\\n  + [Events](//cloud.google.com/events/)\\n  + [X (Twitter)](//x.com/googlecloud)\\n  + [Google Cloud on YouTube](//www.youtube.com/googlecloud)\\n  + [Google Cloud Tech on YouTube](//www.youtube.com/googlecloudplatform)\\n\\n* [About Google](//about.google/)\\n* [Privacy](//policies.google.com/privacy)\\n* [Site terms](//policies.google.com/terms?hl=en)\\n* [Google Cloud terms](//cloud.google.com/product-terms)\\n* Manage cookies\\n* [Our third decade of climate action: join us](//cloud.google.com/sustainability)\\n* Sign up for the Google Cloud newsletter\\n  [Subscribe](//cloud.google.com/newsletter/)\\n\\n* English\\n* Deutsch\\n* Español\\n* Español – América Latina\\n* Français\\n* Indonesia\\n* Italiano\\n* Português\\n* Português – Brasil\\n* 中文 – 简体\\n* 中文 – 繁體\\n* 日本語\\n* 한국어', \"Agentic AI patterns and workflows on AWS - AWS Prescriptive Guidance\\nAgentic AI patterns and workflows on AWS - AWS Prescriptive Guidance\\n\\n[Documentation](/index.html)[AWS Prescriptive Guidance](https://aws.amazon.com/prescriptive-guidance/)[Agentic AI patterns and workflows on AWS](introduction.html)\\n\\n[Intended audience](#intended-audience)[Objectives](#objectives)[About this content series](#content-series)\\n\\n# Agentic AI patterns and workflows on AWS\\n\\n*Aaron Sempf and Andrew Hooker, Amazon Web Services*\\n\\n*July 2025* ([document\\nhistory](./doc-history.html))\\n\\nOrganizations are adopting large language models (LLMs) and software agents to solve\\ndynamic, multidomain problems using a new architectural discipline called agentic patterns.\\nAgentic patterns are foundational blueprints and modular constructs that are used to design\\nand orchestrate goal-oriented AI agents across many contexts.\\n\\n## Intended audience\\n\\nThis guide is intended for architects, developers, and product leaders who want to\\nbuild intelligent applications that go beyond static logic, symbolic logic, and\\ndeterministic automation.\\n\\n## Objectives\\n\\nThis guide provides a design framework and implementation approach for AI agent\\nsystems that operate autonomously while remaining controllable and aligned with your\\ngoals. It connects event-driven architectural patterns with various agentic\\nalternatives, demonstrating how to build production-grade agent systems using\\ncloud-native architectures. The following subjects are discussed in this guide:\\n\\n* **Agent patterns –** Agent patterns are\\n  reusable design templates that describe the structure and behavior of individual\\n  agents. This includes reasoning agents, retrieval-augmented agents, coding\\n  agents, voice interfaces, workflow orchestrators, and collaborative multi-agent\\n  systems. Each pattern illustrates how agents perceive, reason, act, and learn,\\n  mapped to AWS services.\\n* **LLM workflows –** Workflows focus on how\\n  agents use LLMs for reasoning. They explore prompting strategies and planning\\n  mechanisms, and outline how LLMs are used not only to generate text but also to\\n  drive structured, interpretable, and reliable behaviors within an agent\\n  loop.\\n* **Agentic workflow patterns –** Workflow\\n  patterns describe how multiple agents, tools, and environments interact to form\\n  autonomous systems. This includes patterns for task orchestration, subagent\\n  delegation, event-based coordination, observability, and control. These aspects\\n  promote scalable, composable, and auditable AI architectures.\\n\\n## About this content series\\n\\nThis guide is part of a series about agentic AI on AWS. For more information and to\\nview the other guides in this series, see\\xa0[Agentic AI](https://aws.amazon.com/prescriptive-guidance/agentic-ai/)\\xa0on the AWS Prescriptive Guidance\\nwebsite.\\n\\n![Warning](https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png) **Javascript is disabled or is unavailable in your browser.**\\n\\nTo use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.\\n\\n[Document Conventions](/general/latest/gr/docconventions.html)\\n\\nAgent patterns\\n\\nDid this page help you? - Yes\\n\\nThanks for letting us know we're doing a good job!\\n\\nIf you've got a moment, please tell us what we did right so we can do more of it.\\n\\nDid this page help you? - No\\n\\nThanks for letting us know this page needs work. We're sorry we let you down.\\n\\nIf you've got a moment, please tell us how we can make the documentation better.\", 'One Agent For Many Worlds, Cross-Species Cell Embeddings, and more | Andrew Ng | 127 comments\\nAgree & Join LinkedIn\\n\\nBy clicking Continue to join or sign in, you agree to LinkedIn’s [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\\n\\n[Skip to main content](#main-content)\\n\\n[LinkedIn](/?trk=public_post_nav-header-logo)\\n\\n* [Top Content](https://www.linkedin.com/top-content?trk=public_post_guest_nav_menu_topContent)\\n* [People](https://www.linkedin.com/pub/dir/%2B/%2B?trk=public_post_guest_nav_menu_people)\\n* [Learning](https://www.linkedin.com/learning/search?trk=public_post_guest_nav_menu_learning)\\n* [Jobs](https://www.linkedin.com/jobs/search?trk=public_post_guest_nav_menu_jobs)\\n* [Games](https://www.linkedin.com/games?trk=public_post_guest_nav_menu_games)\\n\\n[Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_nav-header-join)\\n\\n[Sign in](https://www.linkedin.com/login?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&fromSignIn=true&trk=public_post_nav-header-signin)\\n\\n# Andrew Ng’s Post\\n\\n[![View profile for Andrew Ng]()](https://www.linkedin.com/in/andrewyng?trk=public_post_feed-actor-image)\\n\\n[Andrew Ng](https://www.linkedin.com/in/andrewyng?trk=public_post_feed-actor-name)\\n\\nAndrew Ng is an Influencer\\n\\n1y\\n\\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\\n\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHere’s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applications’ results. If you’re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: [https://lnkd.in/g4bTuWtU](https://lnkd.in/g4bTuWtU?trk=public_post-text) ]\\n\\n[![One Agent For Many Worlds, Cross-Species Cell Embeddings, and more]()\\n\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\n\\ndeeplearning.ai](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Edeeplearning%2Eai%2Fthe-batch%2Fissue-242%2F&urlhash=yLaH&trk=public_post_feed-article-content)\\n\\n[![]()\\n![]()\\n![]()\\n\\n4,157](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_social-actions-reactions)\\n\\n[127 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_social-actions-comments)\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_like-cta)\\n[Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment-cta)\\n\\nShare\\n\\n* Copy\\n* LinkedIn\\n* Facebook\\n* X\\n\\n[![Dan C., graphic]()](https://nl.linkedin.com/in/comandan?trk=public_post_comment_actor-image)\\n\\n[Dan C.](https://nl.linkedin.com/in/comandan?trk=public_post_comment_actor-name)\\n\\n1y\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\nHere are my custom instructions:\\n“First: Ensure responses delve into the implications of the user’s findings, using them as a springboard for deeper insights rather than summarizing what has already been stated.\\nSecond: Tell me all the assumptions you are making and how they may be wrong.\\nThird:\\n1. Analyze deeply, grasp underlying inquiry. Seek clarifications, look beyond surface.\\n2. Extract essential ideas, concepts, requirements. Basis for nuanced response.\\n3. Before finalizing response, attempt to disprove initial conclusions. Continue until confidence in correctness is achieved.\\n4. Aim for originality, depth. Progress from query to new perspectives, solutions.\\n5. Ensure alignment with goals.\\nBe as clear and succinct as possible when answering and use plain language.”\\nWhen I don’t want to use these custom instructions I use ChatGPT Classic.\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n[9\\xa0Reactions](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reactions)\\n\\n10\\xa0Reactions\\n\\n[![Carlos Chinchilla, graphic]()](https://www.linkedin.com/in/carloschinchilla?trk=public_post_comment_actor-image)\\n\\n[Carlos Chinchilla](https://www.linkedin.com/in/carloschinchilla?trk=public_post_comment_actor-name)\\n\\n1y\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\nOne tool I\\'ve been using to self-correct/self-reflect is \"instructor\", [https://python.useinstructor.com/examples/self\\\\_critique](https://python.useinstructor.com/examples/self_critique?trk=public_post_comment-text)/. With instructor, you use Pydantic validators to self-correct. No need for complex frameworks (langchain, DSP), adhoc code, instructor is all you need.\\nI ran across it while building ZAP, an agent that creates videos using simple instructions like: \"create a video on the origins of AI\". ZAP takes the user\\'s command to create a plan, write code, execute the code in parallel, and returns you a shiny video.\\nVideos produced by ZAP already reached millions of views on TikTok.\\nYou can check out the architecture of ZAP here, [https://www.linkedin.com/feed/update/urn:li:activity:7175525317015392256](https://www.linkedin.com/feed/update/urn%3Ali%3Aactivity%3A7175525317015392256?trk=public_post_comment-text)/.\\nExciting times!\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n[4\\xa0Reactions](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reactions)\\n\\n5\\xa0Reactions\\n\\n[![Sai vamsi C., graphic]()](https://au.linkedin.com/in/sai-chunduru12?trk=public_post_comment_actor-image)\\n\\n[Sai vamsi C.](https://au.linkedin.com/in/sai-chunduru12?trk=public_post_comment_actor-name)\\n\\n1y\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\nI use reflection to generate code, it does a good job, but the only downside of it is multiple LLM calls.\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n[1\\xa0Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reactions)\\n\\n2\\xa0Reactions\\n\\n[![SunDeep Mehra, graphic]()](https://in.linkedin.com/in/sundeep-mehra-614464199?trk=public_post_comment_actor-image)\\n\\n[SunDeep Mehra](https://in.linkedin.com/in/sundeep-mehra-614464199?trk=public_post_comment_actor-name)\\n\\n1y\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\nInteresting to see human curiosity in training LLMs for superior responses.\\nBut out of interest in the topic I would like to ask some sorted questions. Some might find is not fully aligned with the topic, but still, having so many great minds and thinkers, we can at least share some inputs to understand or through some light on other relevant queries.\\nAre we trying to train LLM to criticize its own incorrect responses to get a better one?\\nWhy do we want everything out of it? What is the intent behind it?\\nInstead of honing our own skills, knowledge, and expertise every single time in order to enhance human capabilities and intelligence, why our only goal is to achieve enhanced machine performance.\\nThough it\\'s important to do so to a certain extent, why the whole efforts are all about making humans 2nd?\\nIt feels like humans are planning their own whitewash. We need to use these tools as a screwdriver in our creation and upskilling process so that they can strengthen human intelligence.\\nBut if we are just ready to sit and watch things happen, becoming the laziest species on the planet, then in the next 10 years we might not even need our hands or might sense too. Are we planning our own extinction?\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n[1\\xa0Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reactions)\\n\\n2\\xa0Reactions\\n\\n[![Rahul Kumar, graphic]()](https://pk.linkedin.com/in/rahul-kumar-local-seo-expert?trk=public_post_comment_actor-image)\\n\\n[Rahul Kumar](https://pk.linkedin.com/in/rahul-kumar-local-seo-expert?trk=public_post_comment_actor-name)\\n\\n1mo\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\nReflection is one of those deceptively simple ideas that delivers outsized gains.\\nWhat stands out here is that performance improvements don’t come from better prompts, but from better feedback loops. Treating generation, critique, and revision as separate steps mirrors how humans actually produce high-quality work.\\nI’ve seen similar gains when reflection is paired with lightweight evaluation tools (tests, heuristics, retrieval checks). The model stops “guessing” and starts reasoning about its own mistakes.\\nThis also reframes agent design: progress isn’t just about adding more agents, but about giving agents structured ways to doubt themselves.\\nReflection feels foundational — the kind of pattern that quietly becomes standard practice in serious AI systems.\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n\\n1\\xa0Reaction\\n\\n[![PlatorAI, graphic]()](https://uk.linkedin.com/showcase/platorai/?trk=public_post_comment_actor-image)\\n\\n[PlatorAI](https://uk.linkedin.com/showcase/platorai/?trk=public_post_comment_actor-name)\\n\\n1y\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\nThank-you for sharing Andrew. We (at PlatorAI) have naturally found ourselves doing iterations and breaking things down into smaller chunks and have used different models (Gemini to ChatGPT and back) to check/improve responses. Thank-you for explaining “Reflection” and providing the academic research links (will investigate further). Keep up the good work and sharing for all to learn/develop / understand. 👏\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n[3\\xa0Reactions](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reactions)\\n\\n4\\xa0Reactions\\n\\n[![Ray G. Butler, graphic]()](https://es.linkedin.com/in/raygbutler?trk=public_post_comment_actor-image)\\n\\n[Ray G. Butler](https://es.linkedin.com/in/raygbutler?trk=public_post_comment_actor-name)\\n\\n1y\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\nHello, Andrew. It\\'s a pleasure to chat with you. This topic is very recurrent in our activity at [Butler Scientifics](https://es.linkedin.com/company/butler-scientifics?trk=public_post_comment-text). We have developed quite a few pieces of code with that prompting scheme you propose, but I have serious doubts about its fully automation.\\nThese doubts are based on the fact that a significant proportion of the deviations from the expected results occur due to a lack of technical detail in the initial prompt, usually because the programmer himself was not aware of certain functional requirements. In those cases, the solution was also functional, but the deviation from the expected result was evident. And I doubt an LLM can \"imagine\" those expectations.\\nI couldn\\'t tell you in what proportion of cases this happened, but it\\'s a significant problem.\\nAnyway, I congratulate any initiative to raise the level of abstraction of the solutions implemented by LLMs. We are also working in that direction from our #ButlerLabs. I\\'ll tell you about it ;)\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n[1\\xa0Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reactions)\\n\\n2\\xa0Reactions\\n\\n[![Adeel Ahmad, graphic]()](https://au.linkedin.com/in/adeelahmadch?trk=public_post_comment_actor-image)\\n\\n[Adeel Ahmad](https://au.linkedin.com/in/adeelahmadch?trk=public_post_comment_actor-name)\\n\\n1y\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\n[Andrew Ng](https://www.linkedin.com/in/andrewyng?trk=public_post_comment-text) Thank you so much for sharing this. I am experimenting with a similar framework we usually use during interviews STAR( Situation/Context, Task (needs to be carried out), Actions (for each task) and Results (expectations).\\nand then the agent start working on the actions. Thought its own reflection and comparison with the STAR plan i found that even quantized smaller models are performing well. I am hopping to write a blog post and a POC this weekend.\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n[3\\xa0Reactions](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reactions)\\n\\n4\\xa0Reactions\\n\\n[![Shubham Nayak, graphic]()](https://in.linkedin.com/in/shubhamnayakk?trk=public_post_comment_actor-image)\\n\\n[Shubham Nayak](https://in.linkedin.com/in/shubhamnayakk?trk=public_post_comment_actor-name)\\n\\n1mo\\n\\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\n\\nYour focus on Reflection is appropriate, but you must acknowledge that its ceiling is tightly coupled with your other patterns. Reflection alone is an echo chamber. It only becomes a high-leverage mechanism when integrated with Tool use (to provide objective truth) and Planning (to define specific checkpoints for criticism).\\nYou are excited by the low barrier to entry, but don\\'t let that distract you from the fact that its most significant application requires it to break out of the self-contained LLM environment.\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_like)\\n\\n[Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_comment_reply)\\n\\n1\\xa0Reaction\\n\\n[See more comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_see-more-comments)\\n\\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_feed-cta-banner-cta)\\n\\n![](https://static.licdn.com/aero-v1/sc/h/5q92mjc5c51bjlwaj3rs9aa82)\\n\\n![Andrew Ng]()\\n\\n2,380,861 followers\\n\\n* [479 Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fandrewyng%2Frecent-activity%2F&trk=public_post_follow-posts)\\n* [2 Articles](https://www.linkedin.com/today/author/andrewyng?trk=public_post_follow-articles)\\n\\n[View Profile](https://www.linkedin.com/in/andrewyng?trk=public_post_follow-view-profile)\\n[Connect](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7179159130325078016&trk=public_post_follow)\\n\\n## More from this author\\n\\n* [![]()\\n\\n  ### The impact of Tariffs on AI\\n\\n  Andrew Ng\\n\\n  10mo](https://www.linkedin.com/pulse/impact-tariffs-ai-andrew-ng-ybkkc?trk=public_post)\\n* [![]()\\n\\n  ### Learn to Speak or Teach Better in 30 Minutes\\n\\n  Andrew Ng\\n\\n  11y](https://www.linkedin.com/pulse/20140320175655-176238488-learn-to-speak-or-teach-better-in-30-minutes?trk=public_post)\\n\\n## Explore content categories\\n\\n* [Career](https://www.linkedin.com/top-content/career/)\\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\\n* [Finance](https://www.linkedin.com/top-content/finance/)\\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\\n* [Education](https://www.linkedin.com/top-content/education/)\\n* [Technology](https://www.linkedin.com/top-content/technology/)\\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\\n* [Recruitment & HR](https://www.linkedin.com/top-content/recruitment-hr/)\\n* [Customer Experience](https://www.linkedin.com/top-content/customer-experience/)\\n* [Real Estate](https://www.linkedin.com/top-content/real-estate/)\\n* [Marketing](https://www.linkedin.com/top-content/marketing/)\\n* [Sales](https://www.linkedin.com/top-content/sales/)\\n* [Retail & Merchandising](https://www.linkedin.com/top-content/retail-merchandising/)\\n* [Science](https://www.linkedin.com/top-content/science/)\\n* [Supply Chain Management](https://www.linkedin.com/top-content/supply-chain-management/)\\n* [Future Of Work](https://www.linkedin.com/top-content/future-of-work/)\\n* [Consulting](https://www.linkedin.com/top-content/consulting/)\\n* [Writing](https://www.linkedin.com/top-content/writing/)\\n* [Economics](https://www.linkedin.com/top-content/economics/)\\n* [Artificial Intelligence](https://www.linkedin.com/top-content/artificial-intelligence/)\\n* [Employee Experience](https://www.linkedin.com/top-content/employee-experience/)\\n* [Workplace Trends](https://www.linkedin.com/top-content/workplace-trends/)\\n* [Fundraising](https://www.linkedin.com/top-content/fundraising/)\\n* [Networking](https://www.linkedin.com/top-content/networking/)\\n* [Corporate Social Responsibility](https://www.linkedin.com/top-content/corporate-social-responsibility/)\\n* [Negotiation](https://www.linkedin.com/top-content/negotiation/)\\n* [Communication](https://www.linkedin.com/top-content/communication/)\\n* [Engineering](https://www.linkedin.com/top-content/engineering/)\\n* [Hospitality & Tourism](https://www.linkedin.com/top-content/hospitality-tourism/)\\n* [Business Strategy](https://www.linkedin.com/top-content/business-strategy/)\\n* [Change Management](https://www.linkedin.com/top-content/change-management/)\\n* [Organizational Culture](https://www.linkedin.com/top-content/organizational-culture/)\\n* [Design](https://www.linkedin.com/top-content/design/)\\n* [Innovation](https://www.linkedin.com/top-content/innovation/)\\n* [Event Planning](https://www.linkedin.com/top-content/event-planning/)\\n* [Training & Development](https://www.linkedin.com/top-content/training-development/)\\n\\nShow more\\n\\nShow less\\n\\n* LinkedIn\\n\\n  © 2026\\n* [About](https://about.linkedin.com?trk=d_public_post_footer-about)\\n* [Accessibility](https://www.linkedin.com/accessibility?trk=d_public_post_footer-accessibility)\\n* [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=d_public_post_footer-user-agreement)\\n* [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=d_public_post_footer-privacy-policy)\\n* [Your California Privacy Choices](https://www.linkedin.com/legal/california-privacy-disclosure?trk=d_public_post_footer-california-privacy-rights-act)\\n* [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=d_public_post_footer-cookie-policy)\\n* [Copyright Policy](https://www.linkedin.com/legal/copyright-policy?trk=d_public_post_footer-copyright-policy)\\n* [Brand Policy](https://brand.linkedin.com/policies?trk=d_public_post_footer-brand-policy)\\n* [Guest Controls](https://www.linkedin.com/psettings/guest-controls?trk=d_public_post_footer-guest-controls)\\n* [Community Guidelines](https://www.linkedin.com/legal/professional-community-policies?trk=d_public_post_footer-community-guide)\\n* + العربية (Arabic)\\n  + বাংলা (Bangla)\\n  + Čeština (Czech)\\n  + Dansk (Danish)\\n  + Deutsch (German)\\n  + Ελληνικά (Greek)\\n  + **English (English)**\\n  + Español (Spanish)\\n  + فارسی (Persian)\\n  + Suomi (Finnish)\\n  + Français (French)\\n  + हिंदी (Hindi)\\n  + Magyar (Hungarian)\\n  + Bahasa Indonesia (Indonesian)\\n  + Italiano (Italian)\\n  + עברית (Hebrew)\\n  + 日本語 (Japanese)\\n  + 한국어 (Korean)\\n  + मराठी (Marathi)\\n  + Bahasa Malaysia (Malay)\\n  + Nederlands (Dutch)\\n  + Norsk (Norwegian)\\n  + ਪੰਜਾਬੀ (Punjabi)\\n  + Polski (Polish)\\n  + Português (Portuguese)\\n  + Română (Romanian)\\n  + Русский (Russian)\\n  + Svenska (Swedish)\\n  + తెలుగు (Telugu)\\n  + ภาษาไทย (Thai)\\n  + Tagalog (Tagalog)\\n  + Türkçe (Turkish)\\n  + Українська (Ukrainian)\\n  + Tiếng Việt (Vietnamese)\\n  + 简体中文 (Chinese (Simplified))\\n  + 正體中文 (Chinese (Traditional))\\n\\n  Language\\n\\n![]()\\n\\n## Sign in to view more content\\n\\nCreate your free account or sign in to continue your search\\n\\nEmail or phone\\n\\nPassword\\n\\nShow\\n\\n[Forgot password?](https://www.linkedin.com/uas/request-password-reset?trk=csm-v2_forgot_password)\\n\\nSign in\\n\\nSign in with Email\\n\\nor\\n\\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fandrewyng_one-agent-for-many-worlds-cross-species-activity-7179159130325078016-_oXr&trk=public_post_contextual-sign-in-modal_join-link)\\n\\nBy clicking Continue to join or sign in, you agree to LinkedIn’s [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "id": "yJXO6NaNKVQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84dadf0f-c3e2-4b1d-83d1-58f18a5a5fb5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StructuredTool(name='multiply', description='use to multiply numbers', args_schema=<class '__main__.CalculatorInput'>, return_direct=True, func=<function multiply at 0x78820e0ca520>),\n",
              " StructuredTool(name='search_web_extract_info', description='Search the web for a query and extracts useful information from the search links', args_schema=<class 'langchain_core.utils.pydantic.search_web_extract_info'>, func=<function search_web_extract_info at 0x7881f5b2d1c0>),\n",
              " StructuredTool(name='get_weather', description='Search weatherapi to get the current weather.', args_schema=<class 'langchain_core.utils.pydantic.get_weather'>, func=<function get_weather at 0x7881efea8720>)]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ep0u1lE0QAhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# 1. Define a prompt template with a placeholder for the city\n",
        "# The placeholder is specified using curly braces, e.g., {city}\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Given only the tools at your disposal, mention tool calls for the following tasks:\n",
        "    Do not change the query given for any search tasks.\n",
        "\n",
        "    1. What is 3.14 times 2.718\n",
        "    2. What is the current weather in {city} today\n",
        "    3. What are the 4 major Agentic AI Design Patterns\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# 2. Create a chain using LangChain Expression Language (LCEL)\n",
        "chain = prompt_template | chatgpt_with_tools\n",
        "\n",
        "# 3. Invoke the chain, passing the city as a variable in a dictionary\n",
        "# The key in the dictionary ('city') must match the placeholder in the template\n",
        "city_name = \"Fairmont\"\n",
        "results = chain.invoke({\"city\": city_name})\n",
        "print(results.tool_calls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjydBQXRQAdX",
        "outputId": "d4cfd9ca-033d-44a3-99f9-59da8878eff3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'multiply', 'args': {'a': 3.14, 'b': 2.718}, 'id': 'call_dzN3zUTk943dlK00KghhXzmG', 'type': 'tool_call'}, {'name': 'get_weather', 'args': {'query': 'Fairmont'}, 'id': 'call_iNMulZ6kSpJlMPehkP9dFFfr', 'type': 'tool_call'}, {'name': 'search_web_extract_info', 'args': {'query': '4 major Agentic AI Design Patterns'}, 'id': 'call_m1J3mO41d4nLCyYzbeRpZGCB', 'type': 'tool_call'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "L81ZtgG-QAaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install groq --quiet\n",
        "!pip install langchain-groq --quiet"
      ],
      "metadata": {
        "id": "KaYcVsiTRy_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    stream=False,\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "mIIIEdWiQAWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://console.groq.com/docs/models\n",
        "from langchain_groq import ChatGroq\n",
        "groq_model = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "9Vfp8Zg_QATK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool calling for LLMs without native support for tool or function calling"
      ],
      "metadata": {
        "id": "_1Yc8d9MQDqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some models like ChatGPT have been fine-tuned for tool calling and provide a dedicated API for tool calling. Generally, such models are better at tool calling than non-fine-tuned models, and are recommended for use cases that require tool calling.\n",
        "\n",
        "Here we will explore an alternative method to invoke tools if you're using a model that does not natively support tool calling (even though we use ChatGPT here which supports it, we will assume it could be any LLM which doesn't support tool calling).\n",
        "\n",
        "We'll do this by simply writing a prompt that will get the model to invoke the appropriate tools."
      ],
      "metadata": {
        "id": "yIXJC1-9RXnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import render_text_description\n",
        "\n",
        "rendered_tools = render_text_description(tools)\n",
        "print(rendered_tools)"
      ],
      "metadata": {
        "id": "xr2Wt-iuHEuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"\\\n",
        "You are an assistant that has access to the following set of tools.\n",
        "Here are the names and descriptions for each tool:\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user instructions, for each instruction do the following:\n",
        " - Return the name and input of the tool to use.\n",
        " - Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
        " - The `arguments` should be a dictionary, with keys corresponding\n",
        "   to the argument names and the values corresponding to the requested values.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"user\", \"{input}\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "sO8AT_uiK3zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = [\n",
        "                  {\"input\" : \"What is 2.1 times 3.5\"},\n",
        "                  {\"input\" : \"What is the current weather in Gurgaon\"},\n",
        "                  {\"input\" : \"Tell me about the current state of Agentic AI in the industry\" }\n",
        "               ]"
      ],
      "metadata": {
        "id": "aNq3a5B9HEy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "chain = (prompt\n",
        "            |\n",
        "          groq_model #chatgpt\n",
        "            |\n",
        "         JsonOutputParser())"
      ],
      "metadata": {
        "id": "GJWWhI0NHE3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chain.map().invoke(instructions)"
      ],
      "metadata": {
        "id": "a8O7pvViHE5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses"
      ],
      "metadata": {
        "id": "4F7Cqo6yMGzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toolkit = {\n",
        "    \"multiply\": multiply,\n",
        "    \"search_web_extract_info\": search_web_extract_info,\n",
        "    \"get_weather\": get_weather\n",
        "}\n",
        "\n",
        "for tool_call in responses:\n",
        "    selected_tool = toolkit[tool_call[\"name\"].lower()]\n",
        "    print(f\"Calling tool: {tool_call['name']}\")\n",
        "    tool_output = selected_tool.invoke(tool_call[\"arguments\"])\n",
        "    print(tool_output)\n",
        "    print()"
      ],
      "metadata": {
        "id": "rLsWGvOkM5Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in tool_output:\n",
        "    print(doc)\n",
        "    print()"
      ],
      "metadata": {
        "id": "mOS3qwf6tKNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PqE-MyHsVIcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r23Xwkm1VIYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hkiItp-oVIP5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}